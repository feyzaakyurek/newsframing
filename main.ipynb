{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Finetuning the library models for sequence classification on GLUE (Bert, XLM, XLNet, RoBERTa).\n",
      " Modification of the original script for News-Frame detection\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n",
    "# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "print(\"\"\" Finetuning the library models for sequence classification on GLUE (Bert, XLM, XLNet, RoBERTa).\"\"\")\n",
    "print(\"\"\" Modification of the original script for News-Frame detection\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del os.environ['CUDA_VISIBLE_DEVICES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy.special import expit, softmax\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1113 12:44:30.031979 47186697148864 file_utils.py:39] PyTorch version 1.1.0 available.\n",
      "I1113 12:44:30.931105 47186697148864 modeling_xlnet.py:194] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "from transformers import (WEIGHTS_NAME, BertPreTrainedModel, BertConfig, BertModel,\n",
    "                                  BertForSequenceClassification, BertTokenizer,\n",
    "                                  RobertaConfig,\n",
    "                                  RobertaForSequenceClassification,\n",
    "                                  RobertaTokenizer,\n",
    "                                  XLMConfig, XLMForSequenceClassification,\n",
    "                                  XLMTokenizer, XLNetConfig,\n",
    "                                  XLNetForSequenceClassification,\n",
    "                                  XLNetTokenizer,\n",
    "                                  DistilBertConfig,\n",
    "                                  DistilBertForSequenceClassification,\n",
    "                                  DistilBertTokenizer)\n",
    "\n",
    "from transformers import AdamW, WarmupLinearSchedule\n",
    "from transformers import DataProcessor\n",
    "from transformers import glue_compute_metrics as compute_metrics\n",
    "from transformers import glue_output_modes as output_modes\n",
    "output_modes[\"frame\"] = \"classification\"\n",
    "from transformers import glue_processors as processors\n",
    "# from transformers import glue_convert_examples_to_features as convert_examples_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "ALL_MODELS = sum((tuple(conf.pretrained_config_archive_map.keys()) for conf in (BertConfig, XLNetConfig, XLMConfig, \n",
    "                                                                                RobertaConfig, DistilBertConfig)), ())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     46
    ]
   },
   "outputs": [],
   "source": [
    "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
    "        self.init_weights()\n",
    "        self.inverse_normed_freqs = None\n",
    "        \n",
    "    def set_inverse_normed_freqs(self, args, inverse_normed_freqs):\n",
    "        self.inverse_normed_freqs = inverse_normed_freqs.to(args.device)\n",
    "#         print(\"Inverse Normed Freqs after set: \", self.inverse_normed_freqs)\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None,\n",
    "                position_ids=None, head_mask=None, labels=None):\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            position_ids=position_ids, \n",
    "                            head_mask=head_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        if labels is not None:\n",
    "#             loss_fct = BCEWithLogitsLoss()\n",
    "#             print(\"inverse freqs before sending to loss\", self.inverse_normed_freqs)\n",
    "            loss = FocalLoss(logits, labels, self.inverse_normed_freqs) \n",
    "#             loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels).float())\n",
    "            outputs = (loss,) + outputs\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)\n",
    "\n",
    "        \n",
    "#     def freeze_bert_encoder(self):\n",
    "#         for param in self.bert.parameters():\n",
    "#             param.requires_grad = False\n",
    "    \n",
    "#     def unfreeze_bert_encoder(self):\n",
    "#         for param in self.bert.parameters():\n",
    "#             param.requires_grad = True\n",
    "\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer),\n",
    "    'bertmultilabel': (BertConfig, BertForMultiLabelSequenceClassification, BertTokenizer),\n",
    "    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n",
    "    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
    "    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer),\n",
    "    'distilbert': (DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     31
    ]
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"\n",
    "    A single training/test example for simple sequence classification.\n",
    "    Args:\n",
    "        guid: Unique id for the example.\n",
    "        text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "        text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "        label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.labels = labels\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.to_json_string())\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        return output\n",
    "\n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"\n",
    "    A single set of features of data.\n",
    "    Args:\n",
    "        input_ids: Indices of input sequence tokens in the vocabulary.\n",
    "        attention_mask: Mask to avoid performing attention on padding token indices.\n",
    "            Mask values selected in ``[0, 1]``:\n",
    "            Usually  ``1`` for tokens that are NOT MASKED, ``0`` for MASKED (padded) tokens.\n",
    "        token_type_ids: Segment token indices to indicate first and second portions of the inputs.\n",
    "        label: Label corresponding to the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, attention_mask, token_type_ids, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MultiLabelTextProcessor(DataProcessor):\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "    \n",
    "    def get_inverse_normed_freqs(self, data_dir):\n",
    "        lines = self._read_tsv(os.path.join(data_dir, \"train.tsv\"))\n",
    "        freqs = [0] * 9\n",
    "        for line in lines:\n",
    "            labels = line[3:]\n",
    "#             print(\"line:\", line)\n",
    "#             print(\"labels:\", labels)\n",
    "            for (i,label) in enumerate(labels):\n",
    "#                 print((i,label))\n",
    "                if float(label):\n",
    "#                     print(label)\n",
    "                    freqs[i] = freqs[i]+1\n",
    "        inverse_freqs = [1./f for f in freqs]\n",
    "#         print(\"freqs\", freqs)\n",
    "#         print(\"inverse freqs\", inverse_freqs)\n",
    "        total_inverse_freqs = sum(inverse_freqs)\n",
    "        inverse_normed_freqs = [i/total_inverse_freqs for i in inverse_freqs]\n",
    "        return torch.FloatTensor(inverse_normed_freqs)\n",
    "    \n",
    "\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[1]\n",
    "            labels = line[3:]\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=None, labels=labels))\n",
    "        return examples\n",
    "\n",
    "processors[\"frame\"] = MultiLabelTextProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, tokenizer,\n",
    "                                      max_length=512,\n",
    "                                      task=None,\n",
    "                                      label_list=None,\n",
    "                                      output_mode=None,\n",
    "                                      pad_on_left=False,\n",
    "                                      pad_token=0,\n",
    "                                      pad_token_segment_id=0,\n",
    "                                      mask_padding_with_zero=True):\n",
    "    \"\"\"\n",
    "    Loads a data file into a list of ``InputFeatures``\n",
    "    Args:\n",
    "        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.\n",
    "        tokenizer: Instance of a tokenizer that will tokenize the examples\n",
    "        max_length: Maximum example length\n",
    "        task: GLUE task\n",
    "        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n",
    "        output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n",
    "        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n",
    "        pad_token: Padding token\n",
    "        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n",
    "        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n",
    "            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n",
    "            actual values)\n",
    "    Returns:\n",
    "        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n",
    "        containing the task-specific features. If the input is a list of ``InputExamples``, will return\n",
    "        a list of task-specific ``InputFeatures`` which can be fed to the model.\n",
    "    \"\"\"\n",
    "#     is_tf_dataset = False\n",
    "#     if is_tf_available() and isinstance(examples, tf.data.Dataset):\n",
    "#         is_tf_dataset = True\n",
    "\n",
    "#     if task is not None:\n",
    "#         processor = glue_processors[task]()\n",
    "#         if label_list is None:\n",
    "#             label_list = processor.get_labels()\n",
    "#             logger.info(\"Using label list %s for task %s\" % (label_list, task))\n",
    "#         if output_mode is None:\n",
    "#             output_mode = glue_output_modes[task]\n",
    "#             logger.info(\"Using output mode %s for task %s\" % (output_mode, task))\n",
    "\n",
    "#     label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            logger.info(\"Writing example %d\" % (ex_index))\n",
    "#         if is_tf_dataset:\n",
    "#             example = processor.get_example_from_tensor_dict(example)\n",
    "\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            example.text_a,\n",
    "            example.text_b,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_length - len(input_ids)\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask\n",
    "            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids\n",
    "        else:\n",
    "            input_ids = input_ids + ([pad_token] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_ids), max_length)\n",
    "        assert len(attention_mask) == max_length, \"Error with input length {} vs {}\".format(len(attention_mask), max_length)\n",
    "        assert len(token_type_ids) == max_length, \"Error with input length {} vs {}\".format(len(token_type_ids), max_length)\n",
    "\n",
    "#         if output_mode == \"classification\":\n",
    "#             label = label_map[example.label]\n",
    "#         elif output_mode == \"regression\":\n",
    "#             label = f`loat(example.label)\n",
    "#         else:\n",
    "#             raise KeyError(output_mode)\n",
    "\n",
    "#         labels_ids = []\n",
    "#         for label in example.labels:\n",
    "#             labels_ids.append(float(label))\n",
    "            \n",
    "        labels = [float(i) for i in example.labels]\n",
    "\n",
    "        if ex_index < 5:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"guid: %s\" % (example.guid))\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"attention_mask: %s\" % \" \".join([str(x) for x in attention_mask]))\n",
    "            logger.info(\"token_type_ids: %s\" % \" \".join([str(x) for x in token_type_ids]))\n",
    "            logger.info(\"label: %s\" % (example.labels))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              attention_mask=attention_mask,\n",
    "                              token_type_ids=token_type_ids,\n",
    "                              labels=labels))\n",
    "\n",
    "#     if is_tf_available() and is_tf_dataset:\n",
    "#         def gen():\n",
    "#             for ex in features:\n",
    "#                 yield  ({'input_ids': ex.input_ids,\n",
    "#                          'attention_mask': ex.attention_mask,\n",
    "#                          'token_type_ids': ex.token_type_ids},\n",
    "#                         ex.label)\n",
    "\n",
    "#         return tf.data.Dataset.from_generator(gen,\n",
    "#             ({'input_ids': tf.int32,\n",
    "#               'attention_mask': tf.int32,\n",
    "#               'token_type_ids': tf.int32},\n",
    "#              tf.int64),\n",
    "#             ({'input_ids': tf.TensorShape([None]),\n",
    "#               'attention_mask': tf.TensorShape([None]),\n",
    "#               'token_type_ids': tf.TensorShape([None])},\n",
    "#              tf.TensorShape([])))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train(args, train_dataset, model, tokenizer):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer = SummaryWriter()\n",
    "\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "\n",
    "    if args.max_steps > 0:\n",
    "        t_total = args.max_steps\n",
    "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)\n",
    "    if args.fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
    "\n",
    "    # multi-gpu training (should be after apex fp16 initialization)\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Distributed training (should be after apex fp16 initialization)\n",
    "    if args.local_rank != -1:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank],\n",
    "                                                          output_device=args.local_rank,\n",
    "                                                          find_unused_parameters=True)\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
    "    logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "                   args.train_batch_size * args.gradient_accumulation_steps * (torch.distributed.get_world_size() if args.local_rank != -1 else 1))\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])\n",
    "    set_seed(args)  # Added here for reproductibility (even between python 2 and 3)\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[3]}\n",
    "            if args.model_type != 'distilbert':\n",
    "                inputs['token_type_ids'] = batch[2] if args.model_type in ['bert', 'xlnet'] else None  # XLM, DistilBERT and RoBERTa don't use segment_ids\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
    "\n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean() # mean() to average on multi-gpu parallel training\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "            if args.fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                    # Log metrics\n",
    "                    if args.local_rank == -1 and args.evaluate_during_training:  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                        results = evaluate(args, model, tokenizer)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar('eval_{}'.format(key), value, global_step)\n",
    "                    tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar('loss', (tr_loss - logging_loss)/args.logging_steps, global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
    "                    # Save model checkpoint\n",
    "                    output_dir = os.path.join(args.output_dir, 'checkpoint-{}'.format(global_step))\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "                    model_to_save.save_pretrained(output_dir)\n",
    "                    torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "            if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "        if args.max_steps > 0 and global_step > args.max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, roc_auc, output_dir=False):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    for i in range(len(fpr)):\n",
    "        plt.plot(fpr[i], tpr[i], #color='darkorange',\n",
    "                 lw=lw, label='Frame %d (area = %0.2f)' % (int(i+1), roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if output_dir:\n",
    "        plt.savefig(os.path.join(output_dir, \"auc.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, prefix=\"\"):\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_task_names = (\"mnli\", \"mnli-mm\") if args.task_name == \"mnli\" else (args.task_name,)\n",
    "    eval_outputs_dirs = (args.output_dir, args.output_dir + '-MM') if args.task_name == \"mnli\" else (args.output_dir,)\n",
    "\n",
    "    results = {}\n",
    "    for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n",
    "        eval_dataset = load_and_cache_examples(args, eval_task, tokenizer, evaluate=True)\n",
    "\n",
    "        if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
    "            os.makedirs(eval_output_dir)\n",
    "\n",
    "        args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
    "        # Note that DistributedSampler samples randomly\n",
    "        eval_sampler = SequentialSampler(eval_dataset) if args.local_rank == -1 else DistributedSampler(eval_dataset)\n",
    "        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "        logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "        logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            model.eval()\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs = {'input_ids':      batch[0],\n",
    "                          'attention_mask': batch[1],\n",
    "                          'labels':         batch[3]}\n",
    "                if args.model_type != 'distilbert':\n",
    "                    inputs['token_type_ids'] = batch[2] if args.model_type in ['bert', 'xlnet'] else None  # XLM, DistilBERT and RoBERTa don't use segment_ids\n",
    "                outputs = model(**inputs)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "                eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_steps += 1\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "#         if args.output_mode == \"classification\":\n",
    "#             preds = np.argmax(preds, axis=1)\n",
    "#         elif args.output_mode == \"regression\":\n",
    "#             preds = np.squeeze(preds)\n",
    "        \n",
    "#         preds = softmax(preds, axis=1)\n",
    "        preds = expit(preds)\n",
    "        print(\"preds shape: \", preds.shape)\n",
    "        print(\"out label ids: \", out_label_ids.shape)\n",
    "        print(preds[:5])\n",
    "        print(out_label_ids[:5])\n",
    "\n",
    "        return preds\n",
    "#         output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n",
    "#         with open(output_eval_file, \"w\") as writer:\n",
    "#             logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "#             for key in sorted(results.keys()):\n",
    "#                 logger.info(\"  %s = %s\", key, str(results[key]))\n",
    "#                 writer.write(\"%s = %s\\n\" % (key, str(results[key])))\n",
    "\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_and_cache_examples(args, task, tokenizer, evaluate=False):\n",
    "    if args.local_rank not in [-1, 0] and not evaluate:\n",
    "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
    "\n",
    "    processor = processors[task]()\n",
    "    output_mode = output_modes[task]\n",
    "    # Load data features from cache or dataset file\n",
    "    cached_features_file = os.path.join(args.data_dir, 'cached_{}_{}_{}_{}'.format(\n",
    "        'dev' if evaluate else 'train',\n",
    "        list(filter(None, args.model_name_or_path.split('/'))).pop(),\n",
    "        str(args.max_seq_length),\n",
    "        str(task)))\n",
    "    if os.path.exists(cached_features_file):\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
    "        label_list = processor.get_labels()\n",
    "        if task in ['mnli', 'mnli-mm'] and args.model_type in ['roberta']:\n",
    "            # HACK(label indices are swapped in RoBERTa pretrained model)\n",
    "            label_list[1], label_list[2] = label_list[2], label_list[1] \n",
    "        examples = processor.get_dev_examples(args.data_dir) if evaluate else processor.get_train_examples(args.data_dir)\n",
    "        features = convert_examples_to_features(examples,\n",
    "                                                tokenizer,\n",
    "                                                label_list=label_list,\n",
    "                                                max_length=args.max_seq_length,\n",
    "                                                output_mode=output_mode,\n",
    "                                                pad_on_left=bool(args.model_type in ['xlnet']),                 # pad on the left for xlnet\n",
    "                                                pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "                                                pad_token_segment_id=4 if args.model_type in ['xlnet'] else 0,\n",
    "        )\n",
    "#         if args.local_rank in [-1, 0]:\n",
    "#             logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "#             torch.save(features, cached_features_file)\n",
    "\n",
    "    if args.local_rank == 0 and not evaluate:\n",
    "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
    "\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    if output_mode == \"classification\":\n",
    "        all_labels = torch.tensor([f.labels for f in features], dtype=torch.long) #list of list happens ?\n",
    "    elif output_mode == \"regression\":\n",
    "        all_labels = torch.tensor([f.labels for f in features], dtype=torch.float)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    ## Required parameters\n",
    "    parser.add_argument(\"--data_dir\", default=None, type=str, required=True,\n",
    "                        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n",
    "    parser.add_argument(\"--model_type\", default=None, type=str, required=True,\n",
    "                        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()))\n",
    "    parser.add_argument(\"--model_name_or_path\", default=None, type=str, required=True,\n",
    "                        help=\"Path to pre-trained model or shortcut name selected in the list: \" + \", \".join(ALL_MODELS))\n",
    "    parser.add_argument(\"--task_name\", default=None, type=str, required=True,\n",
    "                        help=\"The name of the task to train selected in the list: \" + \", \".join(processors.keys()))\n",
    "    parser.add_argument(\"--output_dir\", default=None, type=str, required=True,\n",
    "                        help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
    "\n",
    "    ## Other parameters\n",
    "    parser.add_argument(\"--config_name\", default=\"\", type=str,\n",
    "                        help=\"Pretrained config name or path if not the same as model_name\")\n",
    "    parser.add_argument(\"--tokenizer_name\", default=\"\", type=str,\n",
    "                        help=\"Pretrained tokenizer name or path if not the same as model_name\")\n",
    "    parser.add_argument(\"--cache_dir\", default=\"\", type=str,\n",
    "                        help=\"Where do you want to store the pre-trained models downloaded from s3\")\n",
    "    parser.add_argument(\"--max_seq_length\", default=128, type=int,\n",
    "                        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "                             \"than this will be truncated, sequences shorter will be padded.\")\n",
    "    parser.add_argument(\"--do_train\", action='store_true',\n",
    "                        help=\"Whether to run training.\")\n",
    "    parser.add_argument(\"--do_eval\", action='store_true',\n",
    "                        help=\"Whether to run eval on the dev set.\")\n",
    "    parser.add_argument(\"--evaluate_during_training\", action='store_true',\n",
    "                        help=\"Rul evaluation during training at each logging step.\")\n",
    "    parser.add_argument(\"--do_lower_case\", action='store_true',\n",
    "                        help=\"Set this flag if you are using an uncased model.\")\n",
    "    parser.add_argument(\"--german\", action='store_true',\n",
    "                        help=\"Set this flag if you are evaluating in german.\")\n",
    "\n",
    "    parser.add_argument(\"--per_gpu_train_batch_size\", default=8, type=int,\n",
    "                        help=\"Batch size per GPU/CPU for training.\")\n",
    "    parser.add_argument(\"--per_gpu_eval_batch_size\", default=8, type=int,\n",
    "                        help=\"Batch size per GPU/CPU for evaluation.\")\n",
    "    parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n",
    "                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float,\n",
    "                        help=\"The initial learning rate for Adam.\")\n",
    "    parser.add_argument(\"--weight_decay\", default=0.0, type=float,\n",
    "                        help=\"Weight deay if we apply some.\")\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float,\n",
    "                        help=\"Epsilon for Adam optimizer.\")\n",
    "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float,\n",
    "                        help=\"Max gradient norm.\")\n",
    "    parser.add_argument(\"--num_train_epochs\", default=3.0, type=float,\n",
    "                        help=\"Total number of training epochs to perform.\")\n",
    "    parser.add_argument(\"--max_steps\", default=-1, type=int,\n",
    "                        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n",
    "    parser.add_argument(\"--warmup_steps\", default=0, type=int,\n",
    "                        help=\"Linear warmup over warmup_steps.\")\n",
    "\n",
    "    parser.add_argument('--logging_steps', type=int, default=50,\n",
    "                        help=\"Log every X updates steps.\")\n",
    "    parser.add_argument('--save_steps', type=int, default=500,\n",
    "                        help=\"Save checkpoint every X updates steps.\")\n",
    "    parser.add_argument(\"--eval_all_checkpoints\", action='store_true',\n",
    "                        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\")\n",
    "    parser.add_argument(\"--no_cuda\", action='store_true',\n",
    "                        help=\"Avoid using CUDA when available\")\n",
    "    parser.add_argument('--overwrite_output_dir', action='store_true',\n",
    "                        help=\"Overwrite the content of the output directory\")\n",
    "    parser.add_argument('--overwrite_cache', action='store_true',\n",
    "                        help=\"Overwrite the cached training and evaluation sets\")\n",
    "    parser.add_argument('--seed', type=int, default=42,\n",
    "                        help=\"random seed for initialization\")\n",
    "\n",
    "    parser.add_argument('--fp16', action='store_true',\n",
    "                        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\")\n",
    "    parser.add_argument('--fp16_opt_level', type=str, default='O1',\n",
    "                        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
    "                             \"See details at https://nvidia.github.io/apex/amp.html\")\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=-1,\n",
    "                        help=\"For distributed training: local_rank\")\n",
    "    parser.add_argument('--server_ip', type=str, default='', help=\"For distant debugging.\")\n",
    "    parser.add_argument('--server_port', type=str, default='', help=\"For distant debugging.\")\n",
    "    \n",
    "    args = parser.parse_args(ARGS)\n",
    "#     print(\"ARGS MODEL NAME OR PATH\", args.model_name_or_path)\n",
    "#     print(\"CACHE DIR\", args.cache_dir)\n",
    "\n",
    "    if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:\n",
    "        raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))\n",
    "\n",
    "    # Setup distant debugging if needed\n",
    "    if args.server_ip and args.server_port:\n",
    "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
    "        import ptvsd\n",
    "        print(\"Waiting for debugger attach\")\n",
    "        ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n",
    "        ptvsd.wait_for_attach()\n",
    "\n",
    "    # Setup CUDA, GPU & distributed training\n",
    "    if args.local_rank == -1 or args.no_cuda:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "        args.n_gpu = torch.cuda.device_count()\n",
    "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        device = torch.device(\"cuda\", args.local_rank)\n",
    "        torch.distributed.init_process_group(backend='nccl')\n",
    "        args.n_gpu = 1\n",
    "    args.device = device\n",
    "\n",
    "    # Setup logging\n",
    "    logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                        datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                        level = logging.INFO if args.local_rank in [-1, 0] else logging.WARN)\n",
    "    logger.warning(\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "                    args.local_rank, device, args.n_gpu, bool(args.local_rank != -1), args.fp16)\n",
    "\n",
    "    # Set seed\n",
    "    set_seed(args)\n",
    "\n",
    "    # Prepare GLUE task\n",
    "    args.task_name = args.task_name.lower()\n",
    "    if args.task_name not in processors:\n",
    "        raise ValueError(\"Task not found: %s\" % (args.task_name))\n",
    "    processor = processors[args.task_name]()\n",
    "    args.output_mode = output_modes[args.task_name]\n",
    "    label_list = processor.get_labels()\n",
    "    num_labels = len(label_list)\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    if args.local_rank not in [-1, 0]:\n",
    "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
    "\n",
    "    args.model_type = args.model_type.lower()\n",
    "    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "    config = config_class.from_pretrained(args.config_name if args.config_name else \n",
    "                                          args.model_name_or_path, num_labels=num_labels, finetuning_task=args.task_name)\n",
    "    tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name if args.tokenizer_name else \n",
    "                                                args.model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "    model = model_class.from_pretrained(args.model_name_or_path, \n",
    "                                        from_tf=bool('.ckpt' in args.model_name_or_path),\n",
    "                                        config=config)\n",
    "\n",
    "    if args.local_rank == 0:\n",
    "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
    "\n",
    "#     print(\"args.device\", args.device)\n",
    "    \n",
    "\n",
    "    logger.info(\"Training/evaluation parameters %s\", args)\n",
    "    \n",
    "    if args.german:\n",
    "        model.set_inverse_normed_freqs(args,torch.ones(num_labels)) \n",
    "    else:\n",
    "        model.set_inverse_normed_freqs(args,processor.get_inverse_normed_freqs(args.data_dir)) \n",
    "    \n",
    "    model.to(args.device)\n",
    "    # Training\n",
    "    if args.do_train:\n",
    "        # this would crash with other tasks\n",
    "        \n",
    "        train_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False)\n",
    "        global_step, tr_loss = train(args, train_dataset, model, tokenizer) #here\n",
    "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
    "\n",
    "\n",
    "    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
    "        # Create output directory if needed\n",
    "        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
    "            os.makedirs(args.output_dir)\n",
    "\n",
    "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
    "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "        # They can then be reloaded using `from_pretrained()`\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "        model_to_save.save_pretrained(args.output_dir)\n",
    "        tokenizer.save_pretrained(args.output_dir)\n",
    "\n",
    "        # Good practice: save your training arguments together with the trained model\n",
    "        torch.save(args, os.path.join(args.output_dir, 'training_args.bin'))\n",
    "\n",
    "        # Load a trained model and vocabulary that you have fine-tuned\n",
    "        model = model_class.from_pretrained(args.output_dir)\n",
    "        tokenizer = tokenizer_class.from_pretrained(args.output_dir, \n",
    "                                                    do_lower_case=args.do_lower_case)\n",
    "        model.to(args.device)\n",
    "\n",
    "\n",
    "    # Evaluation\n",
    "    results = {}\n",
    "    if args.do_eval and args.local_rank in [-1, 0]:\n",
    "        tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
    "        checkpoints = [args.output_dir]\n",
    "        if args.eval_all_checkpoints:\n",
    "            checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + '/**/' + WEIGHTS_NAME, recursive=True)))\n",
    "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
    "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "        for checkpoint in checkpoints:\n",
    "            global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n",
    "            model = model_class.from_pretrained(checkpoint)\n",
    "            if args.german:\n",
    "                model.set_inverse_normed_freqs(args,torch.ones(num_labels)) \n",
    "            else:\n",
    "                model.set_inverse_normed_freqs(args,processor.get_inverse_normed_freqs(args.data_dir)) \n",
    "            model.to(args.device)\n",
    "            result = evaluate(args, model, tokenizer, prefix=global_step)\n",
    "            return(result)\n",
    "#             result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())\n",
    "#             results.update(result)\n",
    "\n",
    "#     return results\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def FocalLoss(logits, labels, inverse_normed_freqs):\n",
    "    labels = labels.type(torch.float32)\n",
    "    probs = torch.sigmoid(logits)\n",
    "\n",
    "#     print(\"probs: \", probs)\n",
    "#     print(\"labels: \", labels)\n",
    "    pt = (1 - labels) * (1 - probs) + labels * probs\n",
    "    log_pt = torch.log(pt)\n",
    "#     print(\"pt: \", pt)\n",
    "#     print(\"log_pt: \", log_pt)\n",
    "    floss = - (1 - pt)**2 * log_pt\n",
    "#     print(\"floss: \", floss)\n",
    "#     print(\"inverse_normed_freqs in focal loss: \",inverse_normed_freqs)\n",
    "    floss_weighted =  floss * inverse_normed_freqs #torch.autograd.Variable(floss * inverse_normed_freqs)\n",
    "#     floss_weighted = floss\n",
    "    #     q = 1 - probs\n",
    "#     fl = torch.autograd.Variable(q * q * log_probs) #torch.mul(torch.mul(q,q), log_probs)\n",
    "#     print(fl.type())\n",
    "#     print(inverse_normed_freqs.type())\n",
    "#     fl_weighted = torch.autograd.Variable(fl * inverse_normed_freqs)#torch.mul(fl, inverse_normed_freqs)\n",
    "#     print(\"floss_weighted \", floss_weighted)\n",
    "    return torch.mean(floss_weighted)\n",
    "#     loss_fct = BCEWithLogitsLoss(pos_weight=inverse_normed_freqs)\n",
    "#     loss = loss_fct(fl.view(-1, self.num_labels), labels.view(-1, self.num_labels).float())\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoftmaxFocalLoss(logits, labels, inverse_normed_freqs):\n",
    "    labels = labels.type(torch.float32)\n",
    "    m = nn.Softmax(dim=1)\n",
    "    probs = m(logits)\n",
    "    logprobs = torch.log(probs) * inverse_normed_freqs\n",
    "    logyhat_for_gold = labels * logprobs\n",
    "#     print(logyhat_for_gold)\n",
    "    logyhat_for_gold_summed = torch.sum(logyhat_for_gold, dim=1)\n",
    "#     print(logyhat_for_gold_summed)\n",
    "    return torch.mean(-logyhat_for_gold_summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoftmaxLoss(logits, labels, inverse_normed_freqs):\n",
    "    labels = labels.type(torch.float32)\n",
    "    m = nn.Softmax(dim=1)\n",
    "    probs = m(logits)\n",
    "    logyhat_for_gold = labels * torch.log(probs)\n",
    "#     print(logyhat_for_gold)\n",
    "    logyhat_for_gold_summed = torch.sum(logyhat_for_gold, dim=1)\n",
    "#     print(logyhat_for_gold_summed)\n",
    "    return torch.mean(-logyhat_for_gold_summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizedLogSoftmaxLoss(logits, labels, inverse_normed_freqs):\n",
    "    labels = labels.type(torch.float32)\n",
    "    m = nn.Softmax(dim=1)\n",
    "    probs = m(logits)\n",
    "    logyhat_for_gold = labels * torch.log(probs)\n",
    "#     print(logyhat_for_gold)\n",
    "    logyhat_for_gold_normalized_summed = torch.sum(logyhat_for_gold / labels.sum(dim=1).reshape((-1,1)), dim=1)\n",
    "#     print(logyhat_for_gold_normalized_summed)\n",
    "    return torch.mean(-logyhat_for_gold_normalized_summed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogNormalizedSoftmaxLoss(logits, labels, inverse_normed_freqs):\n",
    "    labels = labels.type(torch.float32)\n",
    "    m = nn.Softmax(dim=1)\n",
    "    probs = m(logits)\n",
    "#     print(labels)\n",
    "#     print(probs)\n",
    "    yhat_for_gold = labels * probs\n",
    "#     print(yhat_for_gold)\n",
    "    yhat_for_gold_normalized = torch.sum(yhat_for_gold / labels.sum(dim=1).reshape((-1,1)),dim=1)\n",
    "#     print(yhat_for_gold_normalized)\n",
    "    logyhat_for_gold_normalized = torch.log(yhat_for_gold_normalized)\n",
    "#     print(logyhat_for_gold_normalized)\n",
    "    return torch.mean(-logyhat_for_gold_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGS = [\"--model_type\", 'bertmultilabel',\n",
    "    \"--data_dir\", 'dataset/',\n",
    "    \"--task_name\", 'frame',\n",
    "    \"--model_name_or_path\", 'bert_base_uncased',\n",
    "    \"--output_dir\", 'bert_output_multilingual_cased_30shot',\n",
    "    \"--cache_dir\", '/projectnb/llamagrp/feyzanb/.cache/newsframing/',\n",
    "    \"--max_seq_length\", \"128\",\n",
    "#     \"--do_train\", \n",
    "    \"--do_eval\",\n",
    "    \"--do_lower_case\",\n",
    "    \"--per_gpu_train_batch_size\", \"4\",\n",
    "    \"--learning_rate\", \"2e-5\",\n",
    "    \"--num_train_epochs\", \"10.0\"#,\n",
    "#     \"--overwrite_output_dir\",\n",
    "#     \"--overwrite_cache\"#,\n",
    "#     \"--german\"\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folds = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1113 12:47:43.130322 47186697148864 <ipython-input-16-f7769f312fc9>:114] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--model_type', 'bertmultilabel', '--data_dir', 'dataset/0', '--task_name', 'frame', '--model_name_or_path', 'bert-base-uncased', '--output_dir', '/projectnb/llamagrp/feyzanb/bert_output_uncased/0', '--cache_dir', '/projectnb/llamagrp/feyzanb/.cache/newsframing/english/0', '--max_seq_length', '128', '--do_eval', '--do_lower_case', '--per_gpu_train_batch_size', '4', '--learning_rate', '2e-5', '--num_train_epochs', '10.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1113 12:47:43.311354 47186697148864 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1113 12:47:43.313266 47186697148864 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1113 12:47:43.427211 47186697148864 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I1113 12:47:43.582828 47186697148864 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I1113 12:47:48.050162 47186697148864 modeling_utils.py:405] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1113 12:47:48.052357 47186697148864 modeling_utils.py:408] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1113 12:47:48.055387 47186697148864 <ipython-input-16-f7769f312fc9>:148] Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='/projectnb/llamagrp/feyzanb/.cache/newsframing/english/0', config_name='', data_dir='dataset/0', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', german=False, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bertmultilabel', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='/projectnb/llamagrp/feyzanb/bert_output_uncased/0', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=500, seed=42, server_ip='', server_port='', task_name='frame', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "I1113 12:47:51.631847 47186697148864 tokenization_utils.py:306] Model name '/projectnb/llamagrp/feyzanb/bert_output_uncased/0' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming '/projectnb/llamagrp/feyzanb/bert_output_uncased/0' is a path or url to a directory containing tokenizer files.\n",
      "I1113 12:47:51.634305 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/0/vocab.txt\n",
      "I1113 12:47:51.635148 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/0/added_tokens.json\n",
      "I1113 12:47:51.636029 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/0/special_tokens_map.json\n",
      "I1113 12:47:51.637213 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/0/tokenizer_config.json\n",
      "I1113 12:47:51.710396 47186697148864 <ipython-input-16-f7769f312fc9>:196] Evaluate the following checkpoints: ['/projectnb/llamagrp/feyzanb/bert_output_uncased/0']\n",
      "I1113 12:47:51.712141 47186697148864 configuration_utils.py:148] loading configuration file /projectnb/llamagrp/feyzanb/bert_output_uncased/0/config.json\n",
      "I1113 12:47:51.730102 47186697148864 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1113 12:47:51.731642 47186697148864 modeling_utils.py:334] loading weights file /projectnb/llamagrp/feyzanb/bert_output_uncased/0/pytorch_model.bin\n",
      "I1113 12:47:55.798247 47186697148864 <ipython-input-15-78cf35b18f6f>:17] Creating features from dataset file at dataset/0\n",
      "I1113 12:47:55.803484 47186697148864 <ipython-input-10-f72b0bac0eba>:48] Writing example 0\n",
      "I1113 12:47:55.806084 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:47:55.807108 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-0\n",
      "I1113 12:47:55.808016 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 3282 2386 13217 4149 2300 5312 2077 9288 2008 5303 16988 29360 2015 1010 2047 8495 2678 3065 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.808927 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.809760 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.810579 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:47:55.813242 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:47:55.814084 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-1\n",
      "I1113 12:47:55.814912 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 2047 3290 7328 1024 6884 5152 4654 7913 23738 2015 2040 4738 2336 2000 4287 2041 2082 5008 2015 2031 5571 3333 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.815763 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.816583 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1113 12:47:55.817383 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:47:55.819840 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:47:55.820634 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-2\n",
      "I1113 12:47:55.821457 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 15419 14774 6473 3658 2055 4815 1037 3282 2044 2346 7385 5043 1010 17016 2000 2681 1520 9458 3566 1016 1521 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.822313 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.823132 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.823911 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:47:55.826343 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:47:55.827141 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-3\n",
      "I1113 12:47:55.827970 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 10250 10128 1012 3836 4727 2005 2346 7385 1998 4273 13742 1010 2018 8209 3282 1999 9823 2076 6545 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.828829 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.829640 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.830420 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '1.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:47:55.832662 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:47:55.833469 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-4\n",
      "I1113 12:47:55.834269 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 2317 2158 3138 2041 3282 2000 2644 2304 2493 2013 5738 4545 2311 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.835134 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.835916 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:47:55.836715 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:47:56.209810 47186697148864 <ipython-input-14-982f86686519>:19] ***** Running evaluation  *****\n",
      "I1113 12:47:56.210619 47186697148864 <ipython-input-14-982f86686519>:20]   Num examples = 263\n",
      "I1113 12:47:56.211688 47186697148864 <ipython-input-14-982f86686519>:21]   Batch size = 8\n",
      "Evaluating: 100%|██████████| 33/33 [00:01<00:00, 23.20it/s]\n",
      "W1113 12:47:57.679260 47186697148864 <ipython-input-16-f7769f312fc9>:114] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "I1113 12:47:57.777647 47186697148864 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1113 12:47:57.779175 47186697148864 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1113 12:47:57.854733 47186697148864 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape:  (263, 9)\n",
      "out label ids:  (263, 9)\n",
      "[[0.04340864 0.12741871 0.36479062 0.73051023 0.29104042 0.08762373\n",
      "  0.07951498 0.03697357 0.05642395]\n",
      " [0.04692642 0.11594824 0.21871622 0.07402629 0.3543731  0.8389425\n",
      "  0.12013794 0.09937272 0.08372583]\n",
      " [0.05557809 0.15619554 0.31571555 0.445836   0.0868151  0.07386196\n",
      "  0.2564693  0.04908425 0.0436422 ]\n",
      " [0.05897277 0.19968487 0.2119074  0.78304243 0.24766329 0.11617464\n",
      "  0.09429694 0.08327261 0.05109496]\n",
      " [0.0755087  0.13720283 0.18288729 0.0828888  0.13408856 0.8981723\n",
      "  0.18593797 0.0495123  0.08220718]]\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]]\n",
      "['--model_type', 'bertmultilabel', '--data_dir', 'dataset/1', '--task_name', 'frame', '--model_name_or_path', 'bert-base-uncased', '--output_dir', '/projectnb/llamagrp/feyzanb/bert_output_uncased/1', '--cache_dir', '/projectnb/llamagrp/feyzanb/.cache/newsframing/english/1', '--max_seq_length', '128', '--do_eval', '--do_lower_case', '--per_gpu_train_batch_size', '4', '--learning_rate', '2e-5', '--num_train_epochs', '10.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1113 12:47:57.990742 47186697148864 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I1113 12:48:01.252294 47186697148864 modeling_utils.py:405] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1113 12:48:01.253315 47186697148864 modeling_utils.py:408] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1113 12:48:01.255805 47186697148864 <ipython-input-16-f7769f312fc9>:148] Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='/projectnb/llamagrp/feyzanb/.cache/newsframing/english/1', config_name='', data_dir='dataset/1', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', german=False, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bertmultilabel', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='/projectnb/llamagrp/feyzanb/bert_output_uncased/1', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=500, seed=42, server_ip='', server_port='', task_name='frame', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "I1113 12:48:01.348901 47186697148864 tokenization_utils.py:306] Model name '/projectnb/llamagrp/feyzanb/bert_output_uncased/1' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming '/projectnb/llamagrp/feyzanb/bert_output_uncased/1' is a path or url to a directory containing tokenizer files.\n",
      "I1113 12:48:01.350825 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/1/vocab.txt\n",
      "I1113 12:48:01.351640 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/1/added_tokens.json\n",
      "I1113 12:48:01.352443 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/1/special_tokens_map.json\n",
      "I1113 12:48:01.353237 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/1/tokenizer_config.json\n",
      "I1113 12:48:01.424987 47186697148864 <ipython-input-16-f7769f312fc9>:196] Evaluate the following checkpoints: ['/projectnb/llamagrp/feyzanb/bert_output_uncased/1']\n",
      "I1113 12:48:01.426360 47186697148864 configuration_utils.py:148] loading configuration file /projectnb/llamagrp/feyzanb/bert_output_uncased/1/config.json\n",
      "I1113 12:48:01.438076 47186697148864 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1113 12:48:01.439587 47186697148864 modeling_utils.py:334] loading weights file /projectnb/llamagrp/feyzanb/bert_output_uncased/1/pytorch_model.bin\n",
      "I1113 12:48:04.957227 47186697148864 <ipython-input-15-78cf35b18f6f>:17] Creating features from dataset file at dataset/1\n",
      "I1113 12:48:04.975324 47186697148864 <ipython-input-10-f72b0bac0eba>:48] Writing example 0\n",
      "I1113 12:48:04.977721 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:04.978689 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-0\n",
      "I1113 12:48:04.979696 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 3516 13108 1037 11587 10459 2099 2007 2317 10514 28139 22911 2923 7208 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:04.980598 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:04.981474 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:04.982313 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '1.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:04.984747 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:04.985585 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-1\n",
      "I1113 12:48:04.986471 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 11447 4564 9458 5496 1997 4147 2317 10514 28139 22911 2923 3797 25803 2015 2025 5905 2000 4255 5571 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:04.987383 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:04.988447 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:04.989231 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:04.991742 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:04.992560 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-2\n",
      "I1113 12:48:04.993473 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 2155 2008 2165 1999 3516 5008 8343 2655 2032 1037 1005 6071 1005 1998 2360 2027 2018 2053 9789 2054 2002 2001 4041 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:04.994370 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1113 12:48:04.997931 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:04.998672 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:05.001189 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:05.002044 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-3\n",
      "I1113 12:48:05.002886 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 2023 2003 1037 2200 4795 2711 1010 1005 2758 5160 2040 3421 16011 6778 1997 5374 3282 2386 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:05.003766 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:05.004790 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:05.005579 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:05.007859 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:05.008678 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-4\n",
      "I1113 12:48:05.009532 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 2054 2079 2087 3742 28310 2031 1999 2691 1029 2009 1005 1055 2025 4331 1010 6355 2678 2399 2030 27906 9029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:05.010431 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:05.011217 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:05.012025 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0']\n",
      "I1113 12:48:05.356293 47186697148864 <ipython-input-14-982f86686519>:19] ***** Running evaluation  *****\n",
      "I1113 12:48:05.357110 47186697148864 <ipython-input-14-982f86686519>:20]   Num examples = 262\n",
      "I1113 12:48:05.357957 47186697148864 <ipython-input-14-982f86686519>:21]   Batch size = 8\n",
      "Evaluating: 100%|██████████| 33/33 [00:01<00:00, 23.48it/s]\n",
      "W1113 12:48:06.819673 47186697148864 <ipython-input-16-f7769f312fc9>:114] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "I1113 12:48:07.001979 47186697148864 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1113 12:48:07.003806 47186697148864 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape:  (262, 9)\n",
      "out label ids:  (262, 9)\n",
      "[[0.07955708 0.14946368 0.28254947 0.10472074 0.13432314 0.90846306\n",
      "  0.10310006 0.06664892 0.10803405]\n",
      " [0.0776747  0.16687767 0.25703645 0.08864477 0.15758792 0.9016271\n",
      "  0.12426701 0.04859072 0.09720241]\n",
      " [0.04612062 0.07984187 0.26859125 0.4535532  0.31315666 0.10227143\n",
      "  0.09236971 0.07483799 0.05100579]\n",
      " [0.20586269 0.09409542 0.37411752 0.55721545 0.11120135 0.14070842\n",
      "  0.08125616 0.11873214 0.05817408]\n",
      " [0.06490583 0.11185152 0.27022964 0.12168467 0.2290048  0.22750726\n",
      "  0.13255583 0.7438503  0.0983653 ]]\n",
      "[[0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]]\n",
      "['--model_type', 'bertmultilabel', '--data_dir', 'dataset/2', '--task_name', 'frame', '--model_name_or_path', 'bert-base-uncased', '--output_dir', '/projectnb/llamagrp/feyzanb/bert_output_uncased/2', '--cache_dir', '/projectnb/llamagrp/feyzanb/.cache/newsframing/english/2', '--max_seq_length', '128', '--do_eval', '--do_lower_case', '--per_gpu_train_batch_size', '4', '--learning_rate', '2e-5', '--num_train_epochs', '10.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1113 12:48:07.081628 47186697148864 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I1113 12:48:07.251127 47186697148864 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I1113 12:48:10.415192 47186697148864 modeling_utils.py:405] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1113 12:48:10.416427 47186697148864 modeling_utils.py:408] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1113 12:48:10.419041 47186697148864 <ipython-input-16-f7769f312fc9>:148] Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='/projectnb/llamagrp/feyzanb/.cache/newsframing/english/2', config_name='', data_dir='dataset/2', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', german=False, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bertmultilabel', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='/projectnb/llamagrp/feyzanb/bert_output_uncased/2', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=500, seed=42, server_ip='', server_port='', task_name='frame', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "I1113 12:48:10.511191 47186697148864 tokenization_utils.py:306] Model name '/projectnb/llamagrp/feyzanb/bert_output_uncased/2' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming '/projectnb/llamagrp/feyzanb/bert_output_uncased/2' is a path or url to a directory containing tokenizer files.\n",
      "I1113 12:48:10.513379 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/2/vocab.txt\n",
      "I1113 12:48:10.514190 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/2/added_tokens.json\n",
      "I1113 12:48:10.515236 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/2/special_tokens_map.json\n",
      "I1113 12:48:10.516053 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/2/tokenizer_config.json\n",
      "I1113 12:48:10.588424 47186697148864 <ipython-input-16-f7769f312fc9>:196] Evaluate the following checkpoints: ['/projectnb/llamagrp/feyzanb/bert_output_uncased/2']\n",
      "I1113 12:48:10.589577 47186697148864 configuration_utils.py:148] loading configuration file /projectnb/llamagrp/feyzanb/bert_output_uncased/2/config.json\n",
      "I1113 12:48:10.602925 47186697148864 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1113 12:48:10.604427 47186697148864 modeling_utils.py:334] loading weights file /projectnb/llamagrp/feyzanb/bert_output_uncased/2/pytorch_model.bin\n",
      "I1113 12:48:14.448715 47186697148864 <ipython-input-15-78cf35b18f6f>:17] Creating features from dataset file at dataset/2\n",
      "I1113 12:48:14.454068 47186697148864 <ipython-input-10-f72b0bac0eba>:48] Writing example 0\n",
      "I1113 12:48:14.456786 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:14.457886 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-0\n",
      "I1113 12:48:14.458810 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 7262 1024 2177 11834 7696 2265 2082 13108 15896 2007 2679 1010 4808 1998 4409 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.459730 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.460539 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.461343 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '1.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:14.463622 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:14.464424 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-1\n",
      "I1113 12:48:14.465287 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 3516 2082 5008 8343 2001 10847 2011 2110 2044 2969 1011 7386 2075 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.467710 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.468486 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.469259 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:14.471578 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:14.472385 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-2\n",
      "I1113 12:48:14.473206 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 2158 5496 1997 5008 2012 2304 10563 2040 6573 2006 2010 2341 2000 3198 2005 7826 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1113 12:48:14.474050 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.474889 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.475693 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:14.477918 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:14.478704 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-3\n",
      "I1113 12:48:14.479527 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 2430 4174 2118 3738 2018 3674 2448 16021 2007 5008 8343 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.480388 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.481164 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.481938 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:14.484004 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:14.484805 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-4\n",
      "I1113 12:48:14.485638 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 2023 2003 2019 25982 12731 14277 14778 1997 2082 5008 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.486467 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.487293 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:14.488065 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0']\n",
      "I1113 12:48:14.865668 47186697148864 <ipython-input-14-982f86686519>:19] ***** Running evaluation  *****\n",
      "I1113 12:48:14.866601 47186697148864 <ipython-input-14-982f86686519>:20]   Num examples = 260\n",
      "I1113 12:48:14.867685 47186697148864 <ipython-input-14-982f86686519>:21]   Batch size = 8\n",
      "Evaluating: 100%|██████████| 33/33 [00:01<00:00, 23.90it/s]\n",
      "W1113 12:48:16.312190 47186697148864 <ipython-input-16-f7769f312fc9>:114] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "I1113 12:48:16.395670 47186697148864 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1113 12:48:16.397108 47186697148864 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1113 12:48:16.471899 47186697148864 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape:  (260, 9)\n",
      "out label ids:  (260, 9)\n",
      "[[0.04110694 0.05967558 0.20292887 0.22391777 0.23971002 0.56526226\n",
      "  0.09846657 0.17351978 0.04524326]\n",
      " [0.08434811 0.18139066 0.22533362 0.7281061  0.3984547  0.0859406\n",
      "  0.06714122 0.05511456 0.08133119]\n",
      " [0.08926317 0.15205067 0.15812111 0.10873505 0.1010012  0.88676995\n",
      "  0.14195527 0.0588534  0.08003863]\n",
      " [0.09217443 0.12329684 0.20708011 0.46330163 0.2840619  0.11752767\n",
      "  0.07807034 0.04955725 0.05393311]\n",
      " [0.04193665 0.0757037  0.27847305 0.06766564 0.6445395  0.08547347\n",
      "  0.13040334 0.38228297 0.09859458]]\n",
      "[[0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]]\n",
      "['--model_type', 'bertmultilabel', '--data_dir', 'dataset/3', '--task_name', 'frame', '--model_name_or_path', 'bert-base-uncased', '--output_dir', '/projectnb/llamagrp/feyzanb/bert_output_uncased/3', '--cache_dir', '/projectnb/llamagrp/feyzanb/.cache/newsframing/english/3', '--max_seq_length', '128', '--do_eval', '--do_lower_case', '--per_gpu_train_batch_size', '4', '--learning_rate', '2e-5', '--num_train_epochs', '10.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1113 12:48:16.599407 47186697148864 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I1113 12:48:19.760777 47186697148864 modeling_utils.py:405] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1113 12:48:19.761798 47186697148864 modeling_utils.py:408] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1113 12:48:19.764306 47186697148864 <ipython-input-16-f7769f312fc9>:148] Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='/projectnb/llamagrp/feyzanb/.cache/newsframing/english/3', config_name='', data_dir='dataset/3', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', german=False, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bertmultilabel', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='/projectnb/llamagrp/feyzanb/bert_output_uncased/3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=500, seed=42, server_ip='', server_port='', task_name='frame', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "I1113 12:48:19.857145 47186697148864 tokenization_utils.py:306] Model name '/projectnb/llamagrp/feyzanb/bert_output_uncased/3' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming '/projectnb/llamagrp/feyzanb/bert_output_uncased/3' is a path or url to a directory containing tokenizer files.\n",
      "I1113 12:48:19.858998 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/3/vocab.txt\n",
      "I1113 12:48:19.859747 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/3/added_tokens.json\n",
      "I1113 12:48:19.860556 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/3/special_tokens_map.json\n",
      "I1113 12:48:19.861292 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/3/tokenizer_config.json\n",
      "I1113 12:48:19.946213 47186697148864 <ipython-input-16-f7769f312fc9>:196] Evaluate the following checkpoints: ['/projectnb/llamagrp/feyzanb/bert_output_uncased/3']\n",
      "I1113 12:48:19.947432 47186697148864 configuration_utils.py:148] loading configuration file /projectnb/llamagrp/feyzanb/bert_output_uncased/3/config.json\n",
      "I1113 12:48:19.963351 47186697148864 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1113 12:48:19.964763 47186697148864 modeling_utils.py:334] loading weights file /projectnb/llamagrp/feyzanb/bert_output_uncased/3/pytorch_model.bin\n",
      "I1113 12:48:24.294799 47186697148864 <ipython-input-15-78cf35b18f6f>:17] Creating features from dataset file at dataset/3\n",
      "I1113 12:48:24.299174 47186697148864 <ipython-input-10-f72b0bac0eba>:48] Writing example 0\n",
      "I1113 12:48:24.301623 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:24.302541 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-0\n",
      "I1113 12:48:24.303386 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 14135 3076 5338 2007 9554 5026 8209 3282 2503 2152 2082 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.304285 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.305085 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.305893 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:24.308035 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:24.308845 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-1\n",
      "I1113 12:48:24.309701 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 9559 2655 2149 3282 5571 2005 4916 2158 1005 19354 29201 3512 1005 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.310557 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.311388 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.312176 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:24.314336 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:24.315141 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-2\n",
      "I1113 12:48:24.315973 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 3516 13108 3662 4808 2012 2188 1010 2610 4311 7487 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.316837 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1113 12:48:24.317664 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.318445 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:24.320852 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:24.321642 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-3\n",
      "I1113 12:48:24.322501 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 9361 8866 1998 6270 9021 2015 2055 3282 4808 1998 5177 7355 2044 2380 3122 5008 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.323372 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.324168 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.324948 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:24.327151 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:24.327969 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-4\n",
      "I1113 12:48:24.328800 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 24794 2015 8096 1005 1055 2567 23161 18917 2082 13108 1010 3189 2758 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.329646 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.330479 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:24.331258 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0']\n",
      "I1113 12:48:24.714738 47186697148864 <ipython-input-14-982f86686519>:19] ***** Running evaluation  *****\n",
      "I1113 12:48:24.715565 47186697148864 <ipython-input-14-982f86686519>:20]   Num examples = 258\n",
      "I1113 12:48:24.716437 47186697148864 <ipython-input-14-982f86686519>:21]   Batch size = 8\n",
      "Evaluating: 100%|██████████| 33/33 [00:01<00:00, 24.23it/s]\n",
      "W1113 12:48:26.154540 47186697148864 <ipython-input-16-f7769f312fc9>:114] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "I1113 12:48:26.229578 47186697148864 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1113 12:48:26.231179 47186697148864 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1113 12:48:26.306360 47186697148864 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape:  (258, 9)\n",
      "out label ids:  (258, 9)\n",
      "[[0.05071707 0.15887439 0.17622653 0.12818035 0.7663562  0.10549534\n",
      "  0.11570404 0.04346367 0.04263725]\n",
      " [0.06103522 0.1875369  0.15222426 0.3282678  0.11952296 0.6371188\n",
      "  0.07829299 0.11612374 0.03737324]\n",
      " [0.06974523 0.1036577  0.18933971 0.7974407  0.15384798 0.12816565\n",
      "  0.10727964 0.17298998 0.06850657]\n",
      " [0.09952114 0.19776411 0.26653484 0.9105971  0.13811693 0.17776345\n",
      "  0.17279527 0.15161653 0.11436763]\n",
      " [0.05130332 0.09010521 0.2675132  0.8087362  0.35247514 0.1736913\n",
      "  0.06896851 0.15560643 0.07730091]]\n",
      "[[0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]]\n",
      "['--model_type', 'bertmultilabel', '--data_dir', 'dataset/4', '--task_name', 'frame', '--model_name_or_path', 'bert-base-uncased', '--output_dir', '/projectnb/llamagrp/feyzanb/bert_output_uncased/4', '--cache_dir', '/projectnb/llamagrp/feyzanb/.cache/newsframing/english/4', '--max_seq_length', '128', '--do_eval', '--do_lower_case', '--per_gpu_train_batch_size', '4', '--learning_rate', '2e-5', '--num_train_epochs', '10.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1113 12:48:26.449553 47186697148864 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I1113 12:48:29.648097 47186697148864 modeling_utils.py:405] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1113 12:48:29.649183 47186697148864 modeling_utils.py:408] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1113 12:48:29.651607 47186697148864 <ipython-input-16-f7769f312fc9>:148] Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='/projectnb/llamagrp/feyzanb/.cache/newsframing/english/4', config_name='', data_dir='dataset/4', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', german=False, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bertmultilabel', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='/projectnb/llamagrp/feyzanb/bert_output_uncased/4', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=500, seed=42, server_ip='', server_port='', task_name='frame', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "I1113 12:48:29.746172 47186697148864 tokenization_utils.py:306] Model name '/projectnb/llamagrp/feyzanb/bert_output_uncased/4' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming '/projectnb/llamagrp/feyzanb/bert_output_uncased/4' is a path or url to a directory containing tokenizer files.\n",
      "I1113 12:48:29.748017 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/4/vocab.txt\n",
      "I1113 12:48:29.748769 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/4/added_tokens.json\n",
      "I1113 12:48:29.749554 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/4/special_tokens_map.json\n",
      "I1113 12:48:29.750348 47186697148864 tokenization_utils.py:370] loading file /projectnb/llamagrp/feyzanb/bert_output_uncased/4/tokenizer_config.json\n",
      "I1113 12:48:29.968278 47186697148864 <ipython-input-16-f7769f312fc9>:196] Evaluate the following checkpoints: ['/projectnb/llamagrp/feyzanb/bert_output_uncased/4']\n",
      "I1113 12:48:29.969979 47186697148864 configuration_utils.py:148] loading configuration file /projectnb/llamagrp/feyzanb/bert_output_uncased/4/config.json\n",
      "I1113 12:48:29.983979 47186697148864 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1113 12:48:29.985771 47186697148864 modeling_utils.py:334] loading weights file /projectnb/llamagrp/feyzanb/bert_output_uncased/4/pytorch_model.bin\n",
      "I1113 12:48:34.081444 47186697148864 <ipython-input-15-78cf35b18f6f>:17] Creating features from dataset file at dataset/4\n",
      "I1113 12:48:34.086281 47186697148864 <ipython-input-10-f72b0bac0eba>:48] Writing example 0\n",
      "I1113 12:48:34.088682 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:34.089520 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-0\n",
      "I1113 12:48:34.090372 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 28376 3464 1997 5869 7136 3742 13108 2000 2022 2921 1999 3647 12816 3482 1010 2567 2758 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.091250 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.092058 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.092909 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0']\n",
      "I1113 12:48:34.095390 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:34.096264 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-1\n",
      "I1113 12:48:34.097076 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 2380 3122 2082 5008 8343 24794 2015 8096 7282 21783 1010 5870 2096 1999 7173 1010 8089 3189 2758 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.097942 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.098788 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.099558 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:34.101778 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:34.102592 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-2\n",
      "I1113 12:48:34.103429 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 2047 8839 2375 2109 2000 2562 2082 5008 5436 8343 2013 2893 3282 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.104303 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1113 12:48:34.105190 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.106002 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:34.108012 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:34.108824 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-3\n",
      "I1113 12:48:34.109685 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 2070 2359 5008 8343 20951 5462 1999 2355 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.110512 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.111328 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.112102 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:34.114351 47186697148864 <ipython-input-10-f72b0bac0eba>:93] *** Example ***\n",
      "I1113 12:48:34.115157 47186697148864 <ipython-input-10-f72b0bac0eba>:94] guid: dev-4\n",
      "I1113 12:48:34.115997 47186697148864 <ipython-input-10-f72b0bac0eba>:95] input_ids: 101 2054 1996 8495 2354 2055 1996 5496 3516 2082 13108 1516 1998 2043 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.116831 47186697148864 <ipython-input-10-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.117661 47186697148864 <ipython-input-10-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1113 12:48:34.118457 47186697148864 <ipython-input-10-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1113 12:48:34.460750 47186697148864 <ipython-input-14-982f86686519>:19] ***** Running evaluation  *****\n",
      "I1113 12:48:34.461555 47186697148864 <ipython-input-14-982f86686519>:20]   Num examples = 257\n",
      "I1113 12:48:34.462405 47186697148864 <ipython-input-14-982f86686519>:21]   Batch size = 8\n",
      "Evaluating: 100%|██████████| 33/33 [00:01<00:00, 24.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape:  (257, 9)\n",
      "out label ids:  (257, 9)\n",
      "[[0.03954358 0.20285709 0.11329707 0.06202652 0.08669348 0.14905502\n",
      "  0.46971983 0.03170887 0.04327589]\n",
      " [0.06211288 0.09912343 0.22226913 0.82286745 0.2353874  0.11689589\n",
      "  0.11265853 0.12917158 0.06289471]\n",
      " [0.06035551 0.27531752 0.1449432  0.36705682 0.5813159  0.10403158\n",
      "  0.05289694 0.03925006 0.04388687]\n",
      " [0.10840052 0.25734016 0.20292307 0.8477822  0.07533127 0.21040834\n",
      "  0.10551006 0.06184076 0.09199462]\n",
      " [0.0406174  0.08113878 0.1519881  0.24726449 0.656458   0.12212618\n",
      "  0.06828822 0.09384947 0.05186936]]\n",
      "[[0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # train and test for fold i\n",
    "    ARGS[7] = \"bert-base-uncased\"\n",
    "    ARGS[3] = \"dataset/\"+str(i)\n",
    "    # output for fold i\n",
    "    ARGS[9] = \"/projectnb/llamagrp/feyzanb/bert_output_uncased/\" + str(i)\n",
    "    # cache folder for fold i\n",
    "    ARGS[11] = \"/projectnb/llamagrp/feyzanb/.cache/newsframing/english/\" + str(i)\n",
    "    print(ARGS)\n",
    "    results_folds[i] = main()\n",
    "#     print(results_folds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"english_focal_loss.pkl\",\"wb\")\n",
    "pickle.dump(results_folds,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_in = open(\"multiclass_multilingual_folds.pkl\",\"wb\")\n",
    "pickle.dump(results_folds,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7122da9ee6c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_folds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_multi = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1030 00:41:40.554017 47434470365632 <ipython-input-25-6fc69c447052>:112] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "I1030 00:41:40.643097 47434470365632 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.83b0fa3d7f1ac0e113ad300189a938c6f14d0588a4200f30eef109d0a047c484\n",
      "I1030 00:41:40.644619 47434470365632 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "I1030 00:41:40.725575 47434470365632 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--model_type', 'bertmultilabel', '--data_dir', 'dataset/0', '--task_name', 'frame', '--model_name_or_path', 'bert-base-multilingual-cased', '--output_dir', '/projectnb/llamagrp/feyzanb/bert_output_multilingual_cased/0', '--cache_dir', '/projectnb/llamagrp/feyzanb/.cache/newsframing/multilingual/0', '--max_seq_length', '128', '--do_eval', '--do_lower_case', '--per_gpu_train_batch_size', '4', '--learning_rate', '2e-5', '--num_train_epochs', '10.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 00:41:41.118432 47434470365632 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
      "I1030 00:41:45.770072 47434470365632 modeling_utils.py:405] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1030 00:41:45.771268 47434470365632 modeling_utils.py:408] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1030 00:41:45.773847 47434470365632 <ipython-input-25-6fc69c447052>:146] Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='/projectnb/llamagrp/feyzanb/.cache/newsframing/multilingual/0', config_name='', data_dir='dataset/0', device=device(type='cuda', index=1), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-multilingual-cased', model_type='bertmultilabel', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='/projectnb/llamagrp/feyzanb/bert_output_multilingual_cased/0', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=50, seed=42, server_ip='', server_port='', task_name='frame', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.device cuda:1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-59e9331fd1fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mARGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/projectnb/llamagrp/feyzanb/.cache/newsframing/multilingual/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresults_multi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_multi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-6fc69c447052>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     model.set_inverse_normed_freqs(args, \n\u001b[0;32m--> 149\u001b[0;31m                     processor.get_inverse_normed_freqs(args.data_dir)) \n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-64a5427a0ad6>\u001b[0m in \u001b[0;36mset_inverse_normed_freqs\u001b[0;34m(self, args, inverse_normed_freqs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_inverse_normed_freqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_normed_freqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_normed_freqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minverse_normed_freqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#         print(\"Inverse Normed Freqs after set: \", self.inverse_normed_freqs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal"
     ]
    }
   ],
   "source": [
    "# multilingual cased training 5-folds\n",
    "for i in range(5):\n",
    "    ARGS[3] = \"dataset/\" + str(i) # train and test for fold i\n",
    "    ARGS[9] = \"/projectnb/llamagrp/feyzanb/bert_output_multilingual_cased/\" + str(i) # output for fold i\n",
    "    ARGS[11] = \"/projectnb/llamagrp/feyzanb/.cache/newsframing/multilingual/\" + str(i)\n",
    "    print(ARGS)\n",
    "    results_multi[i] = main()\n",
    "    print(results_multi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.arange(4).reshape((-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"random_pickle.pkl\",\"wb\")\n",
    "pickle.dump(a,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"random_pickle.pkl\",\"rb\")\n",
    "results = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "auc_                      0.940406\n",
       "exact_match_              0.674049\n",
       "exact_match_multiple_     0.408988\n",
       "f1_macro_                 0.745567\n",
       "f1_micro_                 0.800864\n",
       "f1_weighted_              0.793502\n",
       "hamming_                  0.052956\n",
       "number_multiple_         63.800000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).transpose().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_english = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1103 19:36:55.259245 47239948470720 <ipython-input-57-09309c0e52c9>:112] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "I1103 19:36:55.344631 47239948470720 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1103 19:36:55.346837 47239948470720 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1103 19:36:55.436037 47239948470720 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--model_type', 'bertmultilabel', '--data_dir', 'dataset/0', '--task_name', 'frame', '--model_name_or_path', 'bert-base-uncased', '--output_dir', '/projectnb/llamagrp/feyzanb/bert_output_uncased/0', '--cache_dir', '/projectnb/llamagrp/feyzanb/.cache/newsframing/english/0', '--max_seq_length', '128', '--do_train', '--do_eval', '--do_lower_case', '--per_gpu_train_batch_size', '4', '--learning_rate', '2e-5', '--num_train_epochs', '10.0', '--overwrite_output_dir', '--overwrite_cache']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1103 19:36:55.575359 47239948470720 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-0fb265e17e7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mARGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/projectnb/llamagrp/feyzanb/.cache/newsframing/english/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresults_english\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_english\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-09309c0e52c9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m     model = model_class.from_pretrained(args.model_name_or_path, \n\u001b[1;32m    137\u001b[0m                                         \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.ckpt'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                                         config=config)\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_rank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mmissing_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.1/install/3.7/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.1/install/3.7/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# only if offset is zero we can attempt the legacy tar file loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlegacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTarError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.1/install/3.7/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mlegacy_load\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAX_FORMAT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m                 \u001b[0mmkdtemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmpdir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.3/install/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown compression type %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1591\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"|\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.3/install/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mtaropen\u001b[0;34m(cls, name, mode, fileobj, **kwargs)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode must be 'r', 'a', 'w' or 'x'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.3/install/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, fileobj, format, tarinfo, dereference, ignore_zeros, encoding, errors, pax_headers, debug, errorlevel, copybufsize)\u001b[0m\n\u001b[1;32m   1482\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirstmember\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirstmember\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.3/install/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2287\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2288\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2289\u001b[0;31m                 \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtarfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2290\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFHeaderError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_zeros\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.3/install/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mfromtarfile\u001b[0;34m(cls, tarfile)\u001b[0m\n\u001b[1;32m   1092\u001b[0m            \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \"\"\"\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBLOCKSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mBLOCKSIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ARGS[7] = \"bert-base-uncased\"\n",
    "for i in range(5):\n",
    "    ARGS[3] = \"dataset/\" + str(i) # train and test for fold i\n",
    "    ARGS[9] = \"/projectnb/llamagrp/feyzanb/bert_output_uncased/\" + str(i) # output for fold i\n",
    "    ARGS[11] = \"/projectnb/llamagrp/feyzanb/.cache/newsframing/english/\" + str(i)\n",
    "    print(ARGS)\n",
    "    results_english[i] = main()\n",
    "    print(results_english[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>any_frame_correct_rate_</th>\n",
       "      <th>auc_</th>\n",
       "      <th>exact_match_</th>\n",
       "      <th>exact_match_multiple_</th>\n",
       "      <th>f1_macro_</th>\n",
       "      <th>f1_micro_</th>\n",
       "      <th>f1_weighted_</th>\n",
       "      <th>first_frame_acc_</th>\n",
       "      <th>hamming_</th>\n",
       "      <th>number_multiple_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.946768</td>\n",
       "      <td>0.957492</td>\n",
       "      <td>0.733840</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.813743</td>\n",
       "      <td>0.850649</td>\n",
       "      <td>0.846353</td>\n",
       "      <td>0.794677</td>\n",
       "      <td>0.038868</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950382</td>\n",
       "      <td>0.974030</td>\n",
       "      <td>0.725191</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.807073</td>\n",
       "      <td>0.853081</td>\n",
       "      <td>0.849212</td>\n",
       "      <td>0.767176</td>\n",
       "      <td>0.039440</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.969814</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.831653</td>\n",
       "      <td>0.883648</td>\n",
       "      <td>0.876895</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.031624</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.961110</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.796635</td>\n",
       "      <td>0.863124</td>\n",
       "      <td>0.855975</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.036606</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.914397</td>\n",
       "      <td>0.955323</td>\n",
       "      <td>0.727626</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.742853</td>\n",
       "      <td>0.830870</td>\n",
       "      <td>0.822908</td>\n",
       "      <td>0.754864</td>\n",
       "      <td>0.044531</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   any_frame_correct_rate_      auc_  exact_match_  exact_match_multiple_  \\\n",
       "0                 0.946768  0.957492      0.733840               0.508475   \n",
       "1                 0.950382  0.974030      0.725191               0.500000   \n",
       "2                 0.950000  0.969814      0.784615               0.628571   \n",
       "3                 0.922481  0.961110      0.736434               0.530303   \n",
       "4                 0.914397  0.955323      0.727626               0.466667   \n",
       "\n",
       "   f1_macro_  f1_micro_  f1_weighted_  first_frame_acc_  hamming_  \\\n",
       "0   0.813743   0.850649      0.846353          0.794677  0.038868   \n",
       "1   0.807073   0.853081      0.849212          0.767176  0.039440   \n",
       "2   0.831653   0.883648      0.876895          0.773077  0.031624   \n",
       "3   0.796635   0.863124      0.855975          0.779070  0.036606   \n",
       "4   0.742853   0.830870      0.822908          0.754864  0.044531   \n",
       "\n",
       "   number_multiple_  \n",
       "0              59.0  \n",
       "1              64.0  \n",
       "2              70.0  \n",
       "3              66.0  \n",
       "4              60.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_english).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9368055999999999"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.946768 + 0.950382 + 0.950000 + 0.922481 +0.914397)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7737727999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.794677 + 0.767176 + 0.773077 + 0.779070 + 0.754864)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).transpose().to_csv('results_multilingual.csv')\n",
    "pd.DataFrame(results_english).transpose().to_csv('results_english.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_multi = pd.read_csv('results_multilingual.csv')\n",
    "results_english = pd.read_csv('results_english.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                2.000000\n",
       "auc_                      0.963554\n",
       "exact_match_              0.741541\n",
       "exact_match_multiple_     0.526803\n",
       "hamming_                  0.038214\n",
       "number_multiple_         63.800000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_english.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                2.000000\n",
       "auc_                      0.940406\n",
       "exact_match_              0.674049\n",
       "exact_match_multiple_     0.408988\n",
       "hamming_                  0.052956\n",
       "number_multiple_         63.800000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_multi.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1018 11:02:21.957935 47382659590592 <ipython-input-15-fb4439387059>:110] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "I1018 11:02:22.181343 47382659590592 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json not found in cache or force_download set to True, downloading to /scratch/90046.1.kulisgpu-pub/tmp8tx99dg2\n",
      "100%|██████████| 521/521 [00:00<00:00, 371764.61B/s]\n",
      "I1018 11:02:22.299580 47382659590592 file_utils.py:309] copying /scratch/90046.1.kulisgpu-pub/tmp8tx99dg2 to cache at /usr4/cs591/akyurek/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.83b0fa3d7f1ac0e113ad300189a938c6f14d0588a4200f30eef109d0a047c484\n",
      "I1018 11:02:22.305373 47382659590592 file_utils.py:313] creating metadata file for /usr4/cs591/akyurek/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.83b0fa3d7f1ac0e113ad300189a938c6f14d0588a4200f30eef109d0a047c484\n",
      "I1018 11:02:22.307822 47382659590592 file_utils.py:322] removing temp file /scratch/90046.1.kulisgpu-pub/tmp8tx99dg2\n",
      "I1018 11:02:22.308762 47382659590592 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.83b0fa3d7f1ac0e113ad300189a938c6f14d0588a4200f30eef109d0a047c484\n",
      "I1018 11:02:22.310257 47382659590592 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "I1018 11:02:22.392716 47382659590592 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt not found in cache or force_download set to True, downloading to /scratch/90046.1.kulisgpu-pub/tmpbqq4j_iw\n",
      "100%|██████████| 995526/995526 [00:00<00:00, 12290105.27B/s]\n",
      "I1018 11:02:22.569598 47382659590592 file_utils.py:309] copying /scratch/90046.1.kulisgpu-pub/tmpbqq4j_iw to cache at /usr4/cs591/akyurek/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "I1018 11:02:22.576519 47382659590592 file_utils.py:313] creating metadata file for /usr4/cs591/akyurek/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "I1018 11:02:22.579691 47382659590592 file_utils.py:322] removing temp file /scratch/90046.1.kulisgpu-pub/tmpbqq4j_iw\n",
      "I1018 11:02:22.580908 47382659590592 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "I1018 11:02:22.981390 47382659590592 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin not found in cache or force_download set to True, downloading to /scratch/90046.1.kulisgpu-pub/tmpq4fj0pc5\n",
      "100%|██████████| 714314041/714314041 [00:20<00:00, 34413920.82B/s]\n",
      "I1018 11:02:43.898494 47382659590592 file_utils.py:309] copying /scratch/90046.1.kulisgpu-pub/tmpq4fj0pc5 to cache at /usr4/cs591/akyurek/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
      "I1018 11:02:45.196152 47382659590592 file_utils.py:313] creating metadata file for /usr4/cs591/akyurek/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
      "I1018 11:02:45.199032 47382659590592 file_utils.py:322] removing temp file /scratch/90046.1.kulisgpu-pub/tmpq4fj0pc5\n",
      "I1018 11:02:45.318395 47382659590592 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
      "I1018 11:02:50.760751 47382659590592 modeling_utils.py:405] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1018 11:02:50.763794 47382659590592 modeling_utils.py:408] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1018 11:02:56.807522 47382659590592 <ipython-input-15-fb4439387059>:141] Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='/projectnb/llamagrp/feyzanb', config_name='', data_dir='dataset/0', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-multilingual-cased', model_type='bertmultilabel', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='bert_output_multilingual', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=50, seed=42, server_ip='', server_port='', task_name='frame', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "I1018 11:02:56.811898 47382659590592 <ipython-input-14-5385282ede45>:18] Creating features from dataset file at dataset/0\n",
      "I1018 11:02:56.945600 47382659590592 <ipython-input-9-f72b0bac0eba>:48] Writing example 0\n",
      "I1018 11:02:56.948592 47382659590592 <ipython-input-9-f72b0bac0eba>:93] *** Example ***\n",
      "I1018 11:02:56.949722 47382659590592 <ipython-input-9-f72b0bac0eba>:94] guid: train-0\n",
      "I1018 11:02:56.950698 47382659590592 <ipython-input-9-f72b0bac0eba>:95] input_ids: 101 171 56318 11912 19602 10108 10285 108193 10403 22038 53839 10165 10114 10347 26546 10106 43966 10104 106185 21509 117 15739 22153 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.951569 47382659590592 <ipython-input-9-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.952466 47382659590592 <ipython-input-9-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.953258 47382659590592 <ipython-input-9-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1018 11:02:56.955465 47382659590592 <ipython-input-9-f72b0bac0eba>:93] *** Example ***\n",
      "I1018 11:02:56.956290 47382659590592 <ipython-input-9-f72b0bac0eba>:94] guid: train-1\n",
      "I1018 11:02:56.957114 47382659590592 <ipython-input-9-f72b0bac0eba>:95] input_ids: 101 53866 11726 53839 10165 169 58285 10162 10406 11129 10169 15263 10198 110327 28841 10562 45169 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.957989 47382659590592 <ipython-input-9-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.958798 47382659590592 <ipython-input-9-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.959616 47382659590592 <ipython-input-9-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '1.0', '0.0', '0.0', '0.0']\n",
      "I1018 11:02:56.962018 47382659590592 <ipython-input-9-f72b0bac0eba>:93] *** Example ***\n",
      "I1018 11:02:56.962862 47382659590592 <ipython-input-9-f72b0bac0eba>:94] guid: train-2\n",
      "I1018 11:02:56.963686 47382659590592 <ipython-input-9-f72b0bac0eba>:95] input_ids: 101 16719 17518 46484 33003 37303 10108 56157 15263 10198 110327 28841 10562 81050 20648 30297 10107 10472 56044 10114 31881 31128 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.964532 47382659590592 <ipython-input-9-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.965359 47382659590592 <ipython-input-9-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.966141 47382659590592 <ipython-input-9-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0']\n",
      "I1018 11:02:56.968404 47382659590592 <ipython-input-9-f72b0bac0eba>:93] *** Example ***\n",
      "I1018 11:02:56.969232 47382659590592 <ipython-input-9-f72b0bac0eba>:94] guid: train-3\n",
      "I1018 11:02:56.970075 47382659590592 <ipython-input-9-f72b0bac0eba>:95] input_ids: 101 30518 31025 28229 16470 38253 10169 102363 45749 103927 23103 22978 11846 11393 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.970923 47382659590592 <ipython-input-9-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.971765 47382659590592 <ipython-input-9-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.972546 47382659590592 <ipython-input-9-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1018 11:02:56.974868 47382659590592 <ipython-input-9-f72b0bac0eba>:93] *** Example ***\n",
      "I1018 11:02:56.975661 47382659590592 <ipython-input-9-f72b0bac0eba>:94] guid: train-4\n",
      "I1018 11:02:56.976487 47382659590592 <ipython-input-9-f72b0bac0eba>:95] input_ids: 101 50007 131 11795 69338 58945 11897 11393 53839 10165 17339 13149 16219 10169 14025 117 26342 10111 31199 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.977344 47382659590592 <ipython-input-9-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.978158 47382659590592 <ipython-input-9-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:02:56.978955 47382659590592 <ipython-input-9-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '1.0', '0.0', '0.0', '0.0']\n",
      "I1018 11:02:58.452970 47382659590592 <ipython-input-14-5385282ede45>:34] Saving features into cached file dataset/0/cached_train_bert-base-multilingual-cased_128_frame\n",
      "I1018 11:02:58.963391 47382659590592 <ipython-input-11-ce0a3a7e9c33>:42] ***** Running training *****\n",
      "I1018 11:02:58.964552 47382659590592 <ipython-input-11-ce0a3a7e9c33>:43]   Num examples = 1037\n",
      "I1018 11:02:58.965730 47382659590592 <ipython-input-11-ce0a3a7e9c33>:44]   Num Epochs = 10\n",
      "I1018 11:02:58.966770 47382659590592 <ipython-input-11-ce0a3a7e9c33>:45]   Instantaneous batch size per GPU = 4\n",
      "I1018 11:02:58.967590 47382659590592 <ipython-input-11-ce0a3a7e9c33>:47]   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "I1018 11:02:58.968402 47382659590592 <ipython-input-11-ce0a3a7e9c33>:48]   Gradient Accumulation steps = 1\n",
      "I1018 11:02:58.969225 47382659590592 <ipython-input-11-ce0a3a7e9c33>:49]   Total optimization steps = 2600\n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:21,  3.19it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:21,  3.15it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:21,  3.14it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:21,  3.12it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:21,  3.11it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:21,  3.10it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:21,  3.10it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:21,  3.09it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:21,  3.09it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:21,  3.08it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:20,  3.09it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:20,  3.09it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:20,  3.09it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:19,  3.08it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:19,  3.09it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:19,  3.09it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:18,  3.08it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:18,  3.08it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:06<01:18,  3.09it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:17,  3.09it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:17,  3.08it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:07<01:17,  3.08it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:16,  3.08it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:16,  3.09it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:08<01:16,  3.09it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:08<01:15,  3.08it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:14,  3.11it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:09<01:13,  3.14it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:09<01:13,  3.12it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:09<01:13,  3.14it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:10<01:13,  3.13it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:10<01:12,  3.14it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:10<01:12,  3.12it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:12,  3.11it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:11<01:12,  3.11it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:11<01:12,  3.10it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:11<01:11,  3.12it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:12<01:11,  3.11it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:12<01:11,  3.10it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:12<01:11,  3.10it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:13<01:10,  3.13it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:13<01:09,  3.14it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:13<01:09,  3.13it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:14<01:09,  3.11it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:14<01:09,  3.10it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:14<01:09,  3.10it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:15<01:08,  3.09it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:15<01:08,  3.08it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:15<01:08,  3.07it/s]\u001b[AI1018 11:03:15.112405 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-50/config.json\n",
      "I1018 11:03:16.282306 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-50/pytorch_model.bin\n",
      "I1018 11:03:16.286085 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-50\n",
      "\n",
      "Iteration:  19%|█▉        | 50/260 [00:17<02:22,  1.47it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:58,  1.77it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:42,  2.04it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:18<01:30,  2.29it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:23,  2.48it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:17,  2.65it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:19<01:13,  2.79it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:10,  2.89it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:08,  2.94it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:20<01:07,  2.98it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:20<01:06,  3.01it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:04,  3.07it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:21<01:04,  3.07it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:21<01:04,  3.07it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:03,  3.07it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:22<01:02,  3.11it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:01,  3.13it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<01:01,  3.12it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:23<01:01,  3.10it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:23<01:01,  3.10it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:23<01:01,  3.09it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:24<01:01,  3.09it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:24<01:00,  3.09it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:24<01:00,  3.11it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:24<01:00,  3.10it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:25<00:59,  3.09it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:25<00:59,  3.10it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:25<00:59,  3.10it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:26<00:58,  3.12it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:26<00:57,  3.13it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:26<00:57,  3.14it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:27<00:57,  3.12it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:27<00:57,  3.11it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:27<00:57,  3.10it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:28<00:56,  3.10it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:28<00:56,  3.12it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:28<00:55,  3.13it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:29<00:55,  3.12it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:29<00:55,  3.10it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:29<00:55,  3.10it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:30<00:54,  3.10it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:30<00:54,  3.09it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:30<00:54,  3.09it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:31<00:54,  3.09it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:31<00:53,  3.09it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:31<00:53,  3.09it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:32<00:53,  3.09it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:32<00:52,  3.12it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:32<00:52,  3.11it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:33<00:51,  3.11it/s]\u001b[AI1018 11:03:32.341825 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-100/config.json\n",
      "I1018 11:03:33.481915 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-100/pytorch_model.bin\n",
      "I1018 11:03:33.485365 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-100\n",
      "\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<01:46,  1.50it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<01:29,  1.78it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:35<01:17,  2.04it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:35<01:08,  2.29it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<01:02,  2.48it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:36<00:58,  2.63it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:36<00:55,  2.75it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:53,  2.85it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:37<00:52,  2.92it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:37<00:50,  2.97it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<00:50,  3.00it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:38<00:48,  3.05it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:38<00:48,  3.07it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<00:47,  3.08it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:39<00:47,  3.08it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:39<00:46,  3.10it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:46,  3.10it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:39<00:46,  3.10it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:40<00:45,  3.10it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:45,  3.09it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:40<00:45,  3.09it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:41<00:44,  3.09it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:41<00:44,  3.09it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:41<00:44,  3.09it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:42<00:43,  3.11it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:42<00:43,  3.10it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:42<00:43,  3.10it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:43<00:42,  3.10it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:43<00:42,  3.09it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:43<00:42,  3.09it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:44<00:41,  3.10it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:44<00:41,  3.10it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:44<00:41,  3.09it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:45<00:41,  3.09it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:45<00:40,  3.09it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:45<00:40,  3.10it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:46<00:40,  3.09it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:46<00:39,  3.09it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:46<00:39,  3.09it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:47<00:39,  3.09it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:47<00:38,  3.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  54%|█████▍    | 141/260 [00:47<00:38,  3.08it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:48<00:38,  3.09it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:48<00:37,  3.09it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:48<00:37,  3.09it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:49<00:36,  3.11it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:49<00:36,  3.10it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:49<00:36,  3.10it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:49<00:36,  3.10it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:50<00:35,  3.09it/s]\u001b[AI1018 11:03:49.628221 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-150/config.json\n",
      "I1018 11:03:50.745861 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-150/pytorch_model.bin\n",
      "I1018 11:03:50.749659 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-150\n",
      "\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<01:12,  1.51it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:52<01:00,  1.79it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:52<00:52,  2.05it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:46,  2.28it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:53<00:42,  2.47it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:53<00:39,  2.63it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:53<00:37,  2.76it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:54<00:35,  2.87it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:54<00:34,  2.93it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:54<00:33,  2.97it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:54<00:33,  3.01it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:55<00:32,  3.04it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:55<00:32,  3.05it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:31,  3.05it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:56<00:31,  3.07it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:56<00:30,  3.08it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:30,  3.08it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:57<00:30,  3.08it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:57<00:29,  3.09it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:29,  3.09it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:58<00:29,  3.09it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:58<00:28,  3.11it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:58<00:28,  3.13it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:59<00:27,  3.11it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:59<00:27,  3.11it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:59<00:27,  3.11it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [01:00<00:27,  3.10it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [01:00<00:26,  3.09it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:00<00:26,  3.10it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:01<00:26,  3.10it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:01<00:25,  3.09it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:01<00:25,  3.09it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:02<00:25,  3.09it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:02<00:24,  3.09it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:02<00:24,  3.09it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:03<00:24,  3.09it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:03<00:23,  3.09it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:03<00:23,  3.10it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:04<00:23,  3.09it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:04<00:22,  3.09it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:04<00:22,  3.09it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:05<00:22,  3.10it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:05<00:22,  3.09it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:05<00:21,  3.09it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:05<00:21,  3.08it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:06<00:21,  3.09it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:06<00:20,  3.09it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:06<00:20,  3.08it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:07<00:20,  3.09it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:07<00:19,  3.09it/s]\u001b[AI1018 11:04:06.904515 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-200/config.json\n",
      "I1018 11:04:08.016992 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-200/pytorch_model.bin\n",
      "I1018 11:04:08.020659 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-200\n",
      "\n",
      "Iteration:  77%|███████▋  | 200/260 [01:09<00:39,  1.51it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:09<00:32,  1.80it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:09<00:28,  2.06it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:10<00:24,  2.29it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:10<00:22,  2.48it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:10<00:20,  2.63it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:19,  2.76it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:11<00:18,  2.85it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:11<00:17,  2.91it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:11<00:17,  2.96it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:12<00:16,  3.00it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:12<00:16,  3.03it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:12<00:15,  3.04it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:13<00:15,  3.05it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:13<00:14,  3.07it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:13<00:14,  3.08it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:14<00:14,  3.07it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:14<00:13,  3.08it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:14<00:13,  3.09it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:15<00:13,  3.09it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:15<00:12,  3.09it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:15<00:12,  3.08it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:16<00:12,  3.09it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:16<00:11,  3.09it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:16<00:11,  3.09it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:17<00:11,  3.09it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:17<00:10,  3.09it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:17<00:10,  3.10it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:18<00:10,  3.09it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:18<00:10,  3.09it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:18<00:09,  3.09it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:19<00:09,  3.09it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:19<00:09,  3.09it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:19<00:08,  3.09it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:20<00:08,  3.09it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:20<00:08,  3.09it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:20<00:07,  3.09it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:21<00:07,  3.09it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:21<00:07,  3.10it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:21<00:06,  3.10it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:21<00:06,  3.09it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:22<00:06,  3.09it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:22<00:05,  3.10it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:22<00:05,  3.10it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:23<00:05,  3.12it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:23<00:04,  3.11it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:23<00:04,  3.10it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:24<00:04,  3.13it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:24<00:03,  3.12it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:24<00:03,  3.12it/s]\u001b[AI1018 11:04:24.174451 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-250/config.json\n",
      "I1018 11:04:25.288547 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-250/pytorch_model.bin\n",
      "I1018 11:04:25.292983 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  96%|█████████▌| 250/260 [01:26<00:06,  1.52it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:26<00:05,  1.80it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:26<00:03,  2.06it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:27<00:03,  2.29it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:27<00:02,  2.48it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:27<00:01,  2.64it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:28<00:01,  2.76it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:28<00:01,  2.86it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:28<00:00,  2.92it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:29<00:00,  2.97it/s]\u001b[A\n",
      "Epoch:  10%|█         | 1/10 [01:29<13:24, 89.43s/it]35it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:22,  3.14it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:22,  3.13it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:22,  3.12it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:22,  3.11it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:22,  3.10it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:21,  3.10it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:21,  3.10it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:21,  3.09it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:21,  3.09it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:20,  3.09it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:20,  3.10it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:20,  3.09it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:20,  3.09it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:19,  3.09it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:19,  3.09it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:19,  3.09it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:18,  3.08it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:18,  3.09it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:06<01:17,  3.09it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:17,  3.09it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:17,  3.09it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:07<01:17,  3.09it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:16,  3.09it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:16,  3.09it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:08<01:16,  3.09it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:08<01:15,  3.09it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:15,  3.10it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:09<01:15,  3.09it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:09<01:14,  3.09it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:09<01:14,  3.09it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:10<01:13,  3.10it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:10<01:13,  3.09it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:10<01:13,  3.09it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:13,  3.09it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:11<01:12,  3.10it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:11<01:12,  3.09it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:11<01:12,  3.09it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:12<01:11,  3.09it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:12<01:10,  3.12it/s]\u001b[AI1018 11:04:41.337057 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-300/config.json\n",
      "I1018 11:04:42.445881 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-300/pytorch_model.bin\n",
      "I1018 11:04:42.449723 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-300\n",
      "\n",
      "Iteration:  15%|█▌        | 40/260 [00:14<02:24,  1.52it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:14<02:01,  1.80it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:45,  2.06it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:15<01:34,  2.29it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:15<01:26,  2.49it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:21,  2.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:17,  2.76it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:16<01:14,  2.85it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:12,  2.92it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:11,  2.97it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:17<01:09,  3.00it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:08,  3.03it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:08,  3.06it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:18<01:07,  3.06it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:07,  3.07it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:05,  3.11it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:19<01:05,  3.11it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:05,  3.11it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:05,  3.10it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:20<01:04,  3.10it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:20<01:04,  3.10it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:04,  3.10it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:21<01:03,  3.10it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:21<01:03,  3.09it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:03,  3.10it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:22<01:02,  3.10it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:02,  3.09it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<01:02,  3.09it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:23<01:02,  3.09it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:23<01:01,  3.09it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:23<01:01,  3.09it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:24<01:01,  3.09it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:24<01:00,  3.09it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:24<01:00,  3.10it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:25<01:00,  3.09it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:25<00:59,  3.09it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:25<00:59,  3.09it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:25<00:59,  3.10it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:26<00:58,  3.09it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:26<00:58,  3.09it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:26<00:58,  3.09it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:27<00:57,  3.10it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:27<00:57,  3.09it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:27<00:57,  3.09it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:28<00:56,  3.09it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:28<00:56,  3.09it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:28<00:56,  3.09it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:29<00:56,  3.09it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:29<00:55,  3.09it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:29<00:55,  3.10it/s]\u001b[AI1018 11:04:58.601947 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-350/config.json\n",
      "I1018 11:04:59.705099 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-350/pytorch_model.bin\n",
      "I1018 11:04:59.709805 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-350\n",
      "\n",
      "Iteration:  35%|███▍      | 90/260 [00:31<01:51,  1.52it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:31<01:33,  1.80it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<01:21,  2.06it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:32<01:12,  2.29it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:32<01:06,  2.48it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:32<01:02,  2.64it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:33<00:59,  2.76it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:33<00:57,  2.86it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:33<00:55,  2.92it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:34<00:54,  2.97it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<00:53,  3.01it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<00:52,  3.04it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:35<00:51,  3.05it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:35<00:51,  3.06it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<00:50,  3.07it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:36<00:49,  3.11it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:36<00:49,  3.11it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:49,  3.10it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:37<00:49,  3.09it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:37<00:48,  3.10it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<00:48,  3.10it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:38<00:48,  3.09it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:38<00:47,  3.09it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<00:47,  3.09it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:39<00:47,  3.10it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:39<00:46,  3.09it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:46,  3.09it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:40<00:46,  3.09it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:40<00:45,  3.09it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:45,  3.09it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:40<00:45,  3.09it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:41<00:44,  3.09it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:41<00:44,  3.09it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:41<00:44,  3.09it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:42<00:44,  3.09it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:42<00:43,  3.09it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:42<00:43,  3.10it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:43<00:43,  3.09it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:43<00:42,  3.09it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:43<00:42,  3.09it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:44<00:41,  3.10it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:44<00:41,  3.10it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:44<00:41,  3.09it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:45<00:41,  3.10it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:45<00:40,  3.10it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:45<00:40,  3.09it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:46<00:40,  3.09it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:46<00:39,  3.09it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:46<00:39,  3.10it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:47<00:39,  3.09it/s]\u001b[AI1018 11:05:15.863970 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-400/config.json\n",
      "I1018 11:05:16.966936 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-400/pytorch_model.bin\n",
      "I1018 11:05:16.970528 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-400\n",
      "\n",
      "Iteration:  54%|█████▍    | 140/260 [00:48<01:18,  1.52it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:48<01:05,  1.80it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:49<00:57,  2.06it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:49<00:51,  2.29it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:49<00:46,  2.48it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:50<00:43,  2.64it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:50<00:41,  2.76it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:50<00:39,  2.85it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:51<00:38,  2.92it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:51<00:37,  3.00it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<00:36,  3.03it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:52<00:35,  3.05it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:52<00:35,  3.06it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:34,  3.07it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:53<00:34,  3.08it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:53<00:34,  3.08it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:53<00:33,  3.08it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:54<00:33,  3.08it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:54<00:33,  3.09it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:54<00:32,  3.09it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:55<00:32,  3.09it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:55<00:32,  3.09it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:55<00:31,  3.09it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:31,  3.09it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:56<00:31,  3.09it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:56<00:30,  3.09it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:30,  3.09it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:57<00:30,  3.09it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:57<00:29,  3.09it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:29,  3.09it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:58<00:29,  3.09it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:58<00:28,  3.09it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:58<00:28,  3.09it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:59<00:28,  3.09it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:59<00:27,  3.09it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:59<00:27,  3.09it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [01:00<00:26,  3.12it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [01:00<00:26,  3.13it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:00<00:26,  3.15it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:01<00:25,  3.13it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:01<00:25,  3.11it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:01<00:25,  3.11it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:02<00:24,  3.14it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:02<00:24,  3.13it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:02<00:24,  3.11it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:03<00:23,  3.13it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:03<00:23,  3.12it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:03<00:23,  3.11it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:04<00:23,  3.11it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:04<00:22,  3.10it/s]\u001b[AI1018 11:05:33.086010 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-450/config.json\n",
      "I1018 11:05:34.197359 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-450/pytorch_model.bin\n",
      "I1018 11:05:34.200429 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-450\n",
      "\n",
      "Iteration:  73%|███████▎  | 190/260 [01:05<00:46,  1.52it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:06<00:38,  1.80it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:06<00:32,  2.06it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:06<00:29,  2.29it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:07<00:26,  2.50it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:07<00:24,  2.65it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:07<00:23,  2.77it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:08<00:21,  2.86it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:08<00:21,  2.93it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:08<00:20,  2.97it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:09<00:19,  3.01it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:09<00:19,  3.04it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:09<00:19,  3.05it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:09<00:18,  3.06it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:10<00:18,  3.08it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:10<00:17,  3.08it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:17,  3.08it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:11<00:17,  3.08it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:11<00:16,  3.09it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:11<00:16,  3.10it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:12<00:16,  3.09it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:12<00:15,  3.09it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:12<00:15,  3.10it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:13<00:15,  3.10it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:13<00:14,  3.09it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:13<00:14,  3.09it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:14<00:14,  3.09it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:14<00:13,  3.10it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:14<00:13,  3.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  84%|████████▍ | 219/260 [01:15<00:13,  3.09it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:15<00:12,  3.09it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:15<00:12,  3.09it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:16<00:12,  3.09it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:16<00:11,  3.09it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:16<00:11,  3.09it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:17<00:11,  3.09it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:17<00:10,  3.09it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:17<00:10,  3.09it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:18<00:10,  3.09it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:18<00:10,  3.10it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:18<00:09,  3.09it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:19<00:09,  3.09it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:19<00:09,  3.09it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:19<00:08,  3.10it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:19<00:08,  3.09it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:20<00:08,  3.12it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:20<00:07,  3.10it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:20<00:07,  3.10it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:21<00:07,  3.10it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:21<00:06,  3.10it/s]\u001b[AI1018 11:05:50.335539 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-500/config.json\n",
      "I1018 11:05:51.458851 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-500/pytorch_model.bin\n",
      "I1018 11:05:51.462862 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-500\n",
      "\n",
      "Iteration:  92%|█████████▏| 240/260 [01:23<00:13,  1.51it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:23<00:10,  1.80it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:23<00:08,  2.06it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:24<00:07,  2.29it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:24<00:06,  2.48it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:24<00:05,  2.64it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:24<00:05,  2.76it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:25<00:04,  2.86it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:25<00:04,  2.92it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:25<00:03,  2.97it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:26<00:03,  3.01it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:26<00:02,  3.04it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:26<00:02,  3.08it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:27<00:02,  3.08it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:27<00:01,  3.08it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:27<00:01,  3.09it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:28<00:01,  3.09it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:28<00:00,  3.12it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:28<00:00,  3.11it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:29<00:00,  3.10it/s]\u001b[A\n",
      "Epoch:  20%|██        | 2/10 [02:58<11:55, 89.42s/it]47it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:22,  3.14it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:22,  3.13it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:21,  3.15it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:21,  3.14it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:21,  3.12it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:20,  3.14it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:21,  3.12it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:20,  3.14it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:20,  3.13it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:20,  3.12it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:19,  3.14it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:19,  3.12it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:19,  3.11it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:19,  3.11it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:18,  3.11it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:18,  3.10it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:18,  3.09it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:18,  3.10it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:06<01:17,  3.10it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:17,  3.10it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:16,  3.12it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:07<01:16,  3.11it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:16,  3.11it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:15,  3.11it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:08<01:15,  3.10it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:08<01:15,  3.09it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:15,  3.10it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:14,  3.10it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:09<01:14,  3.10it/s]\u001b[AI1018 11:06:07.442436 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-550/config.json\n",
      "I1018 11:06:08.575794 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-550/pytorch_model.bin\n",
      "I1018 11:06:08.579569 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-550\n",
      "\n",
      "Iteration:  12%|█▏        | 30/260 [00:10<02:33,  1.50it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:11<02:08,  1.79it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:11<01:51,  2.05it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:11<01:39,  2.28it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:12<01:31,  2.47it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:12<01:25,  2.63it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:12<01:21,  2.76it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:13<01:18,  2.85it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:13<01:16,  2.92it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:13<01:14,  2.97it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:14<01:13,  3.01it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:14<01:12,  3.03it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:11,  3.05it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:10,  3.07it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:15<01:09,  3.10it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:09,  3.11it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:09,  3.10it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:16<01:08,  3.09it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:08,  3.10it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:08,  3.10it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:17<01:07,  3.09it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:07,  3.09it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:07,  3.09it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:18<01:06,  3.10it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:06,  3.09it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:05,  3.11it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:19<01:05,  3.10it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:05,  3.10it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:05,  3.10it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:20<01:04,  3.10it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:20<01:04,  3.09it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:04,  3.10it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:21<01:03,  3.13it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:21<01:03,  3.12it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:02,  3.13it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:22<01:02,  3.12it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:02,  3.11it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<01:02,  3.10it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:23<01:01,  3.13it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:23<01:01,  3.13it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:23<01:01,  3.11it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:23<01:00,  3.13it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:24<01:00,  3.12it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:24<01:00,  3.11it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:24<00:59,  3.11it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:25<00:59,  3.13it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:25<00:59,  3.12it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:25<00:58,  3.10it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:26<00:58,  3.10it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:26<00:57,  3.13it/s]\u001b[AI1018 11:06:24.661431 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-600/config.json\n",
      "I1018 11:06:25.801560 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-600/pytorch_model.bin\n",
      "I1018 11:06:25.807199 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-600\n",
      "\n",
      "Iteration:  31%|███       | 80/260 [00:28<01:59,  1.50it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:28<01:40,  1.78it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:28<01:27,  2.04it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:28<01:17,  2.28it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:29<01:11,  2.47it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:29<01:06,  2.63it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:29<01:03,  2.75it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:30<01:00,  2.85it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:30<00:58,  2.92it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:30<00:57,  2.97it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:31<00:56,  3.00it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:31<00:55,  3.06it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<00:54,  3.07it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:32<00:54,  3.08it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:32<00:53,  3.08it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:32<00:53,  3.11it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:33<00:52,  3.10it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:33<00:52,  3.10it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:33<00:52,  3.10it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:34<00:52,  3.10it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<00:51,  3.09it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<00:51,  3.10it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:35<00:50,  3.13it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:35<00:50,  3.12it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<00:50,  3.11it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:36<00:50,  3.10it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:36<00:49,  3.10it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:49,  3.10it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:37<00:48,  3.12it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:37<00:48,  3.11it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<00:48,  3.10it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:37<00:48,  3.10it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:38<00:47,  3.10it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<00:47,  3.10it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:38<00:47,  3.09it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:39<00:46,  3.10it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:46,  3.10it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:39<00:46,  3.09it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:40<00:45,  3.09it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:45,  3.09it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:40<00:45,  3.10it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:41<00:44,  3.09it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:41<00:44,  3.11it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:41<00:44,  3.10it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:42<00:43,  3.10it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:42<00:43,  3.13it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:42<00:42,  3.12it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:43<00:42,  3.11it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:43<00:42,  3.13it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:43<00:42,  3.12it/s]\u001b[AI1018 11:06:41.909760 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-650/config.json\n",
      "I1018 11:06:43.065300 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-650/pytorch_model.bin\n",
      "I1018 11:06:43.070461 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-650\n",
      "\n",
      "Iteration:  50%|█████     | 130/260 [00:45<01:27,  1.49it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:45<01:12,  1.77it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:45<01:03,  2.03it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:46<00:56,  2.26it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:46<00:51,  2.46it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:46<00:47,  2.63it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:47<00:45,  2.75it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:47<00:42,  2.86it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:47<00:41,  2.93it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:48<00:40,  3.00it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:48<00:39,  3.03it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:48<00:38,  3.05it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:49<00:38,  3.06it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:49<00:38,  3.07it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:49<00:37,  3.08it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:50<00:37,  3.09it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:50<00:36,  3.09it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:50<00:36,  3.09it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:51<00:36,  3.09it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:51<00:35,  3.10it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<00:35,  3.09it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:52<00:34,  3.12it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:52<00:34,  3.13it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:34,  3.12it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:34,  3.11it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:53<00:33,  3.11it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:53<00:33,  3.10it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:53<00:33,  3.09it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:54<00:32,  3.12it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:54<00:32,  3.12it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:54<00:32,  3.12it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:55<00:31,  3.13it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:55<00:31,  3.15it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:31,  3.12it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:56<00:30,  3.11it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:56<00:30,  3.14it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:30,  3.13it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:57<00:29,  3.12it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:57<00:29,  3.11it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:29,  3.10it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:58<00:28,  3.13it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:58<00:28,  3.12it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:58<00:28,  3.12it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:59<00:27,  3.13it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:59<00:27,  3.12it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:59<00:27,  3.11it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [01:00<00:27,  3.10it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [01:00<00:26,  3.10it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:00<00:26,  3.10it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:01<00:26,  3.09it/s]\u001b[AI1018 11:06:59.147697 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-700/config.json\n",
      "I1018 11:07:00.313229 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-700/pytorch_model.bin\n",
      "I1018 11:07:00.317610 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-700\n",
      "\n",
      "Iteration:  69%|██████▉   | 180/260 [01:02<00:54,  1.48it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:02<00:44,  1.76it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  70%|███████   | 182/260 [01:03<00:38,  2.02it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:03<00:33,  2.27it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:03<00:30,  2.46it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:04<00:28,  2.63it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:04<00:26,  2.75it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:04<00:25,  2.84it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:05<00:24,  2.91it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:05<00:23,  2.97it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:05<00:23,  3.01it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:06<00:22,  3.03it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:06<00:22,  3.04it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:06<00:21,  3.06it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:07<00:21,  3.07it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:07<00:20,  3.10it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:07<00:20,  3.10it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:07<00:20,  3.09it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:08<00:20,  3.10it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:08<00:19,  3.10it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:08<00:19,  3.12it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:09<00:18,  3.11it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:09<00:18,  3.10it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:09<00:18,  3.10it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:10<00:18,  3.10it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:10<00:17,  3.10it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:17,  3.09it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:11<00:17,  3.09it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:11<00:16,  3.10it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:11<00:16,  3.09it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:12<00:16,  3.09it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:12<00:15,  3.09it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:12<00:15,  3.10it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:13<00:15,  3.09it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:13<00:14,  3.09it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:13<00:14,  3.09it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:14<00:14,  3.10it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:14<00:13,  3.09it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:14<00:13,  3.09it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:15<00:13,  3.12it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:15<00:12,  3.14it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:15<00:12,  3.13it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:16<00:12,  3.12it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:16<00:11,  3.14it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:16<00:11,  3.12it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:17<00:11,  3.11it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:17<00:10,  3.10it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:17<00:10,  3.10it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:17<00:10,  3.10it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:18<00:10,  3.09it/s]\u001b[AI1018 11:07:16.429738 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-750/config.json\n",
      "I1018 11:07:17.601023 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-750/pytorch_model.bin\n",
      "I1018 11:07:17.604279 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-750\n",
      "\n",
      "Iteration:  88%|████████▊ | 230/260 [01:19<00:20,  1.48it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:20<00:16,  1.77it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:20<00:13,  2.03it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:20<00:11,  2.26it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:21<00:10,  2.46it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:21<00:09,  2.62it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:21<00:08,  2.75it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:22<00:08,  2.84it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:22<00:07,  2.91it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:22<00:07,  2.99it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:23<00:06,  3.02it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:23<00:06,  3.07it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:23<00:05,  3.08it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:23<00:05,  3.08it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:24<00:05,  3.09it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:24<00:04,  3.09it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:24<00:04,  3.10it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:25<00:04,  3.09it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:25<00:03,  3.09it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:25<00:03,  3.10it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:26<00:03,  3.10it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:26<00:02,  3.09it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:26<00:02,  3.12it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:27<00:02,  3.11it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:27<00:01,  3.11it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:27<00:01,  3.11it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:28<00:01,  3.10it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:28<00:00,  3.10it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:28<00:00,  3.10it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:29<00:00,  3.10it/s]\u001b[A\n",
      "Epoch:  30%|███       | 3/10 [04:28<10:25, 89.40s/it]47it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:21,  3.16it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:22,  3.14it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:22,  3.12it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:22,  3.12it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:21,  3.11it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:21,  3.11it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:20,  3.13it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:20,  3.11it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:20,  3.14it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:19,  3.13it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:19,  3.12it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:19,  3.11it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:19,  3.10it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:19,  3.10it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:19,  3.10it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:18,  3.09it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:18,  3.09it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:18,  3.09it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:06<01:17,  3.12it/s]\u001b[AI1018 11:07:33.576250 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-800/config.json\n",
      "I1018 11:07:34.746663 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-800/pytorch_model.bin\n",
      "I1018 11:07:34.750140 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-800\n",
      "\n",
      "Iteration:   8%|▊         | 20/260 [00:07<02:42,  1.48it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:07<02:15,  1.76it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:08<01:56,  2.03it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:08<01:44,  2.27it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:08<01:35,  2.48it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:09<01:29,  2.64it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:09<01:24,  2.77it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:09<01:21,  2.85it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:10<01:18,  2.94it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:10<01:17,  2.98it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:10<01:15,  3.04it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:11<01:14,  3.06it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:11<01:14,  3.07it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:11<01:13,  3.08it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:12<01:13,  3.08it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:12<01:12,  3.09it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:12<01:12,  3.09it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:13<01:11,  3.12it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:13<01:11,  3.11it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:13<01:11,  3.10it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:14<01:10,  3.10it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:14<01:10,  3.10it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:10,  3.09it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:10,  3.09it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:15<01:09,  3.10it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:09,  3.10it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:09,  3.09it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:16<01:08,  3.09it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:08,  3.09it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:07,  3.12it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:17<01:07,  3.11it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:07,  3.10it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:07,  3.10it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:18<01:06,  3.09it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:06,  3.10it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:06,  3.09it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:19<01:06,  3.09it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:05,  3.09it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:04,  3.12it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:20<01:03,  3.14it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:20<01:03,  3.13it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:03,  3.12it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:21<01:03,  3.11it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:21<01:02,  3.13it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:02,  3.12it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:22<01:01,  3.15it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:01,  3.13it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<01:01,  3.14it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:23<01:01,  3.13it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:23<01:01,  3.12it/s]\u001b[AI1018 11:07:50.809288 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-850/config.json\n",
      "I1018 11:07:51.974919 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-850/pytorch_model.bin\n",
      "I1018 11:07:51.978515 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-850\n",
      "\n",
      "Iteration:  27%|██▋       | 70/260 [00:24<02:07,  1.48it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:25<01:46,  1.78it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:25<01:32,  2.04it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:25<01:22,  2.27it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:26<01:15,  2.46it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:26<01:10,  2.63it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:26<01:06,  2.77it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:27<01:03,  2.87it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:27<01:02,  2.93it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:27<01:00,  3.00it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:28<00:59,  3.05it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:28<00:58,  3.06it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:28<00:57,  3.07it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:28<00:57,  3.08it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:29<00:57,  3.08it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:29<00:56,  3.11it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:29<00:56,  3.10it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:30<00:55,  3.10it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:30<00:55,  3.10it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:30<00:54,  3.12it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:31<00:54,  3.11it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:31<00:54,  3.10it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<00:54,  3.10it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:32<00:53,  3.10it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:32<00:53,  3.10it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:32<00:52,  3.12it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:33<00:52,  3.11it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:33<00:52,  3.11it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:33<00:51,  3.13it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:34<00:51,  3.12it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<00:51,  3.11it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<00:50,  3.13it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:35<00:50,  3.12it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:35<00:50,  3.11it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<00:50,  3.11it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:36<00:49,  3.13it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:36<00:49,  3.11it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:49,  3.10it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:37<00:48,  3.10it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:37<00:48,  3.10it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<00:48,  3.12it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:37<00:47,  3.14it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:38<00:47,  3.12it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<00:47,  3.11it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:38<00:46,  3.13it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:39<00:46,  3.12it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:46,  3.12it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:39<00:45,  3.11it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:40<00:45,  3.10it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:45,  3.10it/s]\u001b[AI1018 11:08:08.016677 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-900/config.json\n",
      "I1018 11:08:09.177524 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-900/pytorch_model.bin\n",
      "I1018 11:08:09.181031 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-900\n",
      "\n",
      "Iteration:  46%|████▌     | 120/260 [00:42<01:33,  1.49it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:42<01:18,  1.78it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:42<01:07,  2.03it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:43<01:00,  2.27it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:43<00:55,  2.47it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:43<00:51,  2.63it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:43<00:48,  2.75it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:44<00:46,  2.87it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:44<00:45,  2.93it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:44<00:43,  3.00it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:45<00:42,  3.06it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:45<00:41,  3.07it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:45<00:41,  3.08it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:46<00:41,  3.09it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:46<00:40,  3.11it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:46<00:40,  3.10it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:47<00:39,  3.10it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:47<00:39,  3.10it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:47<00:39,  3.13it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:48<00:38,  3.11it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:48<00:38,  3.10it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:48<00:38,  3.10it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:49<00:38,  3.10it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:49<00:37,  3.09it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:49<00:37,  3.09it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:50<00:37,  3.09it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:50<00:36,  3.10it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:50<00:36,  3.12it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:51<00:36,  3.11it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:51<00:35,  3.10it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<00:35,  3.10it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  58%|█████▊    | 151/260 [00:51<00:35,  3.10it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:52<00:34,  3.10it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:34,  3.12it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:34,  3.11it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:53<00:33,  3.11it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:53<00:33,  3.13it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:53<00:32,  3.12it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:54<00:32,  3.11it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:54<00:32,  3.10it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:54<00:32,  3.10it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:55<00:31,  3.13it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:55<00:31,  3.12it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:31,  3.11it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:56<00:30,  3.10it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:56<00:30,  3.13it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:30,  3.12it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:57<00:29,  3.12it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:57<00:29,  3.11it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:29,  3.10it/s]\u001b[AI1018 11:08:25.238676 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-950/config.json\n",
      "I1018 11:08:26.404999 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-950/pytorch_model.bin\n",
      "I1018 11:08:26.410482 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-950\n",
      "\n",
      "Iteration:  65%|██████▌   | 170/260 [00:59<01:00,  1.49it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:59<00:50,  1.77it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:59<00:43,  2.03it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [01:00<00:38,  2.28it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [01:00<00:34,  2.47it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [01:00<00:32,  2.63it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [01:01<00:30,  2.75it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [01:01<00:29,  2.85it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:01<00:27,  2.94it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:02<00:27,  2.98it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:02<00:26,  3.01it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:02<00:26,  3.04it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:03<00:25,  3.06it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:03<00:24,  3.09it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:03<00:24,  3.09it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:04<00:24,  3.09it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:04<00:23,  3.09it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:04<00:23,  3.09it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:05<00:23,  3.12it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:05<00:22,  3.13it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:05<00:22,  3.12it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:06<00:22,  3.14it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:06<00:21,  3.12it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:06<00:21,  3.11it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:06<00:21,  3.14it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:07<00:20,  3.13it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:07<00:20,  3.11it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:07<00:20,  3.13it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:08<00:19,  3.11it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:08<00:19,  3.14it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:08<00:19,  3.13it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:09<00:18,  3.12it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:09<00:18,  3.11it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:09<00:18,  3.10it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:10<00:18,  3.10it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:10<00:17,  3.10it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:17,  3.10it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:11<00:17,  3.09it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:11<00:16,  3.10it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:11<00:16,  3.10it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:12<00:16,  3.09it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:12<00:15,  3.09it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:12<00:15,  3.10it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:13<00:15,  3.13it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:13<00:14,  3.15it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:13<00:14,  3.16it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:14<00:13,  3.14it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:14<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:14<00:13,  3.13it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:14<00:13,  3.12it/s]\u001b[AI1018 11:08:42.457784 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1000/config.json\n",
      "I1018 11:08:43.637601 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1000/pytorch_model.bin\n",
      "I1018 11:08:43.641199 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1000\n",
      "\n",
      "Iteration:  85%|████████▍ | 220/260 [01:16<00:27,  1.48it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:16<00:22,  1.77it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:17<00:18,  2.03it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:17<00:16,  2.26it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:17<00:14,  2.48it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:18<00:13,  2.63it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:18<00:12,  2.76it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:18<00:11,  2.85it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:19<00:10,  2.92it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:19<00:10,  2.97it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:19<00:09,  3.03it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:20<00:09,  3.05it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:20<00:09,  3.09it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:20<00:08,  3.12it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:20<00:08,  3.12it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:21<00:08,  3.11it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:21<00:07,  3.10it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:21<00:07,  3.10it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:22<00:07,  3.13it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:22<00:06,  3.15it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:22<00:06,  3.16it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:23<00:06,  3.15it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:23<00:05,  3.13it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:23<00:05,  3.14it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:24<00:05,  3.12it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:24<00:04,  3.12it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:24<00:04,  3.14it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:25<00:04,  3.13it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:25<00:03,  3.11it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:25<00:03,  3.10it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:26<00:03,  3.13it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:26<00:02,  3.12it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:26<00:02,  3.12it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:27<00:02,  3.13it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:27<00:01,  3.12it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:27<00:01,  3.13it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:28<00:01,  3.14it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:28<00:00,  3.12it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:28<00:00,  3.12it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:28<00:00,  3.14it/s]\u001b[A\n",
      "Epoch:  40%|████      | 4/10 [05:57<08:55, 89.33s/it]50it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:21,  3.17it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:21,  3.15it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:22,  3.13it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:22,  3.12it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:21,  3.11it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:20,  3.14it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:20,  3.13it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:20,  3.11it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:20,  3.11it/s]\u001b[AI1018 11:08:59.524517 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1050/config.json\n",
      "I1018 11:09:00.719911 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1050/pytorch_model.bin\n",
      "I1018 11:09:00.724161 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1050\n",
      "\n",
      "Iteration:   4%|▍         | 10/260 [00:04<02:50,  1.47it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:04<02:21,  1.76it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:05<02:01,  2.04it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:05<01:48,  2.28it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:05<01:39,  2.48it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:05<01:32,  2.64it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:06<01:28,  2.76it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:06<01:25,  2.85it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:06<01:22,  2.92it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:07<01:20,  3.00it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:07<01:18,  3.05it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:07<01:17,  3.07it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:08<01:17,  3.07it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:08<01:16,  3.10it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:08<01:16,  3.09it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:09<01:15,  3.12it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:09<01:15,  3.12it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:09<01:14,  3.11it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:10<01:14,  3.11it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:10<01:14,  3.10it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:10<01:14,  3.10it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:11<01:13,  3.10it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:11<01:13,  3.09it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:11<01:12,  3.12it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:12<01:12,  3.11it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:12<01:12,  3.11it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:12<01:12,  3.11it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:13<01:11,  3.10it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:13<01:11,  3.09it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:13<01:11,  3.10it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:14<01:10,  3.13it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:14<01:10,  3.12it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:09,  3.14it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:09,  3.12it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:15<01:08,  3.13it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:08,  3.12it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:08,  3.12it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:16<01:08,  3.11it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:08,  3.10it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:08,  3.10it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:17<01:07,  3.10it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:07,  3.10it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:06,  3.12it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:18<01:06,  3.11it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:05,  3.13it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:05,  3.11it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:19<01:05,  3.11it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:05,  3.11it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:05,  3.10it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:20<01:04,  3.09it/s]\u001b[AI1018 11:09:16.754230 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1100/config.json\n",
      "I1018 11:09:17.961425 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1100/pytorch_model.bin\n",
      "I1018 11:09:17.966777 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1100\n",
      "\n",
      "Iteration:  23%|██▎       | 60/260 [00:21<02:17,  1.46it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:21<01:53,  1.75it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:22<01:38,  2.01it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:22<01:27,  2.25it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:22<01:19,  2.46it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:23<01:14,  2.62it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:23<01:10,  2.74it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:23<01:07,  2.84it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:24<01:05,  2.92it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:24<01:04,  2.97it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:24<01:03,  3.00it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:25<01:02,  3.03it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:25<01:01,  3.05it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:25<01:00,  3.09it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:26<01:00,  3.08it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:26<01:00,  3.08it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:26<00:59,  3.09it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:27<00:58,  3.12it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:27<00:57,  3.14it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:27<00:57,  3.16it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:28<00:56,  3.17it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:28<00:56,  3.18it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:28<00:56,  3.15it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:28<00:56,  3.16it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:29<00:56,  3.14it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:29<00:55,  3.15it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:29<00:55,  3.13it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:30<00:55,  3.12it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:30<00:55,  3.11it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:30<00:55,  3.10it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:31<00:54,  3.09it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:31<00:54,  3.12it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<00:53,  3.15it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:32<00:53,  3.13it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:32<00:52,  3.15it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:32<00:52,  3.16it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:33<00:52,  3.14it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:33<00:52,  3.13it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:33<00:51,  3.14it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:34<00:51,  3.12it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<00:51,  3.12it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<00:51,  3.11it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:35<00:50,  3.10it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:35<00:50,  3.10it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<00:49,  3.12it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:36<00:49,  3.12it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:36<00:49,  3.11it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:49,  3.10it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:37<00:49,  3.09it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:37<00:48,  3.12it/s]\u001b[AI1018 11:09:33.971147 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1150/config.json\n",
      "I1018 11:09:35.181598 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1150/pytorch_model.bin\n",
      "I1018 11:09:35.185589 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1150\n",
      "\n",
      "Iteration:  42%|████▏     | 110/260 [00:38<01:42,  1.46it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:39<01:25,  1.74it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:39<01:13,  2.00it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:39<01:05,  2.25it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  44%|████▍     | 114/260 [00:40<00:59,  2.45it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:40<00:55,  2.63it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:40<00:52,  2.76it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:41<00:49,  2.87it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:41<00:47,  2.96it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:41<00:46,  3.03it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:42<00:45,  3.05it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:42<00:45,  3.09it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:42<00:44,  3.11it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:43<00:44,  3.10it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:43<00:43,  3.10it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:43<00:43,  3.13it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:43<00:42,  3.12it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:44<00:42,  3.11it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:44<00:42,  3.13it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:44<00:42,  3.12it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:45<00:41,  3.11it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:45<00:41,  3.10it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:45<00:41,  3.10it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:46<00:41,  3.10it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:46<00:40,  3.09it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:46<00:40,  3.10it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:47<00:39,  3.13it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:47<00:39,  3.15it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:47<00:38,  3.13it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:48<00:38,  3.15it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:48<00:38,  3.15it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:48<00:37,  3.16it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:49<00:37,  3.16it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:49<00:36,  3.16it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:49<00:36,  3.17it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:50<00:36,  3.17it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:50<00:36,  3.14it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:50<00:36,  3.12it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:50<00:35,  3.12it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:51<00:35,  3.11it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<00:35,  3.10it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:51<00:35,  3.10it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:52<00:34,  3.10it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:34,  3.13it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:33,  3.14it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:53<00:33,  3.13it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:53<00:33,  3.11it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:53<00:33,  3.10it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:54<00:32,  3.10it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:54<00:32,  3.13it/s]\u001b[AI1018 11:09:51.150762 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1200/config.json\n",
      "I1018 11:09:52.376648 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1200/pytorch_model.bin\n",
      "I1018 11:09:52.379792 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1200\n",
      "\n",
      "Iteration:  62%|██████▏   | 160/260 [00:56<01:08,  1.45it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:56<00:56,  1.74it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:56<00:49,  2.00it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:57<00:43,  2.24it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:57<00:39,  2.44it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:57<00:36,  2.61it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:57<00:34,  2.75it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:58<00:32,  2.85it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:58<00:31,  2.94it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:58<00:30,  2.98it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:59<00:29,  3.01it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:59<00:29,  3.04it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:59<00:28,  3.05it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [01:00<00:28,  3.06it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [01:00<00:27,  3.10it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [01:00<00:27,  3.10it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [01:01<00:26,  3.13it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [01:01<00:26,  3.12it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:01<00:26,  3.11it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:02<00:25,  3.13it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:02<00:25,  3.12it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:02<00:25,  3.11it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:03<00:25,  3.11it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:03<00:24,  3.13it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:03<00:24,  3.11it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:04<00:24,  3.10it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:04<00:23,  3.10it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:04<00:23,  3.13it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:05<00:23,  3.12it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:05<00:22,  3.14it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:05<00:22,  3.12it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:06<00:22,  3.13it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:06<00:21,  3.12it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:06<00:21,  3.14it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:06<00:20,  3.16it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:07<00:20,  3.14it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:07<00:20,  3.13it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:07<00:20,  3.14it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:08<00:19,  3.12it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:08<00:19,  3.11it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:08<00:19,  3.11it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:09<00:19,  3.10it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:09<00:18,  3.10it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:09<00:18,  3.09it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:10<00:17,  3.12it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:10<00:17,  3.14it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:17,  3.16it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:11<00:16,  3.17it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:11<00:16,  3.18it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:11<00:16,  3.18it/s]\u001b[AI1018 11:10:08.376282 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1250/config.json\n",
      "I1018 11:10:09.599253 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1250/pytorch_model.bin\n",
      "I1018 11:10:09.602661 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1250\n",
      "\n",
      "Iteration:  81%|████████  | 210/260 [01:13<00:34,  1.46it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:13<00:28,  1.75it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:13<00:23,  2.01it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:14<00:20,  2.25it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:14<00:18,  2.45it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:14<00:17,  2.61it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:15<00:16,  2.74it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:15<00:15,  2.83it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:15<00:14,  2.91it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:16<00:13,  2.96it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:16<00:13,  3.01it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:16<00:12,  3.03it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:17<00:12,  3.05it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:17<00:12,  3.06it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:17<00:11,  3.10it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:18<00:11,  3.10it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:18<00:10,  3.12it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:18<00:10,  3.11it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:19<00:10,  3.10it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:19<00:09,  3.13it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:19<00:09,  3.12it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:20<00:09,  3.11it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:20<00:08,  3.13it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:20<00:08,  3.14it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:20<00:08,  3.12it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:21<00:08,  3.11it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:21<00:07,  3.11it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:21<00:07,  3.11it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:22<00:07,  3.13it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:22<00:06,  3.11it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:22<00:06,  3.13it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:23<00:06,  3.14it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:23<00:05,  3.13it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:23<00:05,  3.15it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:24<00:05,  3.14it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:24<00:04,  3.15it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:24<00:04,  3.14it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:25<00:04,  3.12it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:25<00:03,  3.11it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:25<00:03,  3.11it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:26<00:03,  3.11it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:26<00:02,  3.12it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:26<00:02,  3.14it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:27<00:02,  3.12it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:27<00:01,  3.11it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:27<00:01,  3.13it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:28<00:01,  3.12it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:28<00:00,  3.14it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:28<00:00,  3.13it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:28<00:00,  3.12it/s]\u001b[AI1018 11:10:25.512761 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1300/config.json\n",
      "I1018 11:10:26.735978 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1300/pytorch_model.bin\n",
      "I1018 11:10:26.740469 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1300\n",
      "\n",
      "Epoch:  50%|█████     | 5/10 [07:27<07:28, 89.66s/it]52it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:18,  3.29it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:20,  3.22it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:20,  3.21it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:20,  3.20it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:20,  3.16it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:20,  3.14it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:20,  3.15it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:20,  3.14it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:19,  3.15it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:20,  3.12it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:19,  3.14it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:19,  3.12it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:19,  3.12it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:18,  3.14it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:18,  3.13it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:17,  3.14it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:17,  3.12it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:17,  3.14it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:06<01:17,  3.12it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:17,  3.12it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:16,  3.14it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:07<01:15,  3.16it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:15,  3.14it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:14,  3.15it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:14,  3.16it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:08<01:14,  3.13it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:14,  3.14it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:13,  3.15it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:09<01:13,  3.13it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:09<01:13,  3.15it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:13,  3.13it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:10<01:12,  3.12it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:10<01:12,  3.11it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:12,  3.10it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:11<01:11,  3.13it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:11<01:11,  3.12it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:11<01:11,  3.12it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:12<01:10,  3.14it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:12<01:10,  3.15it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:12<01:10,  3.13it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:13<01:09,  3.14it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:13<01:09,  3.12it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:13<01:09,  3.14it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:14<01:09,  3.13it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:14<01:08,  3.12it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:14<01:08,  3.11it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:15<01:08,  3.10it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:15<01:07,  3.13it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:15<01:07,  3.15it/s]\u001b[AI1018 11:10:42.701461 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1350/config.json\n",
      "I1018 11:10:43.923473 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1350/pytorch_model.bin\n",
      "I1018 11:10:43.927023 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1350\n",
      "\n",
      "Iteration:  19%|█▉        | 50/260 [00:17<02:24,  1.46it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:59,  1.74it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:43,  2.02it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:18<01:31,  2.26it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:24,  2.45it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:17,  2.63it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:19<01:14,  2.75it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:11,  2.85it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:09,  2.92it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:20<01:07,  2.99it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:20<01:05,  3.04it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:04,  3.08it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:21<01:03,  3.11it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:21<01:03,  3.10it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:03,  3.09it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:21<01:02,  3.10it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:02,  3.13it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<01:01,  3.15it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:22<01:00,  3.16it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:23<01:00,  3.15it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:23<01:00,  3.15it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:23<00:59,  3.16it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:24<01:00,  3.13it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:24<00:59,  3.12it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:24<00:59,  3.11it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:25<00:58,  3.14it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:25<00:58,  3.13it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:25<00:58,  3.14it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:26<00:57,  3.15it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:26<00:57,  3.16it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:26<00:56,  3.16it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:27<00:56,  3.17it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:27<00:56,  3.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  32%|███▏      | 83/260 [00:27<00:56,  3.14it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:28<00:55,  3.15it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:28<00:55,  3.13it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:28<00:55,  3.15it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:28<00:54,  3.16it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:29<00:54,  3.14it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:29<00:54,  3.13it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:29<00:54,  3.14it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:30<00:53,  3.15it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:30<00:53,  3.16it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:30<00:53,  3.14it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:31<00:53,  3.12it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:31<00:52,  3.12it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:31<00:52,  3.14it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:32<00:52,  3.13it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:32<00:51,  3.12it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:32<00:51,  3.13it/s]\u001b[AI1018 11:10:59.853275 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1400/config.json\n",
      "I1018 11:11:01.076942 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1400/pytorch_model.bin\n",
      "I1018 11:11:01.080136 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1400\n",
      "\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<01:50,  1.45it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<01:31,  1.74it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<01:18,  2.00it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:35<01:09,  2.25it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<01:03,  2.46it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:35<00:58,  2.63it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:36<00:55,  2.77it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:53,  2.85it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:36<00:51,  2.94it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:37<00:50,  2.98it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<00:49,  3.02it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:37<00:48,  3.04it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:38<00:48,  3.05it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<00:47,  3.06it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:38<00:47,  3.08it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:39<00:47,  3.08it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:46,  3.11it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:39<00:46,  3.10it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:40<00:45,  3.09it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:45,  3.12it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:40<00:44,  3.12it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:41<00:44,  3.14it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:41<00:44,  3.13it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:41<00:43,  3.11it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:42<00:43,  3.13it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:42<00:43,  3.12it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:42<00:42,  3.14it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:42<00:42,  3.13it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:43<00:42,  3.12it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:43<00:41,  3.13it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:43<00:41,  3.15it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:44<00:41,  3.13it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:44<00:41,  3.11it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:44<00:40,  3.11it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:45<00:40,  3.13it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:45<00:40,  3.12it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:45<00:39,  3.11it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:46<00:39,  3.13it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:46<00:38,  3.14it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:46<00:38,  3.15it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:47<00:38,  3.16it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:47<00:37,  3.16it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:47<00:37,  3.16it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:48<00:36,  3.17it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:48<00:36,  3.17it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:48<00:36,  3.14it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:49<00:36,  3.16it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:49<00:35,  3.14it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:49<00:35,  3.16it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:49<00:35,  3.17it/s]\u001b[AI1018 11:11:17.034737 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1450/config.json\n",
      "I1018 11:11:18.256916 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1450/pytorch_model.bin\n",
      "I1018 11:11:18.259827 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1450\n",
      "\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<01:15,  1.46it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:51<01:02,  1.75it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:52<00:53,  2.02it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:47,  2.25it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:42,  2.47it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:53<00:39,  2.64it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:53<00:37,  2.78it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:53<00:35,  2.87it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:54<00:34,  2.93it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:54<00:33,  3.01it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:54<00:32,  3.04it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:55<00:32,  3.05it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:55<00:31,  3.08it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:31,  3.11it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:55<00:30,  3.10it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:56<00:30,  3.10it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:30,  3.10it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:56<00:30,  3.10it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:57<00:29,  3.12it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:29,  3.14it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:57<00:28,  3.12it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:58<00:28,  3.11it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:58<00:28,  3.14it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:58<00:27,  3.15it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:59<00:27,  3.14it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:59<00:27,  3.15it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:59<00:26,  3.13it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [01:00<00:26,  3.12it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:00<00:26,  3.14it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:00<00:25,  3.13it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:01<00:25,  3.12it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:01<00:25,  3.11it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:01<00:24,  3.13it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:02<00:24,  3.14it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:02<00:24,  3.12it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:02<00:23,  3.14it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:03<00:23,  3.13it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:03<00:23,  3.15it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:03<00:22,  3.16it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:03<00:22,  3.15it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:04<00:22,  3.13it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:04<00:22,  3.12it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:04<00:21,  3.14it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:05<00:21,  3.13it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:05<00:21,  3.12it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:05<00:20,  3.11it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:06<00:20,  3.10it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:06<00:20,  3.10it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:06<00:19,  3.13it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:07<00:19,  3.12it/s]\u001b[AI1018 11:11:34.224689 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1500/config.json\n",
      "I1018 11:11:35.446596 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1500/pytorch_model.bin\n",
      "I1018 11:11:35.449555 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1500\n",
      "\n",
      "Iteration:  77%|███████▋  | 200/260 [01:08<00:41,  1.45it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:09<00:33,  1.74it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:09<00:28,  2.01it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:09<00:25,  2.24it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:09<00:22,  2.46it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:10<00:20,  2.63it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:19,  2.75it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:10<00:18,  2.84it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:11<00:17,  2.94it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:11<00:17,  2.98it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:11<00:16,  3.04it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:12<00:16,  3.06it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:12<00:15,  3.07it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:12<00:15,  3.08it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:13<00:14,  3.08it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:13<00:14,  3.09it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:13<00:14,  3.09it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:14<00:13,  3.12it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:14<00:13,  3.14it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:14<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:15<00:12,  3.13it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:15<00:12,  3.11it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:15<00:12,  3.14it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:16<00:11,  3.16it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:16<00:11,  3.14it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:16<00:11,  3.13it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:17<00:10,  3.11it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:17<00:10,  3.13it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:17<00:10,  3.14it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:17<00:09,  3.15it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:18<00:09,  3.16it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:18<00:09,  3.13it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:18<00:08,  3.15it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:19<00:08,  3.14it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:19<00:08,  3.13it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:19<00:07,  3.14it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:20<00:07,  3.15it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:20<00:07,  3.13it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:20<00:07,  3.14it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:21<00:06,  3.15it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:21<00:06,  3.13it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:21<00:06,  3.12it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:22<00:05,  3.14it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:22<00:05,  3.13it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:22<00:05,  3.14it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:23<00:04,  3.12it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:23<00:04,  3.11it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:23<00:04,  3.11it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:24<00:03,  3.14it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:24<00:03,  3.15it/s]\u001b[AI1018 11:11:51.406582 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1550/config.json\n",
      "I1018 11:11:52.628551 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1550/pytorch_model.bin\n",
      "I1018 11:11:52.631540 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1550\n",
      "\n",
      "Iteration:  96%|█████████▌| 250/260 [01:25<00:06,  1.46it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:26<00:05,  1.75it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:26<00:03,  2.03it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:26<00:03,  2.26it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:27<00:02,  2.46it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:27<00:01,  2.62it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:27<00:01,  2.77it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:28<00:01,  2.89it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:28<00:00,  2.97it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:28<00:00,  3.01it/s]\u001b[A\n",
      "Epoch:  60%|██████    | 6/10 [08:56<05:57, 89.45s/it]39it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:19,  3.27it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:19,  3.25it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:19,  3.23it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:19,  3.22it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:19,  3.21it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:19,  3.21it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:18,  3.20it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:18,  3.20it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:19,  3.17it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:18,  3.18it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:18,  3.15it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:18,  3.16it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:18,  3.16it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:18,  3.14it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:17,  3.15it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:17,  3.13it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:17,  3.15it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:16,  3.16it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:15,  3.17it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:15,  3.18it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:15,  3.15it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:15,  3.17it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:15,  3.15it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:15,  3.13it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:15,  3.11it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:08<01:14,  3.14it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:14,  3.13it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:13,  3.15it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:09<01:13,  3.16it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:09<01:12,  3.17it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:12,  3.15it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:10<01:12,  3.13it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:10<01:12,  3.12it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:11,  3.14it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:11<01:11,  3.16it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:11<01:10,  3.17it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:11<01:10,  3.17it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:12<01:09,  3.18it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:12<01:09,  3.18it/s]\u001b[AI1018 11:12:08.346015 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1600/config.json\n",
      "I1018 11:12:09.569564 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1600/pytorch_model.bin\n",
      "I1018 11:12:09.575646 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1600\n",
      "\n",
      "Iteration:  15%|█▌        | 40/260 [00:13<02:30,  1.46it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:14<02:04,  1.75it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:47,  2.03it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:35,  2.28it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:15<01:27,  2.47it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:21,  2.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  18%|█▊        | 46/260 [00:15<01:16,  2.80it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:16<01:13,  2.91it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:11,  2.96it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:10,  3.00it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:17<01:08,  3.05it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:07,  3.08it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:06,  3.11it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:17<01:06,  3.13it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:05,  3.14it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:05,  3.15it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:04,  3.16it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:04,  3.16it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:04,  3.14it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:03,  3.15it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:20<01:03,  3.16it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:03,  3.15it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:20<01:03,  3.13it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:21<01:02,  3.14it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:02,  3.15it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:21<01:02,  3.13it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:01,  3.14it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<01:01,  3.15it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:22<01:00,  3.16it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:23<01:00,  3.13it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:23<01:00,  3.15it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:23<00:59,  3.17it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:24<00:59,  3.15it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:24<00:59,  3.16it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:24<00:59,  3.14it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:24<00:59,  3.12it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:25<00:59,  3.11it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:25<00:58,  3.14it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:25<00:57,  3.15it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:26<00:57,  3.17it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:26<00:56,  3.17it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:26<00:56,  3.18it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:27<00:55,  3.18it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:27<00:55,  3.19it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:27<00:55,  3.19it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:28<00:55,  3.16it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:28<00:54,  3.17it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:28<00:54,  3.18it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:29<00:54,  3.16it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:29<00:54,  3.14it/s]\u001b[AI1018 11:12:25.413941 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1650/config.json\n",
      "I1018 11:12:26.636174 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1650/pytorch_model.bin\n",
      "I1018 11:12:26.639589 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1650\n",
      "\n",
      "Iteration:  35%|███▍      | 90/260 [00:30<01:57,  1.45it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:31<01:37,  1.74it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<01:23,  2.00it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:31<01:13,  2.26it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:32<01:07,  2.46it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:32<01:02,  2.64it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:32<00:59,  2.76it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:33<00:57,  2.85it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:33<00:55,  2.92it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:33<00:54,  2.97it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<00:53,  3.01it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<00:52,  3.05it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<00:51,  3.06it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:35<00:50,  3.09it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<00:50,  3.12it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:35<00:49,  3.10it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:36<00:49,  3.10it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:48,  3.13it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:36<00:48,  3.12it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:37<00:48,  3.11it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<00:48,  3.10it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:37<00:47,  3.10it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:37<00:47,  3.10it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<00:47,  3.13it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:38<00:46,  3.11it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:38<00:46,  3.13it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:45,  3.14it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:39<00:45,  3.12it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:39<00:45,  3.15it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:45,  3.13it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:40<00:44,  3.15it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:40<00:43,  3.16it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:41<00:43,  3.17it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:41<00:43,  3.18it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:41<00:43,  3.16it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:42<00:42,  3.16it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:42<00:42,  3.14it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:42<00:42,  3.15it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:43<00:41,  3.16it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:43<00:41,  3.13it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:43<00:41,  3.16it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:44<00:41,  3.14it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:44<00:40,  3.16it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:44<00:40,  3.14it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:44<00:40,  3.12it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:45<00:40,  3.11it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:45<00:39,  3.11it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:45<00:39,  3.13it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:46<00:38,  3.15it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:46<00:38,  3.14it/s]\u001b[AI1018 11:12:42.586182 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1700/config.json\n",
      "I1018 11:12:43.802156 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1700/pytorch_model.bin\n",
      "I1018 11:12:43.805598 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1700\n",
      "\n",
      "Iteration:  54%|█████▍    | 140/260 [00:48<01:22,  1.46it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:48<01:07,  1.75it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:48<00:58,  2.02it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:49<00:51,  2.26it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:49<00:46,  2.47it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:49<00:43,  2.64it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:50<00:41,  2.76it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:50<00:39,  2.88it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:50<00:37,  2.97it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:50<00:36,  3.01it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<00:36,  3.03it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:51<00:35,  3.05it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:51<00:35,  3.09it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:34,  3.11it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:33,  3.13it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:52<00:33,  3.14it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:53<00:33,  3.12it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:53<00:32,  3.14it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:53<00:32,  3.16it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:54<00:31,  3.17it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:54<00:31,  3.18it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:54<00:31,  3.18it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:55<00:30,  3.19it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:30,  3.16it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:55<00:30,  3.14it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:56<00:30,  3.12it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:29,  3.14it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:56<00:29,  3.15it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:56<00:29,  3.13it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:29,  3.12it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:57<00:28,  3.14it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:57<00:28,  3.16it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:58<00:27,  3.17it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:58<00:27,  3.15it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:58<00:27,  3.16it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:59<00:27,  3.13it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:59<00:26,  3.12it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:59<00:26,  3.14it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:00<00:26,  3.13it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:00<00:25,  3.15it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:00<00:25,  3.14it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:01<00:25,  3.14it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:01<00:24,  3.12it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:01<00:24,  3.11it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:02<00:24,  3.11it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:02<00:23,  3.13it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:02<00:23,  3.15it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:03<00:23,  3.17it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:03<00:22,  3.18it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:03<00:22,  3.15it/s]\u001b[AI1018 11:12:59.685700 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1750/config.json\n",
      "I1018 11:13:00.901750 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1750/pytorch_model.bin\n",
      "I1018 11:13:00.905299 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1750\n",
      "\n",
      "Iteration:  73%|███████▎  | 190/260 [01:05<00:47,  1.46it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:05<00:39,  1.75it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:05<00:33,  2.02it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:06<00:29,  2.27it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:06<00:26,  2.46it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:06<00:24,  2.64it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:07<00:23,  2.76it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:07<00:22,  2.86it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:07<00:21,  2.93it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:08<00:20,  2.97it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:08<00:19,  3.00it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:08<00:19,  3.06it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:09<00:18,  3.10it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:09<00:18,  3.10it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:09<00:17,  3.13it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:09<00:17,  3.15it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:17,  3.16it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:10<00:16,  3.14it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:10<00:16,  3.15it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:11<00:16,  3.13it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:11<00:15,  3.14it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:11<00:15,  3.15it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:12<00:15,  3.13it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:12<00:14,  3.15it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:12<00:14,  3.14it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:13<00:14,  3.15it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:13<00:14,  3.14it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:13<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:14<00:13,  3.16it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:14<00:12,  3.16it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:14<00:12,  3.14it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:15<00:12,  3.15it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:15<00:12,  3.13it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:15<00:11,  3.15it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:16<00:11,  3.16it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:16<00:11,  3.17it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:16<00:10,  3.15it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:16<00:10,  3.17it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:17<00:10,  3.17it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:17<00:09,  3.15it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:17<00:09,  3.16it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:18<00:09,  3.14it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:18<00:08,  3.15it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:18<00:08,  3.13it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:19<00:08,  3.15it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:19<00:07,  3.16it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:19<00:07,  3.17it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:20<00:07,  3.18it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:20<00:06,  3.16it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:20<00:06,  3.14it/s]\u001b[AI1018 11:13:16.785585 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1800/config.json\n",
      "I1018 11:13:18.007431 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1800/pytorch_model.bin\n",
      "I1018 11:13:18.014458 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1800\n",
      "\n",
      "Iteration:  92%|█████████▏| 240/260 [01:22<00:13,  1.45it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:22<00:10,  1.74it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:22<00:08,  2.02it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:23<00:07,  2.26it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:23<00:06,  2.48it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:23<00:05,  2.65it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:24<00:05,  2.79it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:24<00:04,  2.87it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:24<00:04,  2.95it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:25<00:03,  2.99it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:25<00:03,  3.03it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:25<00:02,  3.05it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:26<00:02,  3.09it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:26<00:02,  3.11it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:26<00:01,  3.13it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:27<00:01,  3.14it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:27<00:01,  3.15it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:27<00:00,  3.16it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:28<00:00,  3.16it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:28<00:00,  3.16it/s]\u001b[A\n",
      "Epoch:  70%|███████   | 7/10 [10:25<04:27, 89.17s/it]56it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:19,  3.25it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:19,  3.23it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:20,  3.19it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:20,  3.17it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:20,  3.17it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:20,  3.17it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:19,  3.17it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:19,  3.17it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:19,  3.17it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:18,  3.17it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:18,  3.17it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:18,  3.14it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:18,  3.15it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:17,  3.16it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   6%|▌         | 15/260 [00:04<01:18,  3.13it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:18,  3.13it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:17,  3.12it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:17,  3.11it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:06<01:17,  3.13it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:16,  3.14it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:15,  3.15it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:15,  3.16it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:14,  3.16it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:14,  3.17it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:14,  3.17it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:08<01:13,  3.17it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:13,  3.17it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:13,  3.17it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:09<01:13,  3.15it/s]\u001b[AI1018 11:13:33.757052 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1850/config.json\n",
      "I1018 11:13:34.973080 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1850/pytorch_model.bin\n",
      "I1018 11:13:34.976185 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1850\n",
      "\n",
      "Iteration:  12%|█▏        | 30/260 [00:10<02:37,  1.46it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:11<02:10,  1.75it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:11<01:52,  2.02it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:11<01:39,  2.27it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:11<01:31,  2.47it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:12<01:25,  2.65it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:12<01:20,  2.78it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:12<01:17,  2.89it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:13<01:14,  2.97it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:13<01:13,  3.03it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:13<01:11,  3.07it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:14<01:10,  3.10it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:10,  3.09it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:09,  3.12it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:15<01:08,  3.13it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:08,  3.15it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:07,  3.16it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:16<01:07,  3.16it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:07,  3.16it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:06,  3.16it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:17<01:06,  3.17it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:06,  3.14it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:05,  3.16it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:18<01:05,  3.14it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:05,  3.16it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:05,  3.14it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:04,  3.15it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:04,  3.13it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:04,  3.12it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:04,  3.14it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:20<01:03,  3.16it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:03,  3.14it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:20<01:03,  3.13it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:21<01:02,  3.14it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:02,  3.12it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:21<01:02,  3.14it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:02,  3.12it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<01:01,  3.14it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:22<01:01,  3.13it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:23<01:00,  3.15it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:23<01:00,  3.16it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:23<00:59,  3.17it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:24<00:59,  3.18it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:24<00:58,  3.18it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:24<00:58,  3.19it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:24<00:58,  3.19it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:25<00:57,  3.19it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:25<00:57,  3.16it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:25<00:57,  3.17it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:26<00:57,  3.14it/s]\u001b[AI1018 11:13:50.816706 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1900/config.json\n",
      "I1018 11:13:52.035787 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1900/pytorch_model.bin\n",
      "I1018 11:13:52.040241 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1900\n",
      "\n",
      "Iteration:  31%|███       | 80/260 [00:27<02:03,  1.46it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:28<01:43,  1.74it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:28<01:28,  2.01it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:28<01:18,  2.25it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:29<01:11,  2.47it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:29<01:06,  2.65it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:29<01:02,  2.79it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:30<00:59,  2.90it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:30<00:57,  2.98it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:30<00:56,  3.02it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:30<00:55,  3.04it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:31<00:54,  3.08it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<00:54,  3.11it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:31<00:53,  3.13it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:32<00:52,  3.14it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:32<00:52,  3.12it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:32<00:52,  3.14it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:33<00:52,  3.13it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:33<00:51,  3.15it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:33<00:50,  3.16it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<00:50,  3.17it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<00:50,  3.18it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<00:50,  3.16it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:35<00:49,  3.16it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<00:49,  3.17it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:35<00:48,  3.17it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:36<00:48,  3.17it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:48,  3.14it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:36<00:48,  3.15it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:36<00:47,  3.16it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<00:47,  3.16it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:37<00:47,  3.16it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:37<00:46,  3.17it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<00:46,  3.14it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:38<00:46,  3.16it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:38<00:45,  3.17it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:45,  3.18it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:39<00:44,  3.18it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:39<00:44,  3.19it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:44,  3.19it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:40<00:44,  3.16it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:40<00:43,  3.17it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:41<00:43,  3.18it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:41<00:43,  3.18it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:41<00:42,  3.19it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:42<00:42,  3.16it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:42<00:42,  3.17it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:42<00:42,  3.16it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:42<00:41,  3.17it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:43<00:41,  3.17it/s]\u001b[AI1018 11:14:07.839539 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-1950/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1018 11:14:09.055959 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-1950/pytorch_model.bin\n",
      "I1018 11:14:09.058860 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-1950\n",
      "\n",
      "Iteration:  50%|█████     | 130/260 [00:44<01:28,  1.46it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:45<01:13,  1.76it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:45<01:03,  2.03it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:45<00:56,  2.26it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:46<00:50,  2.47it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:46<00:47,  2.65it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:46<00:44,  2.79it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:47<00:42,  2.89it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:47<00:41,  2.97it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:47<00:39,  3.03it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:47<00:39,  3.07it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:48<00:38,  3.10it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:48<00:38,  3.09it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:48<00:37,  3.12it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:49<00:36,  3.14it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:49<00:36,  3.16it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:49<00:36,  3.14it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:50<00:35,  3.16it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:50<00:35,  3.17it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:50<00:34,  3.18it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<00:34,  3.18it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:51<00:34,  3.18it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:51<00:34,  3.16it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:33,  3.16it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:33,  3.16it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:52<00:33,  3.17it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:53<00:32,  3.17it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:53<00:32,  3.17it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:53<00:32,  3.14it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:53<00:32,  3.13it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:54<00:32,  3.12it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:54<00:31,  3.12it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:54<00:31,  3.13it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:30,  3.14it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:55<00:30,  3.15it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:55<00:30,  3.16it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:30,  3.13it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:56<00:29,  3.14it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:56<00:29,  3.15it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:28,  3.16it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:57<00:28,  3.13it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:57<00:28,  3.12it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:58<00:28,  3.12it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:58<00:27,  3.11it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:58<00:27,  3.10it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:59<00:27,  3.10it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:59<00:27,  3.10it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:59<00:26,  3.12it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:00<00:26,  3.14it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:00<00:25,  3.12it/s]\u001b[AI1018 11:14:24.952121 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2000/config.json\n",
      "I1018 11:14:26.169387 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2000/pytorch_model.bin\n",
      "I1018 11:14:26.172820 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2000\n",
      "\n",
      "Iteration:  69%|██████▉   | 180/260 [01:01<00:55,  1.45it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:02<00:45,  1.73it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:02<00:38,  2.01it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:02<00:34,  2.26it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:03<00:30,  2.48it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:03<00:28,  2.65it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:03<00:26,  2.80it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:04<00:25,  2.90it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:04<00:24,  2.99it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:04<00:23,  3.05it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:05<00:22,  3.09it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:05<00:22,  3.12it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:05<00:21,  3.14it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:06<00:21,  3.13it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:06<00:21,  3.11it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:06<00:20,  3.13it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:06<00:20,  3.15it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:07<00:19,  3.15it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:07<00:19,  3.13it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:07<00:19,  3.12it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:08<00:19,  3.14it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:08<00:18,  3.16it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:08<00:18,  3.17it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:09<00:17,  3.18it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:09<00:17,  3.18it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:09<00:17,  3.19it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:17,  3.16it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:10<00:16,  3.14it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:10<00:16,  3.15it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:11<00:16,  3.15it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:11<00:15,  3.16it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:11<00:15,  3.16it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:12<00:15,  3.16it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:12<00:14,  3.17it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:12<00:14,  3.17it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:12<00:14,  3.17it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:13<00:13,  3.17it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:13<00:13,  3.17it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:13<00:13,  3.17it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:14<00:12,  3.17it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:14<00:12,  3.17it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:14<00:12,  3.14it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:15<00:12,  3.16it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:15<00:11,  3.17it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:15<00:11,  3.17it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:16<00:11,  3.15it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:16<00:10,  3.17it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:16<00:10,  3.17it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:17<00:10,  3.15it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:17<00:09,  3.16it/s]\u001b[AI1018 11:14:41.965464 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2050/config.json\n",
      "I1018 11:14:43.182600 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2050/pytorch_model.bin\n",
      "I1018 11:14:43.185585 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2050\n",
      "\n",
      "Iteration:  88%|████████▊ | 230/260 [01:18<00:20,  1.46it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:19<00:16,  1.74it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:19<00:13,  2.02it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:19<00:11,  2.26it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:20<00:10,  2.48it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:20<00:09,  2.65it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:20<00:08,  2.79it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:21<00:08,  2.87it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:21<00:07,  2.96it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:21<00:06,  3.03it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:22<00:06,  3.07it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:22<00:06,  3.11it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:22<00:05,  3.11it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:23<00:05,  3.11it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:23<00:05,  3.13it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:23<00:04,  3.14it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:24<00:04,  3.15it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:24<00:04,  3.16it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:24<00:03,  3.16it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:24<00:03,  3.17it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:25<00:03,  3.17it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:25<00:02,  3.17it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:25<00:02,  3.17it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:26<00:02,  3.14it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:26<00:01,  3.15it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:26<00:01,  3.16it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:27<00:01,  3.16it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:27<00:00,  3.16it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:27<00:00,  3.14it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:28<00:00,  3.15it/s]\u001b[A\n",
      "Epoch:  80%|████████  | 8/10 [11:53<02:57, 88.92s/it]55it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:20,  3.23it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:20,  3.19it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:20,  3.18it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:21,  3.15it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:20,  3.17it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:19,  3.18it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:19,  3.18it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:19,  3.18it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:18,  3.19it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:19,  3.16it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:18,  3.17it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:18,  3.18it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:17,  3.19it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:17,  3.19it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:17,  3.16it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:17,  3.17it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:17,  3.14it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:16,  3.15it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:06<01:16,  3.16it/s]\u001b[AI1018 11:14:58.886869 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2100/config.json\n",
      "I1018 11:15:00.103581 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2100/pytorch_model.bin\n",
      "I1018 11:15:00.106613 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2100\n",
      "\n",
      "Iteration:   8%|▊         | 20/260 [00:07<02:44,  1.46it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:07<02:17,  1.74it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:08<01:57,  2.02it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:08<01:44,  2.27it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:08<01:34,  2.49it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:09<01:28,  2.64it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:09<01:24,  2.77it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:09<01:21,  2.88it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:10<01:18,  2.96it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:10<01:17,  2.99it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:10<01:15,  3.05it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:11<01:14,  3.08it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:11<01:13,  3.11it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:11<01:12,  3.13it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:11<01:11,  3.14it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:12<01:11,  3.15it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:12<01:10,  3.16it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:12<01:10,  3.16it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:13<01:10,  3.16it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:13<01:09,  3.17it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:13<01:10,  3.14it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:14<01:09,  3.13it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:09,  3.15it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:09,  3.13it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:15<01:09,  3.12it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:08,  3.13it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:08,  3.14it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:16<01:08,  3.12it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:07,  3.15it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:06,  3.16it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:17<01:06,  3.17it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:05,  3.18it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:05,  3.15it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:18<01:05,  3.17it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:04,  3.17it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:04,  3.18it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:04,  3.19it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:03,  3.19it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:03,  3.19it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:02,  3.19it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:20<01:02,  3.19it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:02,  3.19it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:20<01:01,  3.19it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:21<01:01,  3.19it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:01,  3.19it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:21<01:01,  3.17it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:01,  3.16it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<01:00,  3.17it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:22<01:00,  3.17it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:23<01:00,  3.17it/s]\u001b[AI1018 11:15:15.912231 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2150/config.json\n",
      "I1018 11:15:17.129504 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2150/pytorch_model.bin\n",
      "I1018 11:15:17.132748 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2150\n",
      "\n",
      "Iteration:  27%|██▋       | 70/260 [00:24<02:09,  1.46it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:24<01:47,  1.75it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:25<01:33,  2.01it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:25<01:23,  2.25it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:25<01:15,  2.47it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:26<01:09,  2.65it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:26<01:05,  2.79it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:26<01:03,  2.90it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:27<01:01,  2.98it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:27<00:59,  3.04it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:27<00:58,  3.09it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:28<00:57,  3.12it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:28<00:57,  3.11it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:28<00:56,  3.14it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:28<00:56,  3.13it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:29<00:55,  3.14it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:29<00:55,  3.15it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:29<00:54,  3.16it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:30<00:54,  3.16it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:30<00:54,  3.16it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:30<00:53,  3.17it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:31<00:53,  3.17it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<00:52,  3.17it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:31<00:53,  3.14it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:32<00:52,  3.15it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  37%|███▋      | 95/260 [00:32<00:52,  3.13it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:32<00:52,  3.15it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:33<00:51,  3.16it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:33<00:51,  3.14it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:33<00:50,  3.16it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<00:50,  3.14it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<00:50,  3.15it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<00:50,  3.15it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:35<00:49,  3.16it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<00:49,  3.16it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:35<00:48,  3.16it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:35<00:48,  3.17it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:48,  3.17it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:36<00:47,  3.17it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:36<00:48,  3.14it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<00:47,  3.15it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:37<00:47,  3.16it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:37<00:46,  3.16it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<00:46,  3.16it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:38<00:46,  3.16it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:38<00:45,  3.16it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:45,  3.16it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:39<00:45,  3.14it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:39<00:44,  3.16it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:44,  3.17it/s]\u001b[AI1018 11:15:32.947674 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2200/config.json\n",
      "I1018 11:15:34.164815 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2200/pytorch_model.bin\n",
      "I1018 11:15:34.168190 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2200\n",
      "\n",
      "Iteration:  46%|████▌     | 120/260 [00:41<01:35,  1.46it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:41<01:19,  1.76it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:42<01:07,  2.03it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:42<01:00,  2.27it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:42<00:54,  2.48it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:43<00:51,  2.64it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:43<00:48,  2.76it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:43<00:46,  2.85it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:44<00:45,  2.92it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:44<00:43,  3.00it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:44<00:42,  3.03it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:45<00:42,  3.07it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:45<00:41,  3.10it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:45<00:40,  3.12it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:46<00:40,  3.11it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:46<00:40,  3.10it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:46<00:39,  3.13it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:47<00:39,  3.15it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:47<00:38,  3.14it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:47<00:38,  3.15it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:47<00:37,  3.16it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:48<00:37,  3.17it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:48<00:37,  3.18it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:48<00:36,  3.18it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:49<00:36,  3.16it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:49<00:36,  3.16it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:49<00:36,  3.14it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:50<00:35,  3.15it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:50<00:35,  3.16it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:50<00:35,  3.13it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<00:34,  3.15it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:51<00:34,  3.16it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:51<00:34,  3.15it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:33,  3.16it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:33,  3.17it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:52<00:33,  3.18it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:53<00:32,  3.18it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:53<00:32,  3.16it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:53<00:32,  3.17it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:53<00:32,  3.14it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:54<00:31,  3.15it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:54<00:31,  3.16it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:54<00:31,  3.13it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:31,  3.13it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:55<00:30,  3.15it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:55<00:30,  3.13it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:29,  3.15it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:56<00:29,  3.12it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:56<00:29,  3.14it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:28,  3.15it/s]\u001b[AI1018 11:15:50.042683 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2250/config.json\n",
      "I1018 11:15:51.261393 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2250/pytorch_model.bin\n",
      "I1018 11:15:51.264225 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2250\n",
      "\n",
      "Iteration:  65%|██████▌   | 170/260 [00:58<01:01,  1.46it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:59<00:50,  1.75it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:59<00:43,  2.02it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:59<00:38,  2.27it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:59<00:34,  2.46it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [01:00<00:32,  2.64it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [01:00<00:30,  2.79it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [01:00<00:28,  2.90it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:01<00:27,  2.96it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:01<00:26,  3.02it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:01<00:26,  3.07it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:02<00:25,  3.11it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:02<00:25,  3.11it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:02<00:24,  3.13it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:03<00:24,  3.11it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:03<00:24,  3.10it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:03<00:23,  3.13it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:04<00:23,  3.15it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:04<00:22,  3.16it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:04<00:22,  3.17it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:05<00:22,  3.18it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:05<00:21,  3.19it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:05<00:21,  3.19it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:05<00:21,  3.19it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:06<00:20,  3.19it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:06<00:20,  3.19it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:06<00:20,  3.19it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:07<00:19,  3.19it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:07<00:19,  3.17it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:07<00:19,  3.18it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:08<00:18,  3.18it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:08<00:18,  3.18it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:08<00:18,  3.19it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:09<00:17,  3.19it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:09<00:17,  3.19it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:09<00:17,  3.19it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:16,  3.19it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:10<00:16,  3.17it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:10<00:16,  3.17it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:10<00:16,  3.17it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:11<00:15,  3.17it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:11<00:15,  3.17it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:11<00:15,  3.17it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:12<00:14,  3.17it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:12<00:14,  3.17it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:12<00:14,  3.14it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:13<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:13<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:13<00:13,  3.16it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:14<00:13,  3.14it/s]\u001b[AI1018 11:16:07.037227 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2300/config.json\n",
      "I1018 11:16:08.254013 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2300/pytorch_model.bin\n",
      "I1018 11:16:08.257142 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2300\n",
      "\n",
      "Iteration:  85%|████████▍ | 220/260 [01:15<00:27,  1.46it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:16<00:22,  1.75it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:16<00:18,  2.02it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:16<00:16,  2.27it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:16<00:14,  2.49it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:17<00:13,  2.66it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:17<00:12,  2.80it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:17<00:11,  2.91it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:18<00:10,  2.99it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:18<00:10,  3.05it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:18<00:09,  3.09it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:19<00:09,  3.09it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:19<00:08,  3.12it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:19<00:08,  3.13it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:20<00:08,  3.14it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:20<00:07,  3.15it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:20<00:07,  3.16it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:21<00:07,  3.13it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:21<00:06,  3.15it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:21<00:06,  3.13it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:22<00:06,  3.15it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:22<00:06,  3.13it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:22<00:05,  3.15it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:22<00:05,  3.14it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:23<00:05,  3.15it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:23<00:04,  3.15it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:23<00:04,  3.16it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:24<00:04,  3.16it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:24<00:03,  3.14it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:24<00:03,  3.15it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:25<00:03,  3.13it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:25<00:02,  3.12it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:25<00:02,  3.14it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:26<00:02,  3.13it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:26<00:01,  3.14it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:26<00:01,  3.15it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:27<00:01,  3.15it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:27<00:00,  3.16it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:27<00:00,  3.13it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:28<00:00,  3.12it/s]\u001b[A\n",
      "Epoch:  90%|█████████ | 9/10 [13:21<01:28, 88.72s/it]52it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:20,  3.22it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:20,  3.21it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:20,  3.20it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:20,  3.19it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:20,  3.18it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:20,  3.15it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:20,  3.16it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:19,  3.16it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:19,  3.16it/s]\u001b[AI1018 11:16:23.988652 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2350/config.json\n",
      "I1018 11:16:25.216326 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2350/pytorch_model.bin\n",
      "I1018 11:16:25.220983 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2350\n",
      "\n",
      "Iteration:   4%|▍         | 10/260 [00:04<02:51,  1.46it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:04<02:22,  1.75it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:05<02:02,  2.02it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:05<01:49,  2.26it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:05<01:40,  2.46it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:05<01:33,  2.62it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:06<01:28,  2.75it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:06<01:24,  2.86it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:06<01:22,  2.93it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:07<01:20,  2.99it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:07<01:18,  3.05it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:07<01:18,  3.06it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:08<01:17,  3.07it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:08<01:16,  3.11it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:08<01:15,  3.13it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:09<01:14,  3.15it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:09<01:13,  3.16it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:09<01:13,  3.17it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:10<01:13,  3.18it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:10<01:12,  3.18it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:10<01:12,  3.16it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:11<01:12,  3.16it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:11<01:12,  3.17it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:11<01:11,  3.17it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:11<01:11,  3.17it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:12<01:11,  3.17it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:12<01:10,  3.17it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:12<01:10,  3.17it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:13<01:10,  3.14it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:13<01:10,  3.15it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:13<01:09,  3.15it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:14<01:09,  3.16it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:09,  3.14it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:08,  3.16it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:15<01:08,  3.17it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:07,  3.17it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:07,  3.18it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:16<01:07,  3.16it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:06,  3.17it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:06,  3.17it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:17<01:06,  3.18it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:05,  3.18it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:05,  3.16it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:18<01:05,  3.16it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:05,  3.17it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:04,  3.17it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:04,  3.17it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:04,  3.17it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:03,  3.17it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:03,  3.17it/s]\u001b[AI1018 11:16:41.042737 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2400/config.json\n",
      "I1018 11:16:42.267381 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2400/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1018 11:16:42.271046 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2400\n",
      "\n",
      "Iteration:  23%|██▎       | 60/260 [00:21<02:17,  1.46it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:21<01:53,  1.75it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:22<01:38,  2.01it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:22<01:27,  2.26it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:22<01:19,  2.47it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:23<01:13,  2.65it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:23<01:09,  2.78it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:23<01:06,  2.89it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:23<01:04,  2.97it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:24<01:03,  3.00it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:24<01:02,  3.06it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:24<01:01,  3.10it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:25<01:00,  3.12it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:25<00:59,  3.15it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:25<00:59,  3.13it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:26<00:58,  3.15it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:26<00:58,  3.16it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:26<00:57,  3.17it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:27<00:57,  3.18it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:27<00:56,  3.18it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:27<00:56,  3.18it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:28<00:56,  3.19it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:28<00:55,  3.19it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:28<00:55,  3.19it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:29<00:55,  3.19it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:29<00:54,  3.19it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:29<00:55,  3.16it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:29<00:54,  3.17it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:30<00:54,  3.17it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:30<00:53,  3.17it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:30<00:53,  3.17it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:31<00:53,  3.17it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<00:52,  3.17it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:31<00:52,  3.17it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:32<00:52,  3.17it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:32<00:52,  3.17it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:32<00:51,  3.17it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:33<00:51,  3.17it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:33<00:51,  3.17it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:33<00:50,  3.17it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<00:50,  3.14it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<00:50,  3.13it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<00:50,  3.12it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:35<00:49,  3.14it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<00:49,  3.16it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:35<00:48,  3.17it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:35<00:48,  3.17it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:48,  3.18it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:36<00:48,  3.16it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:36<00:47,  3.16it/s]\u001b[AI1018 11:16:58.057547 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2450/config.json\n",
      "I1018 11:16:59.281773 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2450/pytorch_model.bin\n",
      "I1018 11:16:59.284872 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2450\n",
      "\n",
      "Iteration:  42%|████▏     | 110/260 [00:38<01:42,  1.46it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:38<01:25,  1.75it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:39<01:13,  2.02it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:39<01:04,  2.27it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:39<00:58,  2.48it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:40<00:54,  2.65it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:40<00:51,  2.79it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:40<00:49,  2.87it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:40<00:48,  2.95it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:41<00:46,  3.02it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:41<00:46,  3.03it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:41<00:45,  3.08it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:42<00:44,  3.08it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:42<00:43,  3.12it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:42<00:43,  3.14it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:43<00:42,  3.15it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:43<00:42,  3.14it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:43<00:42,  3.12it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:44<00:42,  3.13it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:44<00:41,  3.14it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:44<00:41,  3.15it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:45<00:40,  3.16it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:45<00:40,  3.16it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:45<00:40,  3.16it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:46<00:39,  3.17it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:46<00:39,  3.17it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:46<00:39,  3.17it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:47<00:38,  3.17it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:47<00:38,  3.17it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:47<00:38,  3.17it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:47<00:37,  3.17it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:48<00:37,  3.17it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:48<00:37,  3.17it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:48<00:36,  3.17it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:49<00:36,  3.17it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:49<00:36,  3.17it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:49<00:35,  3.17it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:50<00:35,  3.17it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:50<00:35,  3.17it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:50<00:35,  3.14it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<00:34,  3.16it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:51<00:34,  3.14it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:51<00:34,  3.15it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:33,  3.16it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:33,  3.17it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:52<00:33,  3.18it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:53<00:32,  3.15it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:53<00:32,  3.16it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:53<00:32,  3.16it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:53<00:32,  3.14it/s]\u001b[AI1018 11:17:15.118674 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2500/config.json\n",
      "I1018 11:17:16.342919 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2500/pytorch_model.bin\n",
      "I1018 11:17:16.345659 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2500\n",
      "\n",
      "Iteration:  62%|██████▏   | 160/260 [00:55<01:08,  1.45it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:55<00:57,  1.73it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:56<00:49,  2.00it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:56<00:43,  2.25it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:56<00:38,  2.46it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:57<00:36,  2.62it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:57<00:34,  2.76it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:57<00:32,  2.87it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:58<00:31,  2.96it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:58<00:30,  3.02it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:58<00:29,  3.06it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:59<00:28,  3.09it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:59<00:28,  3.09it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:59<00:27,  3.12it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:59<00:27,  3.14it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [01:00<00:26,  3.15it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [01:00<00:26,  3.17it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [01:00<00:26,  3.17it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:01<00:25,  3.18it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:01<00:25,  3.18it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:01<00:25,  3.19it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:02<00:24,  3.19it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:02<00:24,  3.19it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:02<00:24,  3.17it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:03<00:23,  3.18it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:03<00:23,  3.18it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:03<00:23,  3.16it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:04<00:23,  3.16it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:04<00:22,  3.16it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:04<00:22,  3.14it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:05<00:22,  3.15it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:05<00:21,  3.15it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:05<00:21,  3.13it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:05<00:21,  3.15it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:06<00:20,  3.16it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:06<00:20,  3.17it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:06<00:20,  3.18it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:07<00:19,  3.18it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:07<00:19,  3.19it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:07<00:19,  3.19it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:08<00:18,  3.16it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:08<00:18,  3.17it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:08<00:18,  3.18it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:09<00:17,  3.18it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:09<00:17,  3.18it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:09<00:17,  3.19it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:17,  3.16it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:10<00:16,  3.14it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:10<00:16,  3.12it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:11<00:16,  3.14it/s]\u001b[AI1018 11:17:32.153486 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2550/config.json\n",
      "I1018 11:17:33.378884 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2550/pytorch_model.bin\n",
      "I1018 11:17:33.381748 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2550\n",
      "\n",
      "Iteration:  81%|████████  | 210/260 [01:12<00:34,  1.46it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:12<00:28,  1.75it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:13<00:23,  2.02it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:13<00:20,  2.28it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:13<00:18,  2.49it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:14<00:16,  2.67it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:14<00:15,  2.80it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:14<00:14,  2.89it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:15<00:14,  2.97it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:15<00:13,  3.04it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:15<00:12,  3.08it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:15<00:12,  3.12it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:16<00:12,  3.14it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:16<00:11,  3.15it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:16<00:11,  3.17it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:17<00:11,  3.18it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:17<00:10,  3.18it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:17<00:10,  3.19it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:18<00:10,  3.19it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:18<00:09,  3.19it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:18<00:09,  3.19it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:19<00:09,  3.19it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:19<00:08,  3.19it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:19<00:08,  3.19it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:20<00:08,  3.19it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:20<00:07,  3.19it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:20<00:07,  3.19it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:21<00:07,  3.19it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:21<00:06,  3.19it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:21<00:06,  3.19it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:21<00:06,  3.19it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:22<00:05,  3.19it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:22<00:05,  3.19it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:22<00:05,  3.19it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:23<00:05,  3.19it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:23<00:04,  3.19it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:23<00:04,  3.19it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:24<00:04,  3.19it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:24<00:03,  3.19it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:24<00:03,  3.19it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:25<00:03,  3.19it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:25<00:02,  3.19it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:25<00:02,  3.16it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:26<00:02,  3.14it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:26<00:01,  3.15it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:26<00:01,  3.16it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:26<00:01,  3.16it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:27<00:00,  3.17it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:27<00:00,  3.14it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:27<00:00,  3.15it/s]\u001b[AI1018 11:17:48.969139 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/checkpoint-2600/config.json\n",
      "I1018 11:17:50.194152 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/checkpoint-2600/pytorch_model.bin\n",
      "I1018 11:17:50.197000 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual/checkpoint-2600\n",
      "\n",
      "Epoch: 100%|██████████| 10/10 [14:51<00:00, 88.92s/it]4it/s]\u001b[A\n",
      "I1018 11:17:50.203245 47382659590592 <ipython-input-15-fb4439387059>:148]  global_step = 2600, average loss = 0.12190617550307742\n",
      "I1018 11:17:50.204020 47382659590592 <ipython-input-15-fb4439387059>:157] Saving model checkpoint to bert_output_multilingual\n",
      "I1018 11:17:50.206910 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual/config.json\n",
      "I1018 11:17:51.427004 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual/pytorch_model.bin\n",
      "I1018 11:17:51.613194 47382659590592 configuration_utils.py:148] loading configuration file bert_output_multilingual/config.json\n",
      "I1018 11:17:51.615020 47382659590592 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "I1018 11:17:51.616468 47382659590592 modeling_utils.py:334] loading weights file bert_output_multilingual/pytorch_model.bin\n",
      "I1018 11:17:56.835021 47382659590592 tokenization_utils.py:306] Model name 'bert_output_multilingual' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_output_multilingual' is a path or url to a directory containing tokenizer files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1018 11:17:56.837183 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual/vocab.txt\n",
      "I1018 11:17:56.837977 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual/added_tokens.json\n",
      "I1018 11:17:56.838762 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual/special_tokens_map.json\n",
      "I1018 11:17:56.839544 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual/tokenizer_config.json\n",
      "I1018 11:17:57.241410 47382659590592 tokenization_utils.py:306] Model name 'bert_output_multilingual' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_output_multilingual' is a path or url to a directory containing tokenizer files.\n",
      "I1018 11:17:57.243080 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual/vocab.txt\n",
      "I1018 11:17:57.243764 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual/added_tokens.json\n",
      "I1018 11:17:57.244529 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual/special_tokens_map.json\n",
      "I1018 11:17:57.245311 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual/tokenizer_config.json\n",
      "I1018 11:17:57.540187 47382659590592 <ipython-input-15-fb4439387059>:181] Evaluate the following checkpoints: ['bert_output_multilingual']\n",
      "I1018 11:17:57.541733 47382659590592 configuration_utils.py:148] loading configuration file bert_output_multilingual/config.json\n",
      "I1018 11:17:57.543002 47382659590592 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "I1018 11:17:57.544415 47382659590592 modeling_utils.py:334] loading weights file bert_output_multilingual/pytorch_model.bin\n",
      "I1018 11:18:02.832201 47382659590592 <ipython-input-14-5385282ede45>:18] Creating features from dataset file at dataset/0\n",
      "I1018 11:18:02.854369 47382659590592 <ipython-input-9-f72b0bac0eba>:48] Writing example 0\n",
      "I1018 11:18:02.857006 47382659590592 <ipython-input-9-f72b0bac0eba>:93] *** Example ***\n",
      "I1018 11:18:02.857851 47382659590592 <ipython-input-9-f72b0bac0eba>:94] guid: dev-0\n",
      "I1018 11:18:02.858677 47382659590592 <ipython-input-9-f72b0bac0eba>:95] input_ids: 101 23103 10589 34236 19777 28870 12286 47641 11360 53810 10189 39127 14224 12904 11270 38356 98680 10107 117 10751 174 11645 12078 15573 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.859558 47382659590592 <ipython-input-9-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.860429 47382659590592 <ipython-input-9-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.861254 47382659590592 <ipython-input-9-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1018 11:18:02.863800 47382659590592 <ipython-input-9-f72b0bac0eba>:93] *** Example ***\n",
      "I1018 11:18:02.864595 47382659590592 <ipython-input-9-f72b0bac0eba>:94] guid: dev-1\n",
      "I1018 11:18:02.865442 47382659590592 <ipython-input-9-f72b0bac0eba>:95] input_ids: 101 10751 10911 61105 59550 131 48164 12361 105826 44112 18206 10479 33626 12694 10114 31626 10950 11393 38969 10107 10529 31128 30241 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.866290 47382659590592 <ipython-input-9-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.867122 47382659590592 <ipython-input-9-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.867906 47382659590592 <ipython-input-9-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0']\n",
      "I1018 11:18:02.870350 47382659590592 <ipython-input-9-f72b0bac0eba>:93] *** Example ***\n",
      "I1018 11:18:02.871152 47382659590592 <ipython-input-9-f72b0bac0eba>:94] guid: dev-2\n",
      "I1018 11:18:02.871978 47382659590592 <ipython-input-9-f72b0bac0eba>:95] input_ids: 101 21573 14000 103730 10891 21998 10978 80870 10230 169 23103 10662 15485 11859 10525 28005 117 41256 12457 10114 21964 100 33003 46912 10147 123 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.872811 47382659590592 <ipython-input-9-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.873657 47382659590592 <ipython-input-9-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.874442 47382659590592 <ipython-input-9-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1018 11:18:02.876810 47382659590592 <ipython-input-9-f72b0bac0eba>:93] *** Example ***\n",
      "I1018 11:18:02.877607 47382659590592 <ipython-input-9-f72b0bac0eba>:94] guid: dev-3\n",
      "I1018 11:18:02.878438 47382659590592 <ipython-input-9-f72b0bac0eba>:95] input_ids: 101 25923 13918 119 24996 29479 10142 15485 11859 10525 10111 34174 25470 60805 10157 117 10374 103927 23103 10106 13596 25525 10939 45165 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.879281 47382659590592 <ipython-input-9-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1018 11:18:02.880110 47382659590592 <ipython-input-9-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.880890 47382659590592 <ipython-input-9-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '1.0', '1.0', '0.0', '0.0', '0.0', '0.0']\n",
      "I1018 11:18:02.883063 47382659590592 <ipython-input-9-f72b0bac0eba>:93] *** Example ***\n",
      "I1018 11:18:02.883855 47382659590592 <ipython-input-9-f72b0bac0eba>:94] guid: dev-4\n",
      "I1018 11:18:02.884680 47382659590592 <ipython-input-9-f72b0bac0eba>:95] input_ids: 101 15263 10817 19135 10950 23103 10114 20517 15045 13501 10188 44824 54617 12585 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.885524 47382659590592 <ipython-input-9-f72b0bac0eba>:96] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.886348 47382659590592 <ipython-input-9-f72b0bac0eba>:97] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1018 11:18:02.887133 47382659590592 <ipython-input-9-f72b0bac0eba>:98] label: ['0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0']\n",
      "I1018 11:18:03.261212 47382659590592 <ipython-input-14-5385282ede45>:34] Saving features into cached file dataset/0/cached_dev_bert-base-multilingual-cased_128_frame\n",
      "I1018 11:18:03.384685 47382659590592 <ipython-input-13-7f03f770a8ad>:19] ***** Running evaluation  *****\n",
      "I1018 11:18:03.385474 47382659590592 <ipython-input-13-7f03f770a8ad>:20]   Num examples = 263\n",
      "I1018 11:18:03.386325 47382659590592 <ipython-input-13-7f03f770a8ad>:21]   Batch size = 8\n",
      "Evaluating: 100%|██████████| 33/33 [00:04<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape:  (263, 9)\n",
      "out label ids:  (263, 9)\n",
      "[[0.02894791 0.01142441 0.01370138 0.87591076 0.11124873 0.03659159\n",
      "  0.01977966 0.11644205 0.0193496 ]\n",
      " [0.01905334 0.01243764 0.01313568 0.03438943 0.03945761 0.96375936\n",
      "  0.02917787 0.0193796  0.01566233]\n",
      " [0.11514848 0.00832808 0.33064416 0.00922505 0.7366859  0.00788109\n",
      "  0.0056989  0.03022168 0.020476  ]\n",
      " [0.0167553  0.01152406 0.00769181 0.5935508  0.39642456 0.0193103\n",
      "  0.01206285 0.09942636 0.01138808]\n",
      " [0.01432394 0.01374003 0.01780592 0.02361    0.02767337 0.9501454\n",
      "  0.02396477 0.01419782 0.01448279]]\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]]\n",
      "length:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1018 11:18:08.235924 47382659590592 <ipython-input-13-7f03f770a8ad>:93] ***** Eval results  *****\n",
      "I1018 11:18:08.236648 47382659590592 <ipython-input-13-7f03f770a8ad>:95]   auc = 0.9207217572548225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.9207217572548225}\n",
      "Hamming loss (proportion of wrong labels among all labels):  0.05449936628643853\n",
      "Exact match:  0.6920152091254753\n",
      "Number of articles with multiple frames:  59\n",
      "Accuracy among those:  0.4406779661016949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc_': 0.9207217572548225}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multilingual cased\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1018 11:55:15.582067 47382659590592 <ipython-input-15-fb4439387059>:110] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "I1018 11:55:15.684464 47382659590592 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json not found in cache or force_download set to True, downloading to /scratch/90046.1.kulisgpu-pub/tmpcx476wv_\n",
      "100%|██████████| 313/313 [00:00<00:00, 199637.64B/s]\n",
      "I1018 11:55:15.787593 47382659590592 file_utils.py:309] copying /scratch/90046.1.kulisgpu-pub/tmpcx476wv_ to cache at /usr4/cs591/akyurek/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I1018 11:55:15.790102 47382659590592 file_utils.py:313] creating metadata file for /usr4/cs591/akyurek/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I1018 11:55:15.792388 47382659590592 file_utils.py:322] removing temp file /scratch/90046.1.kulisgpu-pub/tmpcx476wv_\n",
      "I1018 11:55:15.793520 47382659590592 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I1018 11:55:15.794761 47382659590592 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I1018 11:55:15.880786 47382659590592 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt not found in cache or force_download set to True, downloading to /scratch/90046.1.kulisgpu-pub/tmp_3f4c0sw\n",
      "100%|██████████| 213450/213450 [00:00<00:00, 4765214.42B/s]\n",
      "I1018 11:55:16.017068 47382659590592 file_utils.py:309] copying /scratch/90046.1.kulisgpu-pub/tmp_3f4c0sw to cache at /usr4/cs591/akyurek/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "I1018 11:55:16.019963 47382659590592 file_utils.py:313] creating metadata file for /usr4/cs591/akyurek/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "I1018 11:55:16.022543 47382659590592 file_utils.py:322] removing temp file /scratch/90046.1.kulisgpu-pub/tmp_3f4c0sw\n",
      "I1018 11:55:16.023678 47382659590592 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "I1018 11:55:16.156167 47382659590592 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin not found in cache or force_download set to True, downloading to /scratch/90046.1.kulisgpu-pub/tmpe5q2_ot2\n",
      "100%|██████████| 435779157/435779157 [00:25<00:00, 17387830.85B/s]\n",
      "I1018 11:55:41.399032 47382659590592 file_utils.py:309] copying /scratch/90046.1.kulisgpu-pub/tmpe5q2_ot2 to cache at /usr4/cs591/akyurek/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "I1018 11:55:42.193023 47382659590592 file_utils.py:313] creating metadata file for /usr4/cs591/akyurek/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "I1018 11:55:42.195885 47382659590592 file_utils.py:322] removing temp file /scratch/90046.1.kulisgpu-pub/tmpe5q2_ot2\n",
      "I1018 11:55:42.287712 47382659590592 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "I1018 11:55:45.693367 47382659590592 modeling_utils.py:405] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1018 11:55:45.694496 47382659590592 modeling_utils.py:408] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1018 11:55:45.766996 47382659590592 <ipython-input-15-fb4439387059>:141] Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='/projectnb/llamagrp/feyzanb', config_name='', data_dir='dataset/0', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-cased', model_type='bertmultilabel', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='bert_output', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=50, seed=42, server_ip='', server_port='', task_name='frame', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "I1018 11:55:45.771150 47382659590592 <ipython-input-14-5385282ede45>:15] Loading features from cached file dataset/0/cached_train_bert-base-cased_128_frame\n",
      "I1018 11:55:45.989309 47382659590592 <ipython-input-11-ce0a3a7e9c33>:42] ***** Running training *****\n",
      "I1018 11:55:45.990311 47382659590592 <ipython-input-11-ce0a3a7e9c33>:43]   Num examples = 1037\n",
      "I1018 11:55:45.991140 47382659590592 <ipython-input-11-ce0a3a7e9c33>:44]   Num Epochs = 10\n",
      "I1018 11:55:45.991930 47382659590592 <ipython-input-11-ce0a3a7e9c33>:45]   Instantaneous batch size per GPU = 4\n",
      "I1018 11:55:45.992691 47382659590592 <ipython-input-11-ce0a3a7e9c33>:47]   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "I1018 11:55:45.993462 47382659590592 <ipython-input-11-ce0a3a7e9c33>:48]   Gradient Accumulation steps = 1\n",
      "I1018 11:55:45.994220 47382659590592 <ipython-input-11-ce0a3a7e9c33>:49]   Total optimization steps = 2600\n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:08,  3.75it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:09,  3.70it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:09,  3.67it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:10,  3.64it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:10,  3.62it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:10,  3.62it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:09,  3.62it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:09,  3.61it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:09,  3.60it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:09,  3.60it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:09,  3.60it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:08,  3.60it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:08,  3.59it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:08,  3.60it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   6%|▌         | 15/260 [00:04<01:08,  3.60it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:07,  3.59it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:07,  3.59it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:07,  3.59it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:07,  3.59it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:05<01:06,  3.59it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:05<01:06,  3.59it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:06,  3.59it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:05,  3.60it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:06<01:05,  3.59it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:06<01:05,  3.59it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:05,  3.60it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:04,  3.60it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:07<01:04,  3.59it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:04,  3.59it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:03,  3.60it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:08<01:03,  3.60it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:08<01:03,  3.59it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:03,  3.59it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:02,  3.60it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:09<01:02,  3.60it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:02,  3.59it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:02,  3.59it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:10<01:01,  3.60it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:10<01:01,  3.60it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:01,  3.59it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<01:01,  3.59it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:11<01:00,  3.59it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:11<01:00,  3.60it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<01:00,  3.59it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:12<00:59,  3.59it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:12<00:59,  3.59it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:59,  3.60it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:59,  3.59it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:13<00:58,  3.59it/s]\u001b[AI1018 11:55:59.908193 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-50/config.json\n",
      "I1018 11:56:00.578510 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-50/pytorch_model.bin\n",
      "I1018 11:56:00.589569 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-50\n",
      "\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<01:41,  2.07it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<01:27,  2.38it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:15<01:18,  2.65it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<01:12,  2.87it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<01:07,  3.06it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<01:03,  3.21it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<01:01,  3.31it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<01:00,  3.38it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:58,  3.45it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:17<00:57,  3.49it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:56,  3.51it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:56,  3.53it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:55,  3.56it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:18<00:55,  3.57it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:54,  3.57it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:54,  3.57it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:19<00:54,  3.58it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:53,  3.59it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:53,  3.59it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:53,  3.59it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:20<00:52,  3.59it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:52,  3.60it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:20<00:52,  3.59it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:20<00:52,  3.59it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<00:51,  3.59it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:51,  3.60it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:21<00:51,  3.59it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:51,  3.59it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:50,  3.59it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:50,  3.60it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:22<00:50,  3.59it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<00:49,  3.59it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:49,  3.59it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:23<00:49,  3.60it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:48,  3.59it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:48,  3.59it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:48,  3.60it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:24<00:48,  3.60it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:47,  3.59it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:47,  3.59it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:25<00:47,  3.60it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:25<00:46,  3.60it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<00:46,  3.60it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:46,  3.59it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:26<00:46,  3.60it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:45,  3.60it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:27<00:45,  3.60it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:27<00:45,  3.59it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:27<00:45,  3.60it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:44,  3.60it/s]\u001b[AI1018 11:56:14.501163 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-100/config.json\n",
      "I1018 11:56:15.149720 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-100/pytorch_model.bin\n",
      "I1018 11:56:15.154423 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-100\n",
      "\n",
      "Iteration:  38%|███▊      | 100/260 [00:29<01:16,  2.10it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:29<01:05,  2.41it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:58,  2.68it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:53,  2.92it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:30<00:50,  3.10it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:48,  3.23it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:46,  3.33it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:31<00:44,  3.41it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:31<00:43,  3.47it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:43,  3.50it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:31<00:42,  3.52it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:32<00:42,  3.54it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:41,  3.56it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:41,  3.57it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:33<00:40,  3.58it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:33<00:40,  3.59it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:40,  3.59it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:39,  3.59it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:34<00:39,  3.59it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:34<00:39,  3.59it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:38,  3.60it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:34<00:38,  3.59it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:35<00:38,  3.59it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:38,  3.59it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:35<00:37,  3.60it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:37,  3.59it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:37,  3.59it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:37,  3.59it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:36<00:36,  3.60it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:37<00:36,  3.59it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:37<00:36,  3.59it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:35,  3.60it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:35,  3.60it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:35,  3.59it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:35,  3.59it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:38<00:34,  3.60it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:34,  3.60it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:34,  3.60it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:33,  3.60it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:39<00:33,  3.60it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:33,  3.60it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:40<00:33,  3.60it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:40<00:32,  3.59it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:32,  3.60it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:41<00:32,  3.60it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:41<00:32,  3.59it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:41<00:31,  3.59it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:31,  3.59it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:42<00:31,  3.60it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:42<00:30,  3.59it/s]\u001b[AI1018 11:56:29.058337 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-150/config.json\n",
      "I1018 11:56:29.709372 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-150/pytorch_model.bin\n",
      "I1018 11:56:29.713361 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-150\n",
      "\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:52,  2.09it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:43<00:45,  2.41it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:44<00:40,  2.68it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:44<00:36,  2.89it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:34,  3.07it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:45<00:32,  3.21it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:45<00:31,  3.32it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:30,  3.40it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:45<00:29,  3.45it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:46<00:28,  3.49it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:46<00:28,  3.53it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:27,  3.54it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:47<00:27,  3.55it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:47<00:27,  3.57it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:47<00:26,  3.58it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:47<00:26,  3.58it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:48<00:26,  3.58it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:48<00:25,  3.59it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:48<00:25,  3.60it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:48<00:25,  3.59it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:49<00:25,  3.59it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:49<00:24,  3.60it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:49<00:24,  3.60it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:50<00:24,  3.59it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:50<00:23,  3.59it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:50<00:23,  3.59it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:50<00:23,  3.60it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:51<00:23,  3.59it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:51<00:22,  3.59it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:51<00:22,  3.60it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:52<00:22,  3.60it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:21,  3.59it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:52<00:21,  3.59it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:52<00:21,  3.59it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:21,  3.60it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:53<00:20,  3.59it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:53<00:20,  3.59it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:53<00:20,  3.59it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:20,  3.60it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:54<00:19,  3.59it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:54<00:19,  3.59it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:55<00:19,  3.59it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:55<00:18,  3.60it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:55<00:18,  3.59it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:55<00:18,  3.59it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:18,  3.59it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:56<00:17,  3.60it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:56<00:17,  3.59it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:57<00:17,  3.59it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:16,  3.59it/s]\u001b[AI1018 11:56:43.621878 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-200/config.json\n",
      "I1018 11:56:44.267407 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-200/pytorch_model.bin\n",
      "I1018 11:56:44.271661 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-200\n",
      "\n",
      "Iteration:  77%|███████▋  | 200/260 [00:58<00:28,  2.11it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:58<00:24,  2.42it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:58<00:21,  2.68it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:59<00:19,  2.91it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:59<00:18,  3.09it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:59<00:17,  3.22it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:59<00:16,  3.32it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:00<00:15,  3.40it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:00<00:15,  3.46it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:00<00:14,  3.50it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:01<00:14,  3.52it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:01<00:13,  3.55it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:01<00:13,  3.57it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:01<00:13,  3.57it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:02<00:12,  3.57it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:02<00:12,  3.58it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:02<00:12,  3.59it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:02<00:11,  3.59it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:03<00:11,  3.59it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:03<00:11,  3.59it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:03<00:11,  3.59it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:04<00:10,  3.59it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:04<00:10,  3.59it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:04<00:10,  3.60it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:04<00:09,  3.60it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:05<00:09,  3.59it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:05<00:09,  3.59it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:05<00:09,  3.60it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:06<00:08,  3.61it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:06<00:08,  3.60it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:06<00:08,  3.59it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:06<00:08,  3.60it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:07<00:07,  3.60it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:07<00:07,  3.60it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:07<00:07,  3.60it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:07<00:06,  3.60it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:08<00:06,  3.60it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:08<00:06,  3.60it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:08<00:06,  3.59it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:09<00:05,  3.60it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:09<00:05,  3.60it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:09<00:05,  3.59it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:09<00:05,  3.59it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:10<00:04,  3.59it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:10<00:04,  3.60it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:10<00:04,  3.59it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:11<00:03,  3.59it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:11<00:03,  3.59it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  95%|█████████▌| 248/260 [01:11<00:03,  3.60it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:11<00:03,  3.59it/s]\u001b[AI1018 11:56:58.177762 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-250/config.json\n",
      "I1018 11:56:58.825738 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-250/pytorch_model.bin\n",
      "I1018 11:56:58.829818 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-250\n",
      "\n",
      "Iteration:  96%|█████████▌| 250/260 [01:12<00:04,  2.10it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:13<00:03,  2.42it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:13<00:02,  2.68it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:13<00:02,  2.90it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:13<00:01,  3.08it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:14<00:01,  3.22it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:14<00:01,  3.33it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:14<00:00,  3.40it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:15<00:00,  3.45it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:15<00:00,  3.50it/s]\u001b[A\n",
      "Epoch:  10%|█         | 1/10 [01:15<11:19, 75.49s/it]02it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:10,  3.68it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:10,  3.66it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:10,  3.63it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:10,  3.62it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:10,  3.62it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:10,  3.62it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:10,  3.60it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:10,  3.60it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:09,  3.61it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:09,  3.61it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:09,  3.60it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:08,  3.60it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:08,  3.60it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:08,  3.60it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:08,  3.60it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:07,  3.59it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:07,  3.60it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:07,  3.60it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:07,  3.59it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:05<01:06,  3.59it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:05<01:06,  3.59it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:06,  3.60it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:05,  3.59it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:06<01:05,  3.59it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:06<01:05,  3.59it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:05,  3.60it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:04,  3.59it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:07<01:04,  3.59it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:04,  3.59it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:03,  3.60it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:08<01:03,  3.59it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:08<01:03,  3.59it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:03,  3.59it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:02,  3.60it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:09<01:02,  3.60it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:02,  3.59it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:01,  3.60it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:10<01:01,  3.60it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:10<01:01,  3.60it/s]\u001b[AI1018 11:57:12.619229 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-300/config.json\n",
      "I1018 11:57:13.295452 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-300/pytorch_model.bin\n",
      "I1018 11:57:13.302337 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-300\n",
      "\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:46,  2.06it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:12<01:32,  2.37it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<01:22,  2.65it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<01:15,  2.87it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<01:10,  3.05it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:13<01:07,  3.20it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<01:04,  3.31it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<01:02,  3.39it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:14<01:01,  3.45it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<01:00,  3.49it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:59,  3.53it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:58,  3.54it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:15<00:58,  3.56it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:57,  3.57it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:57,  3.58it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:57,  3.58it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<00:56,  3.58it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:56,  3.59it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:56,  3.60it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:17<00:55,  3.59it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:55,  3.59it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:55,  3.59it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:55,  3.60it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:18<00:54,  3.59it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:54,  3.59it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:54,  3.60it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:19<00:53,  3.60it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:53,  3.60it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:53,  3.59it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:53,  3.60it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:20<00:52,  3.60it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:52,  3.59it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:20<00:52,  3.59it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:20<00:51,  3.60it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<00:51,  3.60it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:51,  3.60it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:21<00:51,  3.59it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:50,  3.60it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:50,  3.60it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:50,  3.60it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:22<00:50,  3.59it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<00:49,  3.60it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:49,  3.63it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:23<00:48,  3.62it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:48,  3.61it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:48,  3.60it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:48,  3.61it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:24<00:47,  3.61it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:47,  3.60it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:47,  3.60it/s]\u001b[AI1018 11:57:27.194512 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-350/config.json\n",
      "I1018 11:57:27.840096 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-350/pytorch_model.bin\n",
      "I1018 11:57:27.845431 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-350\n",
      "\n",
      "Iteration:  35%|███▍      | 90/260 [00:26<01:20,  2.11it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<01:09,  2.42it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<01:02,  2.68it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:27<00:57,  2.90it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:53,  3.08it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:51,  3.22it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:28<00:49,  3.32it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:28<00:48,  3.39it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:46,  3.46it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:45,  3.50it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:29<00:45,  3.53it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:29<00:44,  3.54it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:44,  3.57it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:43,  3.58it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:30<00:43,  3.58it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:43,  3.58it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:42,  3.59it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:31<00:42,  3.60it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:31<00:42,  3.59it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:42,  3.58it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:31<00:41,  3.60it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:32<00:41,  3.60it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:41,  3.59it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:40,  3.59it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:33<00:40,  3.59it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:33<00:40,  3.60it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:40,  3.59it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:39,  3.59it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:34<00:39,  3.59it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:34<00:39,  3.60it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:38,  3.59it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:34<00:38,  3.59it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:35<00:38,  3.59it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:38,  3.60it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:35<00:37,  3.59it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:37,  3.59it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:37,  3.60it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:36,  3.60it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:36<00:36,  3.60it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:37<00:36,  3.59it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:37<00:36,  3.60it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:35,  3.60it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:35,  3.60it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:35,  3.59it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:35,  3.60it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:38<00:34,  3.60it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:34,  3.59it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:34,  3.59it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:33,  3.60it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:39<00:33,  3.60it/s]\u001b[AI1018 11:57:41.752094 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-400/config.json\n",
      "I1018 11:57:42.400079 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-400/pytorch_model.bin\n",
      "I1018 11:57:42.405204 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-400\n",
      "\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:57,  2.10it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:41<00:49,  2.41it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:41<00:44,  2.68it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:40,  2.90it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:42<00:37,  3.08it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:42<00:35,  3.21it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:42<00:34,  3.32it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:33,  3.41it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:43<00:32,  3.46it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:43<00:31,  3.51it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:31,  3.53it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:43<00:30,  3.56it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:44<00:30,  3.57it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:44<00:29,  3.57it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:29,  3.58it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:45<00:29,  3.59it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:45<00:28,  3.59it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:28,  3.59it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:45<00:28,  3.59it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:46<00:28,  3.59it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:46<00:27,  3.62it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:27,  3.62it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:47<00:27,  3.61it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:47<00:26,  3.60it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:47<00:26,  3.60it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:47<00:26,  3.61it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:48<00:26,  3.60it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:48<00:25,  3.59it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:48<00:25,  3.60it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:48<00:25,  3.60it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:49<00:25,  3.59it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:49<00:24,  3.59it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:49<00:24,  3.59it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:50<00:24,  3.60it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:50<00:23,  3.59it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:50<00:23,  3.59it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:50<00:23,  3.59it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:51<00:23,  3.60it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:51<00:22,  3.59it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:51<00:22,  3.59it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:52<00:22,  3.59it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:21,  3.60it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:52<00:21,  3.62it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:52<00:21,  3.61it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:21,  3.60it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:53<00:20,  3.60it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:53<00:20,  3.60it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:53<00:20,  3.60it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:20,  3.59it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:54<00:19,  3.60it/s]\u001b[AI1018 11:57:56.293116 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-450/config.json\n",
      "I1018 11:57:56.941385 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-450/pytorch_model.bin\n",
      "I1018 11:57:56.946171 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-450\n",
      "\n",
      "Iteration:  73%|███████▎  | 190/260 [00:55<00:33,  2.11it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:55<00:28,  2.42it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:56<00:25,  2.68it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:56<00:23,  2.90it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:56<00:21,  3.08it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:20,  3.21it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:57<00:19,  3.31it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:57<00:18,  3.40it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:57<00:17,  3.46it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:17,  3.49it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:58<00:17,  3.51it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:58<00:16,  3.55it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:58<00:16,  3.57it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:59<00:15,  3.57it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:59<00:15,  3.57it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:59<00:15,  3.58it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:59<00:15,  3.59it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:00<00:14,  3.59it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:00<00:14,  3.61it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:00<00:14,  3.60it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:01<00:13,  3.60it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:01<00:13,  3.61it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:01<00:13,  3.60it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:01<00:13,  3.60it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  82%|████████▏ | 214/260 [01:02<00:12,  3.60it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:02<00:12,  3.60it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:02<00:12,  3.59it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:02<00:11,  3.59it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:03<00:11,  3.59it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:03<00:11,  3.60it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:03<00:11,  3.59it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:04<00:10,  3.59it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:04<00:10,  3.59it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:04<00:10,  3.60it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:04<00:10,  3.58it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:05<00:09,  3.58it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:05<00:09,  3.59it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:05<00:09,  3.60it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:06<00:08,  3.59it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:06<00:08,  3.59it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:06<00:08,  3.59it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:06<00:08,  3.60it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:07<00:07,  3.59it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:07<00:07,  3.58it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:07<00:07,  3.59it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:07<00:06,  3.60it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:08<00:06,  3.59it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:08<00:06,  3.58it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:08<00:06,  3.59it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:09<00:05,  3.59it/s]\u001b[AI1018 11:58:10.859856 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-500/config.json\n",
      "I1018 11:58:11.527786 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-500/pytorch_model.bin\n",
      "I1018 11:58:11.532588 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-500\n",
      "\n",
      "Iteration:  92%|█████████▏| 240/260 [01:10<00:09,  2.07it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:10<00:07,  2.39it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:10<00:06,  2.66it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:10<00:05,  2.88it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:11<00:05,  3.06it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:11<00:04,  3.20it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:11<00:04,  3.31it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:11<00:03,  3.39it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:12<00:03,  3.44it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:12<00:03,  3.48it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:12<00:02,  3.54it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:13<00:02,  3.56it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:13<00:02,  3.57it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:13<00:01,  3.57it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:13<00:01,  3.57it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:14<00:01,  3.59it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:14<00:01,  3.59it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:14<00:00,  3.59it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:15<00:00,  3.59it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:15<00:00,  3.59it/s]\u001b[A\n",
      "Epoch:  20%|██        | 2/10 [02:30<10:03, 75.49s/it]11it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:10,  3.67it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:10,  3.67it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:09,  3.68it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:10,  3.66it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:10,  3.63it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:10,  3.61it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:10,  3.61it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:09,  3.60it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:09,  3.62it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:09,  3.61it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:08,  3.62it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:08,  3.63it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:08,  3.61it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:08,  3.61it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:07,  3.61it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:07,  3.62it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:07,  3.61it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:07,  3.60it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:06,  3.60it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:05<01:06,  3.60it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:05<01:06,  3.62it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:06,  3.60it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:05,  3.60it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:06<01:05,  3.60it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:06<01:05,  3.60it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:05,  3.59it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:04,  3.59it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:07<01:04,  3.59it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:03,  3.63it/s]\u001b[AI1018 11:58:25.295917 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-550/config.json\n",
      "I1018 11:58:26.016377 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-550/pytorch_model.bin\n",
      "I1018 11:58:26.025218 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-550\n",
      "\n",
      "Iteration:  12%|█▏        | 30/260 [00:09<01:55,  2.00it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:38,  2.32it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:28,  2.59it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:20,  2.83it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:14,  3.02it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:11,  3.17it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:08,  3.28it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:06,  3.37it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:04,  3.44it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:11<01:03,  3.48it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:02,  3.51it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:12<01:01,  3.54it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<01:01,  3.56it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<01:00,  3.57it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<01:00,  3.57it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:13<00:59,  3.60it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<00:59,  3.60it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:59,  3.61it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:14<00:58,  3.60it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:58,  3.59it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:58,  3.60it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:58,  3.60it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:15<00:57,  3.59it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:57,  3.59it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:57,  3.59it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:57,  3.59it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<00:56,  3.59it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:56,  3.58it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:56,  3.59it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:17<00:55,  3.60it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:55,  3.61it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:55,  3.60it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:55,  3.59it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:18<00:54,  3.60it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:54,  3.62it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:53,  3.62it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:19<00:53,  3.60it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:53,  3.60it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:53,  3.62it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:52,  3.62it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:20<00:52,  3.61it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:52,  3.62it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:20<00:52,  3.61it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:20<00:51,  3.60it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<00:51,  3.60it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:50,  3.63it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:21<00:50,  3.62it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:50,  3.63it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:50,  3.62it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:50,  3.60it/s]\u001b[AI1018 11:58:39.974505 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-600/config.json\n",
      "I1018 11:58:40.622547 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-600/pytorch_model.bin\n",
      "I1018 11:58:40.627872 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-600\n",
      "\n",
      "Iteration:  31%|███       | 80/260 [00:23<01:29,  2.01it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<01:16,  2.34it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:24<01:08,  2.61it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:24<01:02,  2.84it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:58,  3.03it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:25<00:54,  3.20it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:25<00:52,  3.31it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:25<00:51,  3.38it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:50,  3.44it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:26<00:48,  3.51it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:26<00:47,  3.56it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<00:47,  3.57it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<00:46,  3.61it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:27<00:46,  3.61it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:46,  3.60it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:45,  3.62it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:28<00:45,  3.60it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:28<00:45,  3.60it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:44,  3.61it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:44,  3.60it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:29<00:44,  3.59it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:29<00:44,  3.59it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:43,  3.62it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:30<00:43,  3.62it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:30<00:43,  3.61it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:43,  3.60it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:42,  3.60it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:31<00:42,  3.60it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:31<00:42,  3.62it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:41,  3.63it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:31<00:41,  3.61it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:32<00:41,  3.60it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:41,  3.60it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:40,  3.60it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:33<00:40,  3.59it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:33<00:40,  3.59it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:40,  3.59it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:39,  3.60it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:34<00:39,  3.59it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:34<00:39,  3.59it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:38,  3.59it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:35<00:38,  3.62it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:35<00:37,  3.64it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:37,  3.63it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:35<00:37,  3.61it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:37,  3.62it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:37,  3.61it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:36,  3.61it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:36<00:36,  3.61it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:37<00:36,  3.60it/s]\u001b[AI1018 11:58:54.480176 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-650/config.json\n",
      "I1018 11:58:55.130225 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-650/pytorch_model.bin\n",
      "I1018 11:58:55.133573 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-650\n",
      "\n",
      "Iteration:  50%|█████     | 130/260 [00:38<01:01,  2.10it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:38<00:53,  2.42it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:47,  2.68it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:43,  2.90it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:39<00:40,  3.07it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:39<00:38,  3.22it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:37,  3.32it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:40<00:36,  3.40it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:40<00:35,  3.45it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:40<00:34,  3.50it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:34,  3.53it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:41<00:33,  3.54it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:41<00:33,  3.56it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:32,  3.57it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:42<00:32,  3.58it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:42<00:32,  3.58it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:42<00:31,  3.58it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:31,  3.61it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:43<00:31,  3.61it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:43<00:30,  3.61it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:30,  3.60it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:43<00:30,  3.59it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:44<00:29,  3.62it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:44<00:29,  3.64it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:29,  3.63it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:45<00:28,  3.62it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:45<00:28,  3.61it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:28,  3.60it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:45<00:28,  3.60it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:46<00:28,  3.60it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:46<00:27,  3.60it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:27,  3.62it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:47<00:27,  3.63it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:47<00:26,  3.64it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:47<00:26,  3.62it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:47<00:26,  3.64it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:48<00:25,  3.63it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:48<00:25,  3.62it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:48<00:25,  3.61it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:48<00:25,  3.60it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:49<00:25,  3.60it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:49<00:24,  3.60it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:49<00:24,  3.60it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:50<00:24,  3.59it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:50<00:23,  3.60it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:50<00:23,  3.60it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:50<00:23,  3.59it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:51<00:23,  3.59it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:51<00:22,  3.62it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:51<00:22,  3.61it/s]\u001b[AI1018 11:59:08.996693 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-700/config.json\n",
      "I1018 11:59:09.663444 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-700/pytorch_model.bin\n",
      "I1018 11:59:09.667858 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  69%|██████▉   | 180/260 [00:52<00:38,  2.08it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:32,  2.41it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:53<00:29,  2.68it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:53<00:26,  2.90it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:24,  3.08it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:54<00:23,  3.22it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:54<00:22,  3.33it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:54<00:21,  3.42it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:20,  3.47it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:55<00:20,  3.50it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:55<00:19,  3.53it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:55<00:19,  3.58it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:56<00:18,  3.58it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:56<00:18,  3.58it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:56<00:18,  3.58it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:18,  3.61it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:57<00:17,  3.63it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:57<00:17,  3.62it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:57<00:17,  3.62it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:16,  3.61it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:58<00:16,  3.60it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:58<00:16,  3.60it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:58<00:16,  3.61it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:59<00:15,  3.60it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:59<00:15,  3.59it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:59<00:15,  3.60it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:59<00:15,  3.60it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:00<00:14,  3.62it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:00<00:14,  3.60it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:00<00:14,  3.60it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:00<00:13,  3.60it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:01<00:13,  3.60it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:01<00:13,  3.62it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:01<00:13,  3.61it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:02<00:12,  3.60it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:02<00:12,  3.63it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:02<00:12,  3.62it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:02<00:11,  3.64it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:03<00:11,  3.63it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:03<00:11,  3.64it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:03<00:11,  3.62it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:04<00:10,  3.63it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:04<00:10,  3.61it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:04<00:10,  3.61it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:04<00:09,  3.61it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:05<00:09,  3.60it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:05<00:09,  3.59it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:05<00:09,  3.62it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:05<00:08,  3.62it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:06<00:08,  3.61it/s]\u001b[AI1018 11:59:23.507930 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-750/config.json\n",
      "I1018 11:59:24.154758 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-750/pytorch_model.bin\n",
      "I1018 11:59:24.159899 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-750\n",
      "\n",
      "Iteration:  88%|████████▊ | 230/260 [01:07<00:14,  2.10it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:07<00:12,  2.41it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:07<00:10,  2.68it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:08<00:09,  2.90it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:08<00:08,  3.08it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:08<00:07,  3.21it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:08<00:07,  3.32it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:09<00:06,  3.40it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:09<00:06,  3.45it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:09<00:05,  3.51it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:09<00:05,  3.55it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:10<00:05,  3.58it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:10<00:04,  3.60it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:10<00:04,  3.62it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:11<00:04,  3.63it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:11<00:04,  3.64it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:11<00:03,  3.64it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:11<00:03,  3.62it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:12<00:03,  3.62it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:12<00:03,  3.61it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:12<00:02,  3.60it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:12<00:02,  3.60it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:13<00:02,  3.62it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:13<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:13<00:01,  3.63it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:14<00:01,  3.62it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:14<00:01,  3.61it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:14<00:00,  3.60it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:14<00:00,  3.60it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:15<00:00,  3.60it/s]\u001b[A\n",
      "Epoch:  30%|███       | 3/10 [03:46<08:48, 75.45s/it]12it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:08,  3.77it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:09,  3.72it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:09,  3.70it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:09,  3.68it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:09,  3.65it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:09,  3.66it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:09,  3.63it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:09,  3.63it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:08,  3.64it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:08,  3.66it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:07,  3.67it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:07,  3.65it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:08,  3.63it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:08,  3.61it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:07,  3.61it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:07,  3.63it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:07,  3.62it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:07,  3.61it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:06,  3.60it/s]\u001b[AI1018 11:59:37.855280 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-800/config.json\n",
      "I1018 11:59:38.525172 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-800/pytorch_model.bin\n",
      "I1018 11:59:38.529212 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-800\n",
      "\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:55,  2.08it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:39,  2.39it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:29,  2.67it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:22,  2.89it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:16,  3.09it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:12,  3.22it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:10,  3.33it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:08,  3.41it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:06,  3.48it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:05,  3.51it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:04,  3.55it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:04,  3.56it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:03,  3.57it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:03,  3.58it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:03,  3.58it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:02,  3.58it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:02,  3.61it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:01,  3.63it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:01,  3.63it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:11<01:00,  3.64it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:00,  3.63it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<01:00,  3.62it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<01:00,  3.60it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<00:59,  3.63it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<00:59,  3.62it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:13<00:59,  3.62it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<00:59,  3.60it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:59,  3.59it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:58,  3.60it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:58,  3.62it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:57,  3.64it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:57,  3.65it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:15<00:56,  3.66it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:56,  3.64it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:56,  3.62it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:56,  3.61it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<00:56,  3.60it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:55,  3.63it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:55,  3.62it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:16<00:55,  3.63it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:55,  3.62it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:55,  3.61it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:54,  3.63it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:18<00:54,  3.65it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:53,  3.63it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:53,  3.65it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:18<00:53,  3.64it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:52,  3.64it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:53,  3.62it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:52,  3.61it/s]\u001b[AI1018 11:59:52.333242 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-850/config.json\n",
      "I1018 11:59:52.987987 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-850/pytorch_model.bin\n",
      "I1018 11:59:52.992227 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-850\n",
      "\n",
      "Iteration:  27%|██▋       | 70/260 [00:20<01:30,  2.10it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<01:18,  2.42it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:21<01:10,  2.68it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:21<01:04,  2.90it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<01:00,  3.09it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:22<00:57,  3.22it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:22<00:54,  3.35it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:53,  3.45it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:51,  3.51it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:23<00:50,  3.56it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:23<00:50,  3.58it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<00:49,  3.58it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:49,  3.58it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:24<00:49,  3.58it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:49,  3.59it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:48,  3.62it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:25<00:48,  3.62it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:25<00:48,  3.60it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:47,  3.59it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:47,  3.62it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:26<00:46,  3.62it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<00:46,  3.61it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<00:46,  3.63it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:46,  3.61it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:46,  3.60it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:45,  3.63it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:27<00:45,  3.62it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:28<00:45,  3.62it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:44,  3.63it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:44,  3.61it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:28<00:44,  3.60it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:29<00:44,  3.60it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:43,  3.63it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:43,  3.62it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:30<00:43,  3.60it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:42,  3.62it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:42,  3.61it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:30<00:42,  3.61it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:31<00:42,  3.61it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:41,  3.60it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:31<00:41,  3.61it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:31<00:41,  3.63it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:40,  3.61it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:40,  3.63it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:32<00:40,  3.62it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:33<00:39,  3.64it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:39,  3.63it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:39,  3.61it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:33<00:39,  3.63it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:34<00:38,  3.64it/s]\u001b[AI1018 12:00:06.798425 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-900/config.json\n",
      "I1018 12:00:07.466632 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-900/pytorch_model.bin\n",
      "I1018 12:00:07.470583 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-900\n",
      "\n",
      "Iteration:  46%|████▌     | 120/260 [00:35<01:07,  2.09it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:35<00:57,  2.40it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:35<00:51,  2.67it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:47,  2.91it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:36<00:44,  3.09it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:41,  3.24it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:39,  3.35it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:37<00:38,  3.42it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:37<00:38,  3.46it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:37<00:37,  3.51it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:37<00:36,  3.56it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:38<00:36,  3.57it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:35,  3.57it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:35,  3.60it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:34,  3.61it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:39<00:34,  3.62it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:34,  3.61it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:33,  3.63it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:40<00:33,  3.65it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:40<00:33,  3.64it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:33,  3.63it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:40<00:32,  3.61it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:41<00:32,  3.62it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:32,  3.61it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:41<00:32,  3.61it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:42<00:31,  3.61it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:42<00:31,  3.60it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:31,  3.62it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:42<00:31,  3.60it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:43<00:30,  3.60it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:30,  3.60it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:43<00:30,  3.60it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  58%|█████▊    | 152/260 [00:43<00:29,  3.61it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:44<00:29,  3.60it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:29,  3.60it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:44<00:29,  3.60it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:45<00:28,  3.62it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:28,  3.61it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:45<00:28,  3.60it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:45<00:28,  3.60it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:46<00:27,  3.62it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:27,  3.64it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:46<00:27,  3.63it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:47<00:26,  3.61it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:47<00:26,  3.60it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:47<00:26,  3.61it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:47<00:26,  3.61it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:48<00:25,  3.62it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:48<00:25,  3.61it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:48<00:25,  3.62it/s]\u001b[AI1018 12:00:21.290056 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-950/config.json\n",
      "I1018 12:00:21.937401 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-950/pytorch_model.bin\n",
      "I1018 12:00:21.941340 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-950\n",
      "\n",
      "Iteration:  65%|██████▌   | 170/260 [00:49<00:42,  2.12it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:49<00:36,  2.43it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:50<00:32,  2.69it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:50<00:29,  2.93it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:50<00:27,  3.12it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:50<00:26,  3.25it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:51<00:25,  3.34it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:51<00:24,  3.41it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:51<00:23,  3.49it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:52<00:22,  3.52it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:52<00:22,  3.55it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:22,  3.55it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:52<00:21,  3.56it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:53<00:21,  3.59it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:20,  3.62it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:53<00:20,  3.64it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:54<00:20,  3.66it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:54<00:19,  3.66it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:19,  3.67it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:54<00:19,  3.67it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:55<00:19,  3.65it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:55<00:18,  3.64it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:55<00:18,  3.62it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:55<00:18,  3.61it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:56<00:18,  3.61it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:17,  3.63it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:56<00:17,  3.62it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:57<00:17,  3.64it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:57<00:17,  3.62it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:16,  3.63it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:57<00:16,  3.61it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:58<00:16,  3.61it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:58<00:15,  3.63it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:58<00:15,  3.63it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:58<00:15,  3.64it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:59<00:15,  3.62it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:59<00:14,  3.63it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [00:59<00:14,  3.61it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:00<00:14,  3.64it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:00<00:13,  3.65it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:00<00:13,  3.64it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:00<00:13,  3.63it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:01<00:13,  3.61it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:01<00:12,  3.63it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:01<00:12,  3.64it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:01<00:12,  3.64it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:02<00:12,  3.65it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:02<00:11,  3.63it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:02<00:11,  3.65it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:03<00:11,  3.66it/s]\u001b[AI1018 12:00:35.707540 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1000/config.json\n",
      "I1018 12:00:36.353930 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1000/pytorch_model.bin\n",
      "I1018 12:00:36.359308 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1000\n",
      "\n",
      "Iteration:  85%|████████▍ | 220/260 [01:04<00:18,  2.12it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:04<00:16,  2.43it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:04<00:14,  2.69it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:04<00:12,  2.91it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:05<00:11,  3.08it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:05<00:10,  3.22it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:05<00:10,  3.32it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:05<00:09,  3.42it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:06<00:09,  3.46it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:06<00:08,  3.50it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:06<00:08,  3.56it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:07<00:08,  3.57it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:07<00:07,  3.59it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:07<00:07,  3.59it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:07<00:07,  3.59it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:08<00:06,  3.60it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:08<00:06,  3.60it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:08<00:06,  3.62it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:08<00:06,  3.63it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:09<00:05,  3.61it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:09<00:05,  3.62it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:09<00:05,  3.63it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:10<00:04,  3.62it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:10<00:04,  3.61it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:10<00:04,  3.63it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:10<00:04,  3.62it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:11<00:03,  3.64it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:11<00:03,  3.62it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:11<00:03,  3.61it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:12<00:03,  3.61it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:12<00:02,  3.64it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:12<00:02,  3.63it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:12<00:02,  3.63it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:13<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:13<00:01,  3.62it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:13<00:01,  3.63it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:13<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:14<00:00,  3.64it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:14<00:00,  3.62it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:14<00:00,  3.64it/s]\u001b[A\n",
      "Epoch:  40%|████      | 4/10 [05:01<07:31, 75.30s/it]15it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:11,  3.64it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:11,  3.63it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:10,  3.62it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:10,  3.63it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:10,  3.64it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:09,  3.64it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:09,  3.62it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:09,  3.61it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:09,  3.63it/s]\u001b[AI1018 12:00:50.047854 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1050/config.json\n",
      "I1018 12:00:50.693657 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1050/pytorch_model.bin\n",
      "I1018 12:00:50.700080 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1050\n",
      "\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:57,  2.12it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:41,  2.45it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:31,  2.72it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:23,  2.95it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:18,  3.12it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:15,  3.25it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:12,  3.36it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:10,  3.43it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:09,  3.49it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:08,  3.52it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:07,  3.57it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:06,  3.60it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:05,  3.63it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:05,  3.64it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:04,  3.66it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:04,  3.67it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:04,  3.65it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:04,  3.64it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:04,  3.62it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:04,  3.60it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:03,  3.61it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:03,  3.61it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:02,  3.62it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:02,  3.61it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:02,  3.60it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:02,  3.60it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:02,  3.60it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:01,  3.62it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:01,  3.63it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:11<01:00,  3.64it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:00,  3.64it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<01:00,  3.62it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<01:00,  3.63it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<00:59,  3.62it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<00:59,  3.64it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:13<00:58,  3.65it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<00:58,  3.67it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:57,  3.67it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:58,  3.65it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:57,  3.64it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:57,  3.62it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:14<00:57,  3.63it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:56,  3.64it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:56,  3.65it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:56,  3.65it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<00:55,  3.65it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:55,  3.63it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:55,  3.62it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:16<00:55,  3.64it/s]\u001b[AI1018 12:01:04.439075 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1100/config.json\n",
      "I1018 12:01:05.105551 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1100/pytorch_model.bin\n",
      "I1018 12:01:05.110259 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1100\n",
      "\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<01:35,  2.10it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:18<01:22,  2.42it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:18<01:13,  2.70it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:18<01:07,  2.93it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<01:02,  3.12it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:19<00:59,  3.26it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:19<00:58,  3.34it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:56,  3.43it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:20<00:55,  3.47it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:20<00:54,  3.54it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:20<00:53,  3.56it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:52,  3.60it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:21<00:51,  3.62it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:21<00:51,  3.64it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<00:50,  3.65it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:50,  3.64it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:22<00:50,  3.64it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:50,  3.65it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:49,  3.65it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:23<00:49,  3.65it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:23<00:49,  3.65it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<00:48,  3.65it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:48,  3.66it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:24<00:48,  3.66it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:48,  3.63it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:48,  3.64it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:48,  3.62it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:25<00:47,  3.64it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:47,  3.63it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:46,  3.65it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:26<00:46,  3.66it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<00:46,  3.67it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<00:45,  3.67it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:45,  3.64it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:45,  3.65it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:45,  3.65it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:27<00:45,  3.63it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:27<00:45,  3.61it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:44,  3.61it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:44,  3.61it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:28<00:44,  3.60it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:29<00:44,  3.59it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:43,  3.62it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:43,  3.62it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:29<00:42,  3.64it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:42,  3.63it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:42,  3.64it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:30<00:42,  3.62it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:30<00:41,  3.63it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:41,  3.64it/s]\u001b[AI1018 12:01:18.848862 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1150/config.json\n",
      "I1018 12:01:19.498177 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1150/pytorch_model.bin\n",
      "I1018 12:01:19.503337 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1150\n",
      "\n",
      "Iteration:  42%|████▏     | 110/260 [00:32<01:11,  2.10it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:32<01:01,  2.42it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:55,  2.69it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:33<00:50,  2.90it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:33<00:47,  3.09it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:33<00:44,  3.24it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:42,  3.36it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:34<00:41,  3.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  45%|████▌     | 118/260 [00:34<00:40,  3.50it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:34<00:39,  3.55it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:39,  3.55it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:35<00:38,  3.59it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:35<00:38,  3.62it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:37,  3.64it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:36<00:37,  3.63it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:37,  3.64it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:36,  3.66it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:36,  3.67it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:37<00:35,  3.67it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:37<00:35,  3.65it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:37<00:35,  3.65it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:35,  3.65it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:35,  3.63it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:34,  3.63it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:34,  3.62it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:39<00:34,  3.64it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:33,  3.65it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:33,  3.66it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:33,  3.67it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:40<00:33,  3.65it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:32,  3.66it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:40<00:32,  3.64it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:40<00:32,  3.62it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:32,  3.63it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:41<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:41<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:42<00:31,  3.62it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:31,  3.62it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:42<00:30,  3.62it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:42<00:30,  3.61it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:30,  3.60it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:43<00:30,  3.60it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:43<00:29,  3.63it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:44<00:29,  3.65it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:28,  3.66it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:44<00:28,  3.64it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:44<00:28,  3.62it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:28,  3.61it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:45<00:28,  3.61it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:45<00:27,  3.63it/s]\u001b[AI1018 12:01:33.243960 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1200/config.json\n",
      "I1018 12:01:34.215320 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1200/pytorch_model.bin\n",
      "I1018 12:01:34.220331 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1200\n",
      "\n",
      "Iteration:  62%|██████▏   | 160/260 [00:46<00:56,  1.76it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:47<00:47,  2.09it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:47<00:40,  2.40it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:47<00:36,  2.67it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:48<00:33,  2.89it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:48<00:30,  3.07it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:48<00:29,  3.23it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:48<00:27,  3.35it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:49<00:26,  3.45it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:49<00:26,  3.49it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:49<00:25,  3.55it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:49<00:24,  3.59it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:50<00:24,  3.60it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:50<00:24,  3.59it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:50<00:23,  3.59it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:51<00:23,  3.59it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:51<00:23,  3.62it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:51<00:22,  3.64it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:51<00:22,  3.63it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:52<00:22,  3.61it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:52<00:22,  3.60it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:21,  3.62it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:52<00:21,  3.65it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:53<00:21,  3.66it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:20,  3.64it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:53<00:20,  3.63it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:54<00:20,  3.61it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:54<00:20,  3.63it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:19,  3.61it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:54<00:19,  3.63it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:55<00:19,  3.63it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:55<00:19,  3.62it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:55<00:18,  3.63it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:56<00:18,  3.64it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:56<00:18,  3.64it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:17,  3.65it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:56<00:17,  3.63it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:57<00:17,  3.61it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:57<00:17,  3.64it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:16,  3.65it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:57<00:16,  3.64it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:58<00:16,  3.65it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:58<00:15,  3.64it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:58<00:15,  3.65it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:59<00:15,  3.65it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:59<00:15,  3.65it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:59<00:14,  3.65it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [00:59<00:14,  3.65it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:00<00:14,  3.65it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:00<00:13,  3.66it/s]\u001b[AI1018 12:01:47.966098 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1250/config.json\n",
      "I1018 12:01:48.640849 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1250/pytorch_model.bin\n",
      "I1018 12:01:48.650068 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1250\n",
      "\n",
      "Iteration:  81%|████████  | 210/260 [01:01<00:24,  2.07it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:01<00:20,  2.38it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:01<00:18,  2.65it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:02<00:16,  2.90it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:02<00:14,  3.08it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:02<00:13,  3.21it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:03<00:13,  3.33it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:03<00:12,  3.40it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:03<00:12,  3.46it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:03<00:11,  3.53it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:04<00:11,  3.57it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:04<00:10,  3.61it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:04<00:10,  3.61it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:04<00:10,  3.59it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:05<00:10,  3.59it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:05<00:09,  3.62it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:05<00:09,  3.64it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:06<00:09,  3.63it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:06<00:08,  3.62it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:06<00:08,  3.63it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:06<00:08,  3.61it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:07<00:07,  3.63it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:07<00:07,  3.64it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:07<00:07,  3.64it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:07<00:07,  3.65it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:08<00:06,  3.63it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:08<00:06,  3.65it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:08<00:06,  3.66it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:09<00:06,  3.66it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:09<00:05,  3.65it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:09<00:05,  3.66it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:09<00:05,  3.67it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:10<00:04,  3.67it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:10<00:04,  3.68it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:10<00:04,  3.68it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:10<00:04,  3.68it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:11<00:03,  3.68it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:11<00:03,  3.66it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:11<00:03,  3.66it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:12<00:03,  3.66it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:12<00:02,  3.66it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:12<00:02,  3.66it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:12<00:02,  3.66it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:13<00:01,  3.66it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:13<00:01,  3.66it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:13<00:01,  3.65it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:13<00:01,  3.65it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:14<00:00,  3.66it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:14<00:00,  3.65it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:14<00:00,  3.65it/s]\u001b[AI1018 12:02:02.243976 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1300/config.json\n",
      "I1018 12:02:02.912054 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1300/pytorch_model.bin\n",
      "I1018 12:02:02.916911 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1300\n",
      "\n",
      "Epoch:  50%|█████     | 5/10 [06:16<06:17, 75.40s/it]26it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:07,  3.83it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:08,  3.78it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:08,  3.75it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:08,  3.73it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:09,  3.69it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:08,  3.69it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:09,  3.66it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:08,  3.66it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:08,  3.66it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:08,  3.66it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:02<01:08,  3.66it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:07,  3.65it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:07,  3.66it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:07,  3.66it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:07,  3.63it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:07,  3.64it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:07,  3.62it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:06,  3.64it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:05,  3.65it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:05<01:05,  3.64it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:05<01:05,  3.66it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:05,  3.64it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:05,  3.64it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:06<01:04,  3.64it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:06<01:04,  3.65it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:04,  3.65it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:03,  3.65it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:07<01:03,  3.65it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:07<01:03,  3.65it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:02,  3.65it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:08<01:02,  3.65it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:08<01:02,  3.63it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:02,  3.64it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:02,  3.64it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:09<01:01,  3.65it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:09<01:01,  3.63it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:01,  3.62it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:10<01:00,  3.64it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:10<01:00,  3.65it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:10<01:00,  3.66it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<00:59,  3.67it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:11<00:59,  3.65it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:11<00:59,  3.65it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<00:59,  3.63it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:12<00:59,  3.62it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:12<00:59,  3.61it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:12<00:59,  3.61it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:58,  3.62it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:13<00:58,  3.61it/s]\u001b[AI1018 12:02:16.642233 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1350/config.json\n",
      "I1018 12:02:17.288750 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1350/pytorch_model.bin\n",
      "I1018 12:02:17.294493 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1350\n",
      "\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<01:39,  2.11it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<01:25,  2.43it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:14<01:16,  2.70it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<01:10,  2.92it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<01:06,  3.10it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<01:03,  3.25it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<01:00,  3.35it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:59,  3.44it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:57,  3.50it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:16<00:56,  3.55it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:55,  3.58it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:55,  3.58it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:54,  3.60it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:17<00:54,  3.59it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:54,  3.60it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:53,  3.62it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:18<00:53,  3.64it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:52,  3.65it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:52,  3.66it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:52,  3.67it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:19<00:52,  3.65it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:51,  3.65it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:20<00:51,  3.65it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:20<00:51,  3.65it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:20<00:51,  3.63it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:50,  3.64it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:21<00:50,  3.62it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:21<00:50,  3.64it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:49,  3.65it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:49,  3.67it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:22<00:49,  3.67it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:22<00:48,  3.68it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:48,  3.68it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:23<00:48,  3.66it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:23<00:48,  3.66it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:23<00:47,  3.67it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:47,  3.67it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:24<00:47,  3.68it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:24<00:47,  3.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  34%|███▍      | 89/260 [00:25<00:46,  3.65it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:25<00:46,  3.65it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:25<00:46,  3.65it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:25<00:45,  3.66it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:45,  3.65it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:26<00:45,  3.65it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:26<00:45,  3.63it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:26<00:45,  3.64it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:27<00:44,  3.64it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:27<00:44,  3.65it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:27<00:44,  3.65it/s]\u001b[AI1018 12:02:30.995239 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1400/config.json\n",
      "I1018 12:02:31.644485 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1400/pytorch_model.bin\n",
      "I1018 12:02:31.649245 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1400\n",
      "\n",
      "Iteration:  38%|███▊      | 100/260 [00:28<01:15,  2.12it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:28<01:05,  2.43it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:58,  2.69it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:53,  2.93it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:29<00:50,  3.12it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:47,  3.27it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:45,  3.38it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:30<00:44,  3.44it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:30<00:43,  3.51it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:42,  3.53it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:31<00:42,  3.57it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:31<00:41,  3.57it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:41,  3.58it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:40,  3.59it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:32<00:40,  3.61it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:32<00:40,  3.62it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:39,  3.63it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:39,  3.64it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:33<00:38,  3.64it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:33<00:38,  3.65it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:38,  3.65it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:34<00:38,  3.65it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:34<00:37,  3.65it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:37,  3.65it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:35<00:37,  3.65it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:35<00:36,  3.65it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:35<00:36,  3.65it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:36,  3.63it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:36<00:36,  3.64it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:36<00:35,  3.64it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:36<00:35,  3.65it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:35,  3.65it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:37<00:35,  3.63it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:37<00:35,  3.62it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:34,  3.64it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:38<00:34,  3.65it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:38<00:34,  3.64it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:38<00:33,  3.64it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:33,  3.65it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:39<00:33,  3.65it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:39<00:32,  3.65it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:39<00:32,  3.65it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:40<00:32,  3.63it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:40<00:32,  3.63it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:40<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:41<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:41<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:41<00:31,  3.62it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:41<00:30,  3.64it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:42<00:30,  3.65it/s]\u001b[AI1018 12:02:45.376241 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1450/config.json\n",
      "I1018 12:02:46.024906 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1450/pytorch_model.bin\n",
      "I1018 12:02:46.031443 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1450\n",
      "\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:51,  2.12it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:43<00:44,  2.44it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:43<00:39,  2.72it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:43<00:36,  2.95it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:33,  3.14it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:44<00:31,  3.28it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:44<00:30,  3.40it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:29,  3.48it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:45<00:28,  3.54it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:45<00:28,  3.58it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:45<00:27,  3.61it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:27,  3.63it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:46<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:46<00:26,  3.66it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:46<00:26,  3.64it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:47<00:25,  3.66it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:47<00:25,  3.66it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:47<00:25,  3.67it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:47<00:25,  3.68it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:48<00:24,  3.68it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:48<00:24,  3.65it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:48<00:24,  3.66it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:49<00:24,  3.66it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:49<00:23,  3.63it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:49<00:23,  3.62it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:49<00:23,  3.64it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:50<00:23,  3.63it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:50<00:22,  3.65it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:50<00:22,  3.66it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:51<00:22,  3.67it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:51<00:21,  3.65it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:51<00:21,  3.65it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:51<00:21,  3.65it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:52<00:21,  3.65it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:52<00:20,  3.66it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:52<00:20,  3.66it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:52<00:20,  3.65it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:53<00:19,  3.65it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:53<00:19,  3.65it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:53<00:19,  3.65it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:54<00:19,  3.63it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:54<00:19,  3.62it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:54<00:18,  3.64it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:54<00:18,  3.63it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:55<00:18,  3.62it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:55<00:18,  3.61it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:55<00:17,  3.62it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:55<00:17,  3.63it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:56<00:17,  3.64it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:56<00:16,  3.62it/s]\u001b[AI1018 12:02:59.714230 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1500/config.json\n",
      "I1018 12:03:00.388579 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1500/pytorch_model.bin\n",
      "I1018 12:03:00.393628 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  77%|███████▋  | 200/260 [00:57<00:28,  2.08it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:57<00:24,  2.41it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:58<00:21,  2.69it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:58<00:19,  2.92it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:58<00:17,  3.12it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:58<00:16,  3.25it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:59<00:16,  3.37it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [00:59<00:15,  3.44it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:59<00:14,  3.50it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [00:59<00:14,  3.55it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:00<00:13,  3.58it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:00<00:13,  3.58it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:00<00:13,  3.58it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:01<00:13,  3.61it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:01<00:12,  3.61it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:01<00:12,  3.64it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:01<00:12,  3.62it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:02<00:11,  3.61it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:02<00:11,  3.62it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:02<00:11,  3.64it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:02<00:10,  3.64it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:03<00:10,  3.65it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:03<00:10,  3.65it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:03<00:10,  3.65it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:04<00:09,  3.65it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:04<00:09,  3.63it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:04<00:09,  3.62it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:04<00:09,  3.64it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:05<00:08,  3.65it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:05<00:08,  3.66it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:05<00:08,  3.67it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:05<00:07,  3.65it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:06<00:07,  3.65it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:06<00:07,  3.65it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:06<00:07,  3.65it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:07<00:06,  3.63it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:07<00:06,  3.64it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:07<00:06,  3.62it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:07<00:06,  3.64it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:08<00:05,  3.65it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:08<00:05,  3.66it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:08<00:05,  3.67it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:08<00:04,  3.67it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:09<00:04,  3.68it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:09<00:04,  3.68it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:09<00:04,  3.66it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:10<00:03,  3.67it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:10<00:03,  3.65it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:10<00:03,  3.65it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:10<00:03,  3.65it/s]\u001b[AI1018 12:03:14.101107 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1550/config.json\n",
      "I1018 12:03:14.751707 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1550/pytorch_model.bin\n",
      "I1018 12:03:14.757633 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1550\n",
      "\n",
      "Iteration:  96%|█████████▌| 250/260 [01:11<00:04,  2.10it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:12<00:03,  2.43it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:12<00:02,  2.70it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:12<00:02,  2.91it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:12<00:01,  3.10it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:13<00:01,  3.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:13<00:01,  3.36it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:13<00:00,  3.42it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:14<00:00,  3.50it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:14<00:00,  3.55it/s]\u001b[A\n",
      "Epoch:  60%|██████    | 6/10 [07:31<05:00, 75.12s/it]07it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:09,  3.72it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:09,  3.70it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:09,  3.69it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:09,  3.68it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:09,  3.67it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:09,  3.67it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:09,  3.66it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:08,  3.66it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:08,  3.66it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:08,  3.66it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:08,  3.63it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:08,  3.65it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:07,  3.66it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:07,  3.66it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:06,  3.67it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:06,  3.67it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:06,  3.68it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:05,  3.68it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:05,  3.68it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:05<01:05,  3.68it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:05<01:04,  3.68it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:05<01:04,  3.68it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:04,  3.68it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:06<01:04,  3.69it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:06<01:03,  3.69it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:03,  3.69it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:03,  3.68it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:07<01:02,  3.68it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:07<01:02,  3.68it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:02,  3.68it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:08<01:02,  3.69it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:08<01:02,  3.66it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:08<01:01,  3.67it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:01,  3.68it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:09<01:01,  3.68it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:09<01:00,  3.68it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:00,  3.68it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:10<01:00,  3.68it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:10<00:59,  3.69it/s]\u001b[AI1018 12:03:28.354262 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1600/config.json\n",
      "I1018 12:03:29.015683 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1600/pytorch_model.bin\n",
      "I1018 12:03:29.020540 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1600\n",
      "\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:48,  2.02it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<01:33,  2.35it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<01:22,  2.64it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<01:15,  2.88it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<01:09,  3.09it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:12<01:06,  3.23it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<01:04,  3.34it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<01:02,  3.43it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<01:01,  3.47it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:59,  3.53it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:58,  3.56it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:58,  3.59it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:14<00:57,  3.61it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:57,  3.63it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:56,  3.64it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:56,  3.64it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<00:55,  3.65it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:55,  3.65it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:55,  3.63it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:16<00:55,  3.62it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:54,  3.64it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:54,  3.66it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:54,  3.67it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:17<00:53,  3.67it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:53,  3.68it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:53,  3.68it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:18<00:52,  3.68it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:52,  3.68it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:52,  3.68it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:51,  3.69it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:19<00:51,  3.68it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:51,  3.69it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:20<00:51,  3.69it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:20<00:50,  3.68it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:20<00:50,  3.66it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:50,  3.66it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:21<00:50,  3.66it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:21<00:50,  3.66it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:49,  3.66it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:49,  3.66it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:22<00:49,  3.65it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:22<00:49,  3.65it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:48,  3.65it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:23<00:48,  3.66it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:23<00:48,  3.65it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:23<00:48,  3.63it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:47,  3.64it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:24<00:47,  3.64it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:24<00:47,  3.65it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:47,  3.62it/s]\u001b[AI1018 12:03:42.710437 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1650/config.json\n",
      "I1018 12:03:43.362539 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1650/pytorch_model.bin\n",
      "I1018 12:03:43.368822 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1650\n",
      "\n",
      "Iteration:  35%|███▍      | 90/260 [00:25<01:21,  2.08it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<01:10,  2.41it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<01:02,  2.69it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:57,  2.93it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:53,  3.12it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:50,  3.27it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:27<00:48,  3.36it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:27<00:47,  3.42it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:46,  3.47it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:45,  3.53it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:28<00:44,  3.58it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:28<00:44,  3.61it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:43,  3.63it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:43,  3.64it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:29<00:42,  3.66it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:42,  3.66it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:42,  3.65it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:30<00:41,  3.66it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:30<00:41,  3.67it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:41,  3.67it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:31<00:41,  3.65it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:31<00:40,  3.65it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:31<00:40,  3.63it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:40,  3.64it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:32<00:40,  3.62it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:32<00:39,  3.64it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:39,  3.65it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:39,  3.63it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:33<00:38,  3.65it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:33<00:38,  3.66it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:38,  3.66it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:34<00:37,  3.67it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:34<00:37,  3.67it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:34<00:37,  3.68it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:35<00:36,  3.68it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:35<00:36,  3.68it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:35<00:36,  3.68it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:36,  3.66it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:36<00:36,  3.66it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:36<00:35,  3.66it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:36<00:35,  3.66it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:35,  3.66it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:37<00:34,  3.66it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:37<00:34,  3.63it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:34,  3.62it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:38<00:34,  3.61it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:38<00:34,  3.61it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:38<00:33,  3.62it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:33,  3.63it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:39<00:33,  3.64it/s]\u001b[AI1018 12:03:57.069015 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1700/config.json\n",
      "I1018 12:03:57.727164 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1700/pytorch_model.bin\n",
      "I1018 12:03:57.732959 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1700\n",
      "\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:57,  2.09it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:40<00:49,  2.41it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:40<00:43,  2.68it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:40,  2.92it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:41<00:37,  3.11it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:41<00:35,  3.25it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:41<00:33,  3.36it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:32,  3.45it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:42<00:31,  3.50it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:42<00:31,  3.52it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:31,  3.54it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:43<00:30,  3.58it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:43<00:29,  3.61it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:43<00:29,  3.61it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:29,  3.63it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:44<00:28,  3.65it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:44<00:28,  3.66it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:44<00:28,  3.67it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:45<00:27,  3.67it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:45<00:27,  3.67it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:45<00:27,  3.67it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:26,  3.68it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:46<00:26,  3.68it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:46<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:46<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:47<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:47<00:25,  3.65it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:47<00:25,  3.66it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:48<00:25,  3.63it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:48<00:25,  3.62it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:48<00:24,  3.64it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:48<00:24,  3.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  66%|██████▌   | 172/260 [00:49<00:24,  3.66it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:49<00:23,  3.65it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:49<00:23,  3.66it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:49<00:23,  3.64it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:50<00:23,  3.62it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:50<00:23,  3.61it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:50<00:22,  3.63it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:51<00:22,  3.65it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:51<00:22,  3.63it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:51<00:21,  3.65it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:51<00:21,  3.66it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:52<00:20,  3.67it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:52<00:20,  3.67it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:52<00:20,  3.68it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:52<00:20,  3.68it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:53<00:19,  3.68it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:53<00:19,  3.68it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:53<00:19,  3.66it/s]\u001b[AI1018 12:04:11.419195 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1750/config.json\n",
      "I1018 12:04:12.089871 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1750/pytorch_model.bin\n",
      "I1018 12:04:12.098724 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1750\n",
      "\n",
      "Iteration:  73%|███████▎  | 190/260 [00:54<00:33,  2.08it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:54<00:28,  2.40it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:55<00:25,  2.68it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:55<00:23,  2.91it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:55<00:21,  3.08it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:20,  3.24it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:56<00:19,  3.35it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:56<00:18,  3.44it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:56<00:17,  3.50it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:17,  3.52it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:57<00:16,  3.57it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:57<00:16,  3.60it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:57<00:16,  3.62it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:58<00:15,  3.62it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:58<00:15,  3.64it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:58<00:15,  3.63it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:59<00:14,  3.63it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [00:59<00:14,  3.64it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:59<00:14,  3.64it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [00:59<00:13,  3.65it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:00<00:13,  3.64it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:00<00:13,  3.65it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:00<00:13,  3.65it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:01<00:12,  3.65it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:01<00:12,  3.65it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:01<00:12,  3.65it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:01<00:12,  3.65it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:02<00:11,  3.65it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:02<00:11,  3.65it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:02<00:11,  3.65it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:02<00:10,  3.65it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:03<00:10,  3.66it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:03<00:10,  3.66it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:03<00:10,  3.65it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:04<00:09,  3.65it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:04<00:09,  3.63it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:04<00:09,  3.64it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:04<00:09,  3.64it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:05<00:08,  3.65it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:05<00:08,  3.65it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:05<00:08,  3.65it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:05<00:07,  3.63it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:06<00:07,  3.65it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:06<00:07,  3.66it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:06<00:07,  3.67it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:07<00:06,  3.67it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:07<00:06,  3.67it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:07<00:06,  3.68it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:07<00:06,  3.66it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:08<00:05,  3.66it/s]\u001b[AI1018 12:04:25.796050 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1800/config.json\n",
      "I1018 12:04:26.444733 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1800/pytorch_model.bin\n",
      "I1018 12:04:26.450031 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1800\n",
      "\n",
      "Iteration:  92%|█████████▏| 240/260 [01:09<00:09,  2.12it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:09<00:07,  2.44it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:09<00:06,  2.72it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:09<00:05,  2.95it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:10<00:05,  3.14it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:10<00:04,  3.28it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:10<00:04,  3.40it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:10<00:03,  3.48it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:11<00:03,  3.54it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:11<00:03,  3.56it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:11<00:02,  3.59it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:12<00:02,  3.61it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:12<00:02,  3.62it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:12<00:01,  3.63it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:12<00:01,  3.63it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:13<00:01,  3.62it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:13<00:01,  3.63it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:13<00:00,  3.64it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:13<00:00,  3.64it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:14<00:00,  3.65it/s]\u001b[A\n",
      "Epoch:  70%|███████   | 7/10 [08:45<03:44, 74.91s/it]19it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:08,  3.76it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:09,  3.74it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:09,  3.72it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:09,  3.71it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:08,  3.70it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:08,  3.70it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:08,  3.69it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:08,  3.69it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:08,  3.69it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:07,  3.69it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:02<01:07,  3.68it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:07,  3.69it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:07,  3.69it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:06,  3.69it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:06,  3.69it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:06,  3.66it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:06,  3.64it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:06,  3.64it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:06,  3.64it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:05<01:05,  3.65it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:05<01:05,  3.65it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:05<01:05,  3.65it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:04,  3.65it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:06<01:04,  3.65it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:06<01:04,  3.65it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:04,  3.65it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:03,  3.65it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:07<01:03,  3.65it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:07<01:03,  3.65it/s]\u001b[AI1018 12:04:39.981115 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1850/config.json\n",
      "I1018 12:04:40.630827 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1850/pytorch_model.bin\n",
      "I1018 12:04:40.636392 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1850\n",
      "\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:48,  2.12it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:33,  2.44it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:24,  2.71it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:17,  2.94it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:12,  3.12it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:08,  3.26it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:06,  3.37it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:04,  3.45it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:03,  3.51it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:11<01:02,  3.55it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:01,  3.58it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<01:00,  3.60it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<01:00,  3.61it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<00:59,  3.62it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<00:59,  3.63it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:12<00:59,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:58,  3.65it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:58,  3.65it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:57,  3.65it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:57,  3.65it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:57,  3.63it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:14<00:57,  3.65it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:56,  3.66it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:56,  3.67it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:55,  3.67it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:15<00:55,  3.68it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:55,  3.68it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:54,  3.68it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:16<00:54,  3.68it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:54,  3.66it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:54,  3.67it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:54,  3.65it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:17<00:53,  3.65it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:53,  3.65it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:53,  3.65it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:18<00:53,  3.65it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:18<00:52,  3.65it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:52,  3.63it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:52,  3.64it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:19<00:52,  3.64it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:51,  3.64it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:20<00:51,  3.62it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:20<00:51,  3.61it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:20<00:51,  3.64it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:50,  3.65it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:21<00:50,  3.66it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:21<00:49,  3.66it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:21<00:49,  3.67it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:49,  3.65it/s]\u001b[AI1018 12:04:54.320726 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1900/config.json\n",
      "I1018 12:04:54.971554 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1900/pytorch_model.bin\n",
      "I1018 12:04:54.979051 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1900\n",
      "\n",
      "Iteration:  31%|███       | 80/260 [00:23<01:25,  2.11it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<01:13,  2.43it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<01:05,  2.70it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:23<01:00,  2.93it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:56,  3.12it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:53,  3.26it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:51,  3.36it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:25<00:50,  3.45it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:49,  3.51it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:48,  3.55it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:25<00:47,  3.58it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<00:46,  3.60it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<00:46,  3.62it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:46,  3.63it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:45,  3.64it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:45,  3.62it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:27<00:45,  3.63it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:27<00:45,  3.61it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:44,  3.63it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:44,  3.65it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:28<00:43,  3.66it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:28<00:43,  3.67it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:43,  3.67it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:42,  3.67it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:29<00:42,  3.68it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:42,  3.68it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:41,  3.68it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:30<00:41,  3.69it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:30<00:41,  3.68it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:40,  3.69it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:31<00:40,  3.69it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:31<00:40,  3.68it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:31<00:40,  3.69it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:40,  3.66it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:32<00:39,  3.67it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:32<00:39,  3.68it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:39,  3.68it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:38,  3.68it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:33<00:38,  3.68it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:33<00:38,  3.68it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:38,  3.66it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:34<00:37,  3.66it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:34<00:37,  3.66it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:34<00:37,  3.65it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:35<00:37,  3.65it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:35<00:36,  3.66it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:35<00:36,  3.66it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:36,  3.65it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:36<00:36,  3.66it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:36<00:35,  3.66it/s]\u001b[AI1018 12:05:08.631045 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-1950/config.json\n",
      "I1018 12:05:09.347736 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-1950/pytorch_model.bin\n",
      "I1018 12:05:09.360585 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-1950\n",
      "\n",
      "Iteration:  50%|█████     | 130/260 [00:37<01:04,  2.02it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:54,  2.35it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:48,  2.63it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:44,  2.87it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:41,  3.07it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:38<00:38,  3.22it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:37,  3.34it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:35,  3.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:34,  3.50it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:40<00:34,  3.54it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:33,  3.57it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:40<00:33,  3.60it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:40<00:32,  3.61it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:32,  3.63it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:41<00:31,  3.63it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:41<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:41<00:31,  3.65it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:42<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:42<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:43<00:29,  3.65it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:43<00:29,  3.66it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:43<00:29,  3.66it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:28,  3.66it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:44<00:28,  3.66it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:44<00:28,  3.66it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:44<00:28,  3.65it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:45<00:27,  3.66it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:45<00:27,  3.65it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:45<00:27,  3.65it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:27,  3.65it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:46<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:46<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:46<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:47<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:47<00:25,  3.65it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:47<00:25,  3.65it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:47<00:25,  3.65it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:48<00:24,  3.65it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:48<00:24,  3.65it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:48<00:24,  3.65it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:49<00:24,  3.63it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:49<00:23,  3.64it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:49<00:23,  3.64it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:49<00:23,  3.62it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:50<00:23,  3.62it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:50<00:22,  3.61it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:50<00:22,  3.63it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:50<00:22,  3.61it/s]\u001b[AI1018 12:05:23.068522 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2000/config.json\n",
      "I1018 12:05:23.787252 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2000/pytorch_model.bin\n",
      "I1018 12:05:23.792716 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2000\n",
      "\n",
      "Iteration:  69%|██████▉   | 180/260 [00:51<00:39,  2.02it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:33,  2.35it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:52<00:29,  2.63it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:52<00:26,  2.87it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:24,  3.07it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:53<00:23,  3.22it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:53<00:22,  3.34it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:53<00:21,  3.43it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:20,  3.49it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:54<00:20,  3.54it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:54<00:19,  3.57it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:55<00:19,  3.60it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:55<00:18,  3.61it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:55<00:18,  3.63it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:55<00:18,  3.61it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:17,  3.64it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:56<00:17,  3.65it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:56<00:17,  3.66it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:56<00:16,  3.67it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:16,  3.65it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:57<00:16,  3.66it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:57<00:16,  3.67it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:58<00:15,  3.67it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:58<00:15,  3.68it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:58<00:15,  3.68it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:58<00:14,  3.68it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:59<00:14,  3.68it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [00:59<00:14,  3.68it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:59<00:14,  3.68it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [00:59<00:13,  3.68it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:00<00:13,  3.68it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:00<00:13,  3.69it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:00<00:13,  3.69it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:00<00:12,  3.69it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:01<00:12,  3.69it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:01<00:12,  3.69it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:01<00:11,  3.69it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:02<00:11,  3.69it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:02<00:11,  3.69it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:02<00:11,  3.69it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:02<00:10,  3.69it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:03<00:10,  3.66it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:03<00:10,  3.66it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:03<00:10,  3.66it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:03<00:09,  3.66it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:04<00:09,  3.63it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:04<00:09,  3.64it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:04<00:09,  3.64it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:05<00:08,  3.65it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:05<00:08,  3.65it/s]\u001b[AI1018 12:05:37.435406 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2050/config.json\n",
      "I1018 12:05:38.149388 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2050/pytorch_model.bin\n",
      "I1018 12:05:38.153172 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2050\n",
      "\n",
      "Iteration:  88%|████████▊ | 230/260 [01:06<00:14,  2.03it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:06<00:12,  2.36it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:06<00:10,  2.63it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:07<00:09,  2.87it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:07<00:08,  3.08it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:07<00:07,  3.24it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:07<00:07,  3.36it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:08<00:06,  3.45it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:08<00:06,  3.52it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:08<00:05,  3.57it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:09<00:05,  3.60it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:09<00:05,  3.62it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:09<00:04,  3.62it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:09<00:04,  3.64it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:10<00:04,  3.65it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:10<00:04,  3.66it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:10<00:03,  3.67it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:10<00:03,  3.67it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:11<00:03,  3.68it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:11<00:02,  3.68it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:11<00:02,  3.68it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:12<00:02,  3.68it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:12<00:02,  3.68it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:12<00:01,  3.68it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:12<00:01,  3.68it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:13<00:01,  3.68it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:13<00:01,  3.68it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:13<00:00,  3.68it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:13<00:00,  3.66it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:14<00:00,  3.65it/s]\u001b[A\n",
      "Epoch:  80%|████████  | 8/10 [10:00<02:29, 74.76s/it]20it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:08,  3.77it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:08,  3.75it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:08,  3.73it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:08,  3.71it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:08,  3.71it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:08,  3.70it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:08,  3.70it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:08,  3.69it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:08,  3.69it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:07,  3.69it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:02<01:07,  3.69it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:07,  3.69it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:07,  3.69it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:06,  3.69it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:06,  3.66it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:06,  3.67it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:06,  3.67it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:05,  3.67it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:05,  3.68it/s]\u001b[AI1018 12:05:51.635083 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2100/config.json\n",
      "I1018 12:05:52.353332 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2100/pytorch_model.bin\n",
      "I1018 12:05:52.357688 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2100\n",
      "\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:57,  2.04it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:41,  2.36it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:30,  2.64it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:22,  2.88it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:16,  3.08it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:12,  3.23it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:09,  3.35it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:08,  3.41it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:06,  3.48it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:05,  3.53it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:04,  3.57it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:03,  3.59it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:03,  3.61it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:02,  3.62it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:02,  3.63it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:01,  3.64it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:01,  3.65it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:01,  3.65it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:00,  3.65it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:11<01:00,  3.65it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:00,  3.65it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<00:59,  3.65it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<00:59,  3.65it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<00:59,  3.65it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<00:59,  3.63it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:13<00:59,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<00:58,  3.66it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:58,  3.67it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:57,  3.67it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:57,  3.65it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:57,  3.66it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:57,  3.67it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:14<00:56,  3.67it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:56,  3.68it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:55,  3.68it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:55,  3.68it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:15<00:55,  3.68it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:55,  3.68it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:54,  3.68it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:16<00:54,  3.69it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:54,  3.69it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:54,  3.68it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:53,  3.68it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:17<00:53,  3.68it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:53,  3.68it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:52,  3.68it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:18<00:52,  3.68it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:18<00:52,  3.68it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:52,  3.68it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:51,  3.68it/s]\u001b[AI1018 12:06:06.001198 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2150/config.json\n",
      "I1018 12:06:06.728284 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2150/pytorch_model.bin\n",
      "I1018 12:06:06.733434 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2150\n",
      "\n",
      "Iteration:  27%|██▋       | 70/260 [00:20<01:33,  2.03it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<01:20,  2.36it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:21<01:11,  2.63it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:21<01:05,  2.87it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<01:00,  3.07it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:57,  3.23it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:22<00:55,  3.35it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:53,  3.43it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:52,  3.50it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:51,  3.54it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:23<00:50,  3.57it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<00:49,  3.60it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:49,  3.61it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:24<00:48,  3.63it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:48,  3.63it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:48,  3.64it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:47,  3.64it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:25<00:47,  3.65it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:47,  3.65it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:46,  3.65it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:25<00:46,  3.65it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<00:46,  3.65it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<00:46,  3.65it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:45,  3.65it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:45,  3.65it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:45,  3.65it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:27<00:44,  3.65it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:27<00:44,  3.65it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:44,  3.65it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:44,  3.65it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:28<00:43,  3.65it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:29<00:43,  3.65it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:43,  3.65it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:42,  3.66it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:29<00:42,  3.65it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:42,  3.65it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:42,  3.65it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:30<00:41,  3.65it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:30<00:41,  3.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  42%|████▏     | 109/260 [00:31<00:41,  3.63it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:31<00:41,  3.64it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:31<00:40,  3.64it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:40,  3.65it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:40,  3.65it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:32<00:39,  3.65it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:32<00:39,  3.65it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:39,  3.66it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:39,  3.65it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:33<00:38,  3.65it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:33<00:38,  3.65it/s]\u001b[AI1018 12:06:20.419186 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2200/config.json\n",
      "I1018 12:06:21.137145 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2200/pytorch_model.bin\n",
      "I1018 12:06:21.152163 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2200\n",
      "\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<01:09,  2.02it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:35<00:59,  2.34it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:35<00:52,  2.63it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:47,  2.87it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:36<00:44,  3.07it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:42,  3.20it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:40,  3.31it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:39,  3.40it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:37<00:38,  3.47it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:37<00:37,  3.52it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:37<00:36,  3.54it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:36,  3.57it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:35,  3.60it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:35,  3.61it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:34,  3.62it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:39<00:34,  3.63it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:34,  3.64it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:33,  3.64it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:33,  3.65it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:40<00:33,  3.65it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:32,  3.64it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:40<00:32,  3.65it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:40<00:32,  3.65it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:32,  3.65it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:41<00:31,  3.65it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:41<00:31,  3.65it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:42<00:31,  3.66it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:30,  3.66it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:42<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:42<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:43<00:29,  3.65it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:43<00:29,  3.65it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:43<00:29,  3.65it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:29,  3.65it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:44<00:28,  3.65it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:44<00:28,  3.65it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:28,  3.65it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:45<00:27,  3.65it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:45<00:27,  3.65it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:45<00:27,  3.65it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:27,  3.65it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:46<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:46<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:47<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:47<00:25,  3.65it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:47<00:25,  3.65it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:47<00:25,  3.66it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:48<00:25,  3.66it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:48<00:24,  3.66it/s]\u001b[AI1018 12:06:34.856223 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2250/config.json\n",
      "I1018 12:06:35.576405 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2250/pytorch_model.bin\n",
      "I1018 12:06:35.580941 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2250\n",
      "\n",
      "Iteration:  65%|██████▌   | 170/260 [00:49<00:44,  2.03it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:49<00:37,  2.36it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:49<00:33,  2.64it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:50<00:30,  2.88it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:50<00:28,  3.06it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:50<00:26,  3.22it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:51<00:25,  3.35it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:51<00:24,  3.44it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:51<00:23,  3.51it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:51<00:22,  3.56it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:52<00:22,  3.60it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:21,  3.62it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:52<00:21,  3.64it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:52<00:21,  3.66it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:20,  3.66it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:53<00:20,  3.67it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:53<00:20,  3.67it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:53<00:19,  3.68it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:19,  3.68it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:54<00:19,  3.68it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:54<00:19,  3.68it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:55<00:18,  3.68it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:55<00:18,  3.68it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:55<00:18,  3.68it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:55<00:17,  3.68it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:17,  3.69it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:56<00:17,  3.69it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:56<00:17,  3.68it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:56<00:16,  3.68it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:16,  3.68it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:57<00:16,  3.68it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:57<00:16,  3.68it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:58<00:15,  3.68it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:58<00:15,  3.68it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:58<00:15,  3.68it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:58<00:14,  3.69it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:59<00:14,  3.68it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [00:59<00:14,  3.69it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:59<00:14,  3.68it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [00:59<00:13,  3.68it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:00<00:13,  3.68it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:00<00:13,  3.68it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:00<00:13,  3.69it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:01<00:12,  3.69it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:01<00:12,  3.69it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:01<00:12,  3.69it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:01<00:11,  3.68it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:02<00:11,  3.68it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:02<00:11,  3.68it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:02<00:11,  3.69it/s]\u001b[AI1018 12:06:49.164784 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2300/config.json\n",
      "I1018 12:06:49.879682 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2300/pytorch_model.bin\n",
      "I1018 12:06:49.884069 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  85%|████████▍ | 220/260 [01:03<00:19,  2.04it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:03<00:16,  2.37it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:04<00:14,  2.66it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:04<00:12,  2.90it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:04<00:11,  3.10it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:05<00:10,  3.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:05<00:10,  3.37it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:05<00:09,  3.46it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:05<00:09,  3.53it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:06<00:08,  3.57it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:06<00:08,  3.61it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:06<00:07,  3.63it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:06<00:07,  3.64it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:07<00:07,  3.66it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:07<00:07,  3.67it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:07<00:06,  3.67it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:08<00:06,  3.67it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:08<00:06,  3.68it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:08<00:06,  3.66it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:08<00:05,  3.67it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:09<00:05,  3.67it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:09<00:05,  3.65it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:09<00:04,  3.65it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:09<00:04,  3.65it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:10<00:04,  3.65it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:10<00:04,  3.65it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:10<00:03,  3.65it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:11<00:03,  3.65it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:11<00:03,  3.63it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:11<00:03,  3.64it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:11<00:02,  3.64it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:12<00:02,  3.62it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:12<00:02,  3.63it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:12<00:01,  3.63it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:12<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:13<00:01,  3.65it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:13<00:01,  3.66it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:13<00:00,  3.67it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:14<00:00,  3.65it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:14<00:00,  3.63it/s]\u001b[A\n",
      "Epoch:  90%|█████████ | 9/10 [11:14<01:14, 74.68s/it]17it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:08,  3.76it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:09,  3.74it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:09,  3.72it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:09,  3.71it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:08,  3.70it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:09,  3.67it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:08,  3.67it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:08,  3.66it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:08,  3.66it/s]\u001b[AI1018 12:07:03.426015 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2350/config.json\n",
      "I1018 12:07:04.163782 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2350/pytorch_model.bin\n",
      "I1018 12:07:04.167915 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2350\n",
      "\n",
      "Iteration:   4%|▍         | 10/260 [00:03<02:04,  2.00it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:46,  2.33it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:04<01:34,  2.61it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:26,  2.86it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:20,  3.06it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:16,  3.21it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:13,  3.33it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:10,  3.43it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:09,  3.49it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:08,  3.54it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:07,  3.57it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:06,  3.60it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:05,  3.61it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:05,  3.62it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:04,  3.63it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:04,  3.64it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:04,  3.64it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:03,  3.64it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:03,  3.65it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:03,  3.65it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:03,  3.65it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:02,  3.65it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:02,  3.65it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:02,  3.66it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:01,  3.65it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:01,  3.65it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:01,  3.65it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:01,  3.65it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:00,  3.65it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:11<01:00,  3.65it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:00,  3.65it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<00:59,  3.66it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<00:59,  3.65it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<00:59,  3.65it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<00:59,  3.65it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:13<00:58,  3.65it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<00:58,  3.65it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:58,  3.63it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:57,  3.65it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:57,  3.66it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:56,  3.67it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:14<00:56,  3.67it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:56,  3.68it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:56,  3.68it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:55,  3.68it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<00:55,  3.68it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:55,  3.69it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:54,  3.68it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:16<00:54,  3.68it/s]\u001b[AI1018 12:07:17.831672 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2400/config.json\n",
      "I1018 12:07:18.546546 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2400/pytorch_model.bin\n",
      "I1018 12:07:18.551056 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2400\n",
      "\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<01:37,  2.04it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:18<01:23,  2.37it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:18<01:14,  2.65it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:18<01:07,  2.90it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<01:03,  3.10it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:19<00:59,  3.25it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:19<00:57,  3.37it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:55,  3.46it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:20<00:54,  3.52it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:20<00:53,  3.57it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:20<00:52,  3.60it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:52,  3.62it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:21<00:51,  3.64it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:21<00:51,  3.65it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<00:50,  3.66it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:50,  3.67it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:22<00:50,  3.67it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:49,  3.67it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:49,  3.68it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:23<00:49,  3.68it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:23<00:48,  3.68it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<00:48,  3.68it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:48,  3.68it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:24<00:48,  3.68it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:47,  3.68it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:47,  3.66it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:47,  3.67it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:25<00:47,  3.67it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:46,  3.67it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:46,  3.68it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:26<00:46,  3.68it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<00:45,  3.68it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<00:45,  3.68it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:45,  3.68it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:45,  3.68it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:44,  3.68it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:27<00:44,  3.68it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:27<00:44,  3.68it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:44,  3.68it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:43,  3.68it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:28<00:43,  3.68it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:28<00:43,  3.68it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:43,  3.66it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:42,  3.66it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:29<00:42,  3.66it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:42,  3.66it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:42,  3.65it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:30<00:41,  3.65it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:30<00:41,  3.65it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:41,  3.65it/s]\u001b[AI1018 12:07:32.156336 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2450/config.json\n",
      "I1018 12:07:32.872099 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2450/pytorch_model.bin\n",
      "I1018 12:07:32.876523 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2450\n",
      "\n",
      "Iteration:  42%|████▏     | 110/260 [00:32<01:13,  2.03it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:32<01:03,  2.36it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:56,  2.64it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:33<00:51,  2.88it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:33<00:47,  3.08it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:33<00:44,  3.23it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:43,  3.34it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:34<00:41,  3.43it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:34<00:40,  3.49it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:34<00:39,  3.54it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:39,  3.57it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:35<00:38,  3.60it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:35<00:38,  3.61it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:37,  3.63it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:36<00:37,  3.63it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:37,  3.64it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:37,  3.62it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:36,  3.63it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:37<00:36,  3.64it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:37<00:35,  3.64it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:37<00:35,  3.64it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:35,  3.64it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:35,  3.65it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:34,  3.65it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:34,  3.65it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:39<00:34,  3.65it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:33,  3.65it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:33,  3.65it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:33,  3.65it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:40<00:33,  3.65it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:32,  3.65it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:40<00:32,  3.65it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:40<00:32,  3.65it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:32,  3.65it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:41<00:31,  3.65it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:41<00:31,  3.65it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:42<00:31,  3.65it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:42<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:42<00:30,  3.63it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:30,  3.64it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:43<00:30,  3.63it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:43<00:29,  3.65it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:43<00:29,  3.65it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:28,  3.66it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:44<00:28,  3.67it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:44<00:28,  3.67it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:28,  3.68it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:45<00:27,  3.68it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:45<00:27,  3.66it/s]\u001b[AI1018 12:07:46.570984 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2500/config.json\n",
      "I1018 12:07:47.288141 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2500/pytorch_model.bin\n",
      "I1018 12:07:47.292885 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2500\n",
      "\n",
      "Iteration:  62%|██████▏   | 160/260 [00:46<00:49,  2.03it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:42,  2.35it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:47<00:37,  2.64it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:47<00:33,  2.88it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:47<00:31,  3.07it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:47<00:29,  3.23it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:48<00:28,  3.35it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:48<00:27,  3.43it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:48<00:26,  3.49it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:49<00:25,  3.54it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:49<00:25,  3.57it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:49<00:24,  3.59it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:49<00:24,  3.61it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:50<00:23,  3.63it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:50<00:23,  3.64it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:50<00:23,  3.64it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:50<00:23,  3.64it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:51<00:22,  3.65it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:51<00:22,  3.65it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:51<00:22,  3.65it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:52<00:21,  3.65it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:21,  3.65it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:52<00:21,  3.65it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:52<00:21,  3.65it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:20,  3.65it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:53<00:20,  3.65it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:53<00:20,  3.65it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:53<00:19,  3.65it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:19,  3.65it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:54<00:19,  3.63it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:54<00:19,  3.64it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:55<00:18,  3.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  74%|███████▍  | 192/260 [00:55<00:18,  3.67it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:55<00:18,  3.67it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:55<00:17,  3.68it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:17,  3.68it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:56<00:17,  3.68it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:56<00:17,  3.68it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:56<00:16,  3.68it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:16,  3.68it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:57<00:16,  3.68it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:57<00:16,  3.68it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:58<00:15,  3.68it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:58<00:15,  3.69it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:58<00:15,  3.69it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:58<00:14,  3.68it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:59<00:14,  3.66it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [00:59<00:14,  3.67it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:59<00:14,  3.67it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [00:59<00:13,  3.67it/s]\u001b[AI1018 12:08:00.941949 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2550/config.json\n",
      "I1018 12:08:01.680046 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2550/pytorch_model.bin\n",
      "I1018 12:08:01.684231 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2550\n",
      "\n",
      "Iteration:  81%|████████  | 210/260 [01:00<00:24,  2.01it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:01<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:01<00:18,  2.63it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:01<00:16,  2.88it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:02<00:14,  3.08it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:02<00:13,  3.24it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:02<00:13,  3.36it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:02<00:12,  3.45it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:03<00:11,  3.52it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:03<00:11,  3.57it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:03<00:11,  3.60it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:03<00:10,  3.63it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:04<00:10,  3.64it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:04<00:10,  3.66it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:04<00:09,  3.67it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:05<00:09,  3.67it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:05<00:09,  3.67it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:05<00:08,  3.67it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:05<00:08,  3.68it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:06<00:08,  3.68it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:06<00:08,  3.68it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:06<00:07,  3.68it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:06<00:07,  3.68it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:07<00:07,  3.69it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:07<00:07,  3.68it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:07<00:06,  3.68it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:08<00:06,  3.69it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:08<00:06,  3.69it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:08<00:05,  3.69it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:08<00:05,  3.69it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:09<00:05,  3.69it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:09<00:05,  3.69it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:09<00:04,  3.68it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:09<00:04,  3.68it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:10<00:04,  3.68it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:10<00:04,  3.68it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:10<00:03,  3.69it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:11<00:03,  3.69it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:11<00:03,  3.68it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:11<00:02,  3.69it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:11<00:02,  3.68it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:12<00:02,  3.68it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:12<00:02,  3.68it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:12<00:01,  3.68it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:12<00:01,  3.68it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:13<00:01,  3.68it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:13<00:01,  3.68it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:13<00:00,  3.68it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:14<00:00,  3.66it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:14<00:00,  3.65it/s]\u001b[AI1018 12:08:15.155362 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/checkpoint-2600/config.json\n",
      "I1018 12:08:15.872464 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/checkpoint-2600/pytorch_model.bin\n",
      "I1018 12:08:15.876647 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output/checkpoint-2600\n",
      "\n",
      "Epoch: 100%|██████████| 10/10 [12:29<00:00, 74.83s/it]8it/s]\u001b[A\n",
      "I1018 12:08:15.899275 47382659590592 <ipython-input-15-fb4439387059>:148]  global_step = 2600, average loss = 0.10193525804887311\n",
      "I1018 12:08:15.900094 47382659590592 <ipython-input-15-fb4439387059>:157] Saving model checkpoint to bert_output\n",
      "I1018 12:08:15.904361 47382659590592 configuration_utils.py:70] Configuration saved in bert_output/config.json\n",
      "I1018 12:08:16.619512 47382659590592 modeling_utils.py:205] Model weights saved in bert_output/pytorch_model.bin\n",
      "I1018 12:08:16.684822 47382659590592 configuration_utils.py:148] loading configuration file bert_output/config.json\n",
      "I1018 12:08:16.686303 47382659590592 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I1018 12:08:16.687732 47382659590592 modeling_utils.py:334] loading weights file bert_output/pytorch_model.bin\n",
      "I1018 12:08:19.773999 47382659590592 tokenization_utils.py:306] Model name 'bert_output' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_output' is a path or url to a directory containing tokenizer files.\n",
      "I1018 12:08:19.775879 47382659590592 tokenization_utils.py:370] loading file bert_output/vocab.txt\n",
      "I1018 12:08:19.776599 47382659590592 tokenization_utils.py:370] loading file bert_output/added_tokens.json\n",
      "I1018 12:08:19.777371 47382659590592 tokenization_utils.py:370] loading file bert_output/special_tokens_map.json\n",
      "I1018 12:08:19.778156 47382659590592 tokenization_utils.py:370] loading file bert_output/tokenizer_config.json\n",
      "I1018 12:08:19.901874 47382659590592 tokenization_utils.py:306] Model name 'bert_output' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_output' is a path or url to a directory containing tokenizer files.\n",
      "I1018 12:08:19.903464 47382659590592 tokenization_utils.py:370] loading file bert_output/vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1018 12:08:19.904135 47382659590592 tokenization_utils.py:370] loading file bert_output/added_tokens.json\n",
      "I1018 12:08:19.904899 47382659590592 tokenization_utils.py:370] loading file bert_output/special_tokens_map.json\n",
      "I1018 12:08:19.905666 47382659590592 tokenization_utils.py:370] loading file bert_output/tokenizer_config.json\n",
      "I1018 12:08:19.962492 47382659590592 <ipython-input-15-fb4439387059>:181] Evaluate the following checkpoints: ['bert_output']\n",
      "I1018 12:08:19.963701 47382659590592 configuration_utils.py:148] loading configuration file bert_output/config.json\n",
      "I1018 12:08:19.964907 47382659590592 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I1018 12:08:19.966241 47382659590592 modeling_utils.py:334] loading weights file bert_output/pytorch_model.bin\n",
      "I1018 12:08:22.957585 47382659590592 <ipython-input-14-5385282ede45>:15] Loading features from cached file dataset/0/cached_dev_bert-base-cased_128_frame\n",
      "I1018 12:08:22.982207 47382659590592 <ipython-input-13-7f03f770a8ad>:19] ***** Running evaluation  *****\n",
      "I1018 12:08:22.983054 47382659590592 <ipython-input-13-7f03f770a8ad>:20]   Num examples = 263\n",
      "I1018 12:08:22.983857 47382659590592 <ipython-input-13-7f03f770a8ad>:21]   Batch size = 8\n",
      "Evaluating: 100%|██████████| 33/33 [00:04<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape:  (263, 9)\n",
      "out label ids:  (263, 9)\n",
      "[[0.01694706 0.00361117 0.9817386  0.0734073  0.14192045 0.01047219\n",
      "  0.00509638 0.04110993 0.00557649]\n",
      " [0.01878825 0.01362717 0.0185039  0.02329214 0.03015293 0.97606206\n",
      "  0.03332512 0.02985614 0.01623917]\n",
      " [0.02355079 0.0039293  0.02162997 0.07842961 0.05156181 0.01292698\n",
      "  0.01265248 0.5461138  0.00982897]\n",
      " [0.00883563 0.00812909 0.01062186 0.5365913  0.5579327  0.02258761\n",
      "  0.00335116 0.12130956 0.00718373]\n",
      " [0.01820121 0.0143407  0.01857713 0.01652319 0.03110326 0.9670236\n",
      "  0.0256306  0.01846602 0.0138386 ]]\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]]\n",
      "length:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1018 12:08:27.704968 47382659590592 <ipython-input-13-7f03f770a8ad>:93] ***** Eval results  *****\n",
      "I1018 12:08:27.705716 47382659590592 <ipython-input-13-7f03f770a8ad>:95]   auc = 0.9493028249140871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.9493028249140871}\n",
      "Hamming loss (proportion of wrong labels among all labels):  0.03802281368821293\n",
      "Exact match:  0.7452471482889734\n",
      "Number of articles with multiple frames:  59\n",
      "Accuracy among those:  0.5084745762711864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc_': 0.9493028249140871}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#english cased\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1018 12:30:13.298868 47382659590592 <ipython-input-15-fb4439387059>:110] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "I1018 12:30:13.431625 47382659590592 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/33b56ce0f312e47e4d77a57791a4fc6233ae4a560dd2bdd186107058294e58ab.3d3939ed0a2ebc86dd3c4703e5a591dcfb3341e9bbf87d411dea195948a37c74\n",
      "I1018 12:30:13.443064 47382659590592 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "I1018 12:30:13.560845 47382659590592 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/bb773818882b0524dc53a1b31a2cc95bc489f000e7e19773ba07846011a6c711.535306b226c42cebebbc0dabc83b92ab11260e9919e21e2ab0beb301f267b4c7\n",
      "I1018 12:30:13.897010 47382659590592 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/cc4042a0d6f70eae595ea0e6d49521b17bd6251f973b3e37d303ce7945b90eed.54b4dad9cc3db9aa8448458b782d11ab07c80dedb951906fd2f684a00ecdb1ee\n",
      "I1018 12:30:20.102153 47382659590592 modeling_utils.py:405] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1018 12:30:20.103351 47382659590592 modeling_utils.py:408] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1018 12:30:20.203577 47382659590592 <ipython-input-15-fb4439387059>:141] Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='/projectnb/llamagrp/feyzanb', config_name='', data_dir='dataset/0', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-multilingual-uncased', model_type='bertmultilabel', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='bert_output_multilingual_uncased', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=50, seed=42, server_ip='', server_port='', task_name='frame', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "I1018 12:30:20.206906 47382659590592 <ipython-input-14-5385282ede45>:15] Loading features from cached file dataset/0/cached_train_bert-base-multilingual-uncased_128_frame\n",
      "I1018 12:30:20.312147 47382659590592 <ipython-input-11-ce0a3a7e9c33>:42] ***** Running training *****\n",
      "I1018 12:30:20.313163 47382659590592 <ipython-input-11-ce0a3a7e9c33>:43]   Num examples = 1037\n",
      "I1018 12:30:20.313987 47382659590592 <ipython-input-11-ce0a3a7e9c33>:44]   Num Epochs = 10\n",
      "I1018 12:30:20.314769 47382659590592 <ipython-input-11-ce0a3a7e9c33>:45]   Instantaneous batch size per GPU = 4\n",
      "I1018 12:30:20.315534 47382659590592 <ipython-input-11-ce0a3a7e9c33>:47]   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "I1018 12:30:20.316305 47382659590592 <ipython-input-11-ce0a3a7e9c33>:48]   Gradient Accumulation steps = 1\n",
      "I1018 12:30:20.317065 47382659590592 <ipython-input-11-ce0a3a7e9c33>:49]   Total optimization steps = 2600\n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:17,  3.34it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:18,  3.27it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:19,  3.23it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:19,  3.21it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:19,  3.20it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:19,  3.18it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:19,  3.17it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:19,  3.17it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:19,  3.17it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:19,  3.16it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:18,  3.15it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:18,  3.16it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:18,  3.16it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:17,  3.16it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:17,  3.15it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:17,  3.15it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:16,  3.16it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:16,  3.15it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:06<01:16,  3.15it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:16,  3.16it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:15,  3.15it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:15,  3.15it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:15,  3.15it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:14,  3.15it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:14,  3.15it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:08<01:14,  3.15it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:13,  3.15it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:12,  3.18it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:09<01:12,  3.18it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:09<01:11,  3.20it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:11,  3.19it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:10<01:11,  3.20it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:10<01:11,  3.19it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:11,  3.17it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:11<01:11,  3.17it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:11<01:10,  3.17it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:11<01:10,  3.16it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:12<01:10,  3.15it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:12<01:09,  3.18it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:12<01:09,  3.18it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:12<01:08,  3.20it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:13<01:07,  3.22it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:13<01:07,  3.23it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:13<01:07,  3.21it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:14<01:06,  3.21it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:14<01:07,  3.19it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:14<01:07,  3.18it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:15<01:06,  3.18it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:15<01:06,  3.17it/s]\u001b[AI1018 12:30:36.092728 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-50/config.json\n",
      "I1018 12:30:37.381374 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-50/pytorch_model.bin\n",
      "I1018 12:30:37.384268 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|█▉        | 50/260 [00:17<02:28,  1.42it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<02:01,  1.71it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:44,  1.99it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:17<01:31,  2.25it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:23,  2.46it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:17,  2.66it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:13,  2.79it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:09,  2.92it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:07,  3.01it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:05,  3.06it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:20<01:04,  3.08it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:03,  3.13it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:20<01:03,  3.13it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:21<01:02,  3.17it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:01,  3.17it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:21<01:01,  3.19it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:00,  3.21it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<00:59,  3.22it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:22<00:59,  3.21it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:22<00:59,  3.19it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:23<00:59,  3.18it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:23<00:59,  3.17it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:23<00:59,  3.17it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:24<00:58,  3.19it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:24<00:58,  3.20it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:24<00:57,  3.21it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:25<00:57,  3.19it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:25<00:57,  3.18it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:25<00:56,  3.20it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:26<00:56,  3.21it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:26<00:55,  3.23it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:26<00:55,  3.21it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:27<00:55,  3.20it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:27<00:55,  3.18it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:27<00:55,  3.17it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:27<00:55,  3.17it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:28<00:54,  3.20it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:28<00:54,  3.19it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:28<00:54,  3.17it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:29<00:54,  3.17it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:29<00:53,  3.17it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:29<00:53,  3.17it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:30<00:53,  3.16it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:30<00:52,  3.15it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:30<00:52,  3.16it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:31<00:52,  3.16it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:31<00:51,  3.16it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:31<00:51,  3.18it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:32<00:51,  3.17it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:32<00:50,  3.16it/s]\u001b[AI1018 12:30:53.061041 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-100/config.json\n",
      "I1018 12:30:54.351464 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-100/pytorch_model.bin\n",
      "I1018 12:30:54.355696 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-100\n",
      "\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<01:53,  1.42it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<01:33,  1.70it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<01:20,  1.97it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:34<01:10,  2.24it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<01:03,  2.45it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:35<00:58,  2.63it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:35<00:55,  2.76it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:53,  2.87it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:36<00:51,  2.95it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:36<00:49,  3.04it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<00:48,  3.08it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:37<00:48,  3.10it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:37<00:47,  3.11it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<00:47,  3.13it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:38<00:46,  3.14it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:38<00:46,  3.14it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:45,  3.14it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:39<00:45,  3.15it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:39<00:45,  3.15it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:44,  3.15it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:40<00:44,  3.15it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:40<00:44,  3.15it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:40<00:43,  3.16it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:41<00:43,  3.18it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:41<00:42,  3.20it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:41<00:42,  3.21it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:42<00:42,  3.19it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:42<00:41,  3.18it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:42<00:41,  3.17it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:43<00:40,  3.20it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:43<00:40,  3.19it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:43<00:40,  3.17it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:44<00:40,  3.17it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:44<00:39,  3.19it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:44<00:39,  3.18it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:45<00:39,  3.18it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:45<00:39,  3.17it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:45<00:38,  3.16it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:46<00:38,  3.16it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:46<00:38,  3.16it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:46<00:38,  3.16it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:46<00:37,  3.18it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:47<00:37,  3.16it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:47<00:36,  3.17it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:47<00:36,  3.19it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:48<00:35,  3.21it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:48<00:35,  3.20it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:48<00:35,  3.18it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:49<00:35,  3.17it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:49<00:35,  3.17it/s]\u001b[AI1018 12:31:10.114029 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-150/config.json\n",
      "I1018 12:31:11.397242 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-150/pytorch_model.bin\n",
      "I1018 12:31:11.401034 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-150\n",
      "\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<01:17,  1.42it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:51<01:03,  1.71it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:51<00:54,  1.98it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:47,  2.23it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:43,  2.45it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:52<00:40,  2.62it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:52<00:37,  2.76it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:53<00:35,  2.87it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:53<00:34,  2.95it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:53<00:33,  3.01it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:54<00:32,  3.05it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:54<00:32,  3.08it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:54<00:31,  3.11it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:31,  3.12it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:55<00:30,  3.13it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:55<00:30,  3.14it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:29,  3.15it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:56<00:29,  3.15it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:56<00:28,  3.17it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:28,  3.16it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:57<00:28,  3.16it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:57<00:28,  3.17it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:58<00:27,  3.16it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:58<00:27,  3.16it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:58<00:27,  3.16it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:58<00:26,  3.16it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:59<00:26,  3.16it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:59<00:26,  3.15it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:59<00:25,  3.16it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:00<00:25,  3.16it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:00<00:25,  3.16it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:00<00:25,  3.15it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:01<00:24,  3.16it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:01<00:24,  3.16it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:01<00:24,  3.16it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:02<00:23,  3.15it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:02<00:23,  3.16it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:02<00:23,  3.16it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:03<00:22,  3.15it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:03<00:22,  3.15it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:03<00:22,  3.15it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:04<00:21,  3.16it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:04<00:21,  3.15it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:04<00:21,  3.15it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:05<00:20,  3.16it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:05<00:20,  3.16it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:05<00:20,  3.16it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:05<00:19,  3.15it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:06<00:19,  3.16it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:06<00:19,  3.16it/s]\u001b[AI1018 12:31:27.232831 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-200/config.json\n",
      "I1018 12:31:28.515992 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-200/pytorch_model.bin\n",
      "I1018 12:31:28.522403 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-200\n",
      "\n",
      "Iteration:  77%|███████▋  | 200/260 [01:08<00:42,  1.42it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:08<00:34,  1.71it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:08<00:29,  1.98it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:09<00:25,  2.23it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:09<00:22,  2.44it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:09<00:21,  2.62it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:19,  2.76it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:10<00:18,  2.87it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:10<00:17,  2.95it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:11<00:16,  3.01it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:11<00:16,  3.08it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:11<00:15,  3.13it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:11<00:15,  3.14it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:12<00:14,  3.15it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:12<00:14,  3.15it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:12<00:14,  3.15it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:13<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:13<00:13,  3.16it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:13<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:14<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:14<00:12,  3.16it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:14<00:12,  3.16it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:15<00:12,  3.15it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:15<00:11,  3.15it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:15<00:11,  3.15it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:16<00:11,  3.16it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:16<00:10,  3.15it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:16<00:10,  3.15it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:17<00:10,  3.15it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:17<00:09,  3.16it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:17<00:09,  3.15it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:17<00:09,  3.15it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:18<00:08,  3.15it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:18<00:08,  3.16it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:18<00:08,  3.15it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:19<00:07,  3.15it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:19<00:07,  3.16it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:19<00:07,  3.16it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:20<00:06,  3.15it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:20<00:06,  3.15it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:20<00:06,  3.16it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:21<00:06,  3.16it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:21<00:05,  3.16it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:21<00:05,  3.15it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:22<00:05,  3.18it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:22<00:04,  3.18it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:22<00:04,  3.17it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:23<00:04,  3.17it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:23<00:03,  3.16it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:23<00:03,  3.16it/s]\u001b[AI1018 12:31:44.336983 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-250/config.json\n",
      "I1018 12:31:45.622068 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-250/pytorch_model.bin\n",
      "I1018 12:31:45.626737 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-250\n",
      "\n",
      "Iteration:  96%|█████████▌| 250/260 [01:25<00:07,  1.42it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:25<00:05,  1.71it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:25<00:04,  1.98it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:26<00:03,  2.23it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:26<00:02,  2.45it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:26<00:01,  2.63it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:27<00:01,  2.76it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:27<00:01,  2.87it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:27<00:00,  2.95it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:28<00:00,  3.02it/s]\u001b[A\n",
      "Epoch:  10%|█         | 1/10 [01:28<13:15, 88.34s/it]42it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:20,  3.22it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:20,  3.20it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:20,  3.18it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:20,  3.18it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:20,  3.17it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:20,  3.16it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:20,  3.16it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:19,  3.16it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:19,  3.16it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:18,  3.18it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:18,  3.17it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:18,  3.16it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:18,  3.16it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:17,  3.16it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:17,  3.16it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:17,  3.15it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   7%|▋         | 17/260 [00:05<01:16,  3.16it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:16,  3.16it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:06<01:16,  3.15it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:16,  3.15it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:15,  3.16it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:15,  3.16it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:15,  3.15it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:14,  3.15it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:14,  3.15it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:08<01:13,  3.18it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:13,  3.18it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:13,  3.17it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:09<01:12,  3.18it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:09<01:12,  3.17it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:12,  3.17it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:10<01:11,  3.17it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:10<01:11,  3.16it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:11,  3.16it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:11<01:11,  3.16it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:11<01:10,  3.16it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:11<01:10,  3.15it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:12<01:09,  3.17it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:12<01:09,  3.16it/s]\u001b[AI1018 12:32:01.317788 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-300/config.json\n",
      "I1018 12:32:02.606357 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-300/pytorch_model.bin\n",
      "I1018 12:32:02.609240 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-300\n",
      "\n",
      "Iteration:  15%|█▌        | 40/260 [00:13<02:35,  1.42it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:14<02:08,  1.71it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:50,  1.98it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:37,  2.23it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:15<01:28,  2.44it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:21,  2.62it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:17,  2.76it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:16<01:14,  2.86it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:11,  2.95it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:09,  3.03it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:17<01:08,  3.07it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:07,  3.09it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:06,  3.11it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:18<01:06,  3.12it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:05,  3.13it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:04,  3.16it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:04,  3.16it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:04,  3.16it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:03,  3.16it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:03,  3.16it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:20<01:03,  3.16it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:03,  3.15it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:20<01:02,  3.16it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:21<01:02,  3.16it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:02,  3.15it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:21<01:01,  3.15it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:01,  3.16it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<01:01,  3.16it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:22<01:00,  3.15it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:23<01:00,  3.15it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:23<01:00,  3.15it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:23<00:59,  3.16it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:24<00:59,  3.15it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:24<00:59,  3.15it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:24<00:58,  3.15it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:25<00:58,  3.16it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:25<00:58,  3.15it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:25<00:58,  3.15it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:25<00:57,  3.15it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:26<00:57,  3.15it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:26<00:57,  3.15it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:26<00:56,  3.15it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:27<00:56,  3.18it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:27<00:55,  3.17it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:27<00:55,  3.17it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:28<00:55,  3.16it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:28<00:55,  3.15it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:28<00:54,  3.16it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:29<00:54,  3.16it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:29<00:54,  3.15it/s]\u001b[AI1018 12:32:18.438480 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-350/config.json\n",
      "I1018 12:32:19.727221 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-350/pytorch_model.bin\n",
      "I1018 12:32:19.730163 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-350\n",
      "\n",
      "Iteration:  35%|███▍      | 90/260 [00:31<02:00,  1.42it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:31<01:39,  1.71it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<01:24,  1.98it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:32<01:14,  2.23it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:32<01:08,  2.44it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:32<01:02,  2.62it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:32<00:59,  2.76it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:33<00:56,  2.87it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:33<00:55,  2.94it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:33<00:53,  3.03it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<00:52,  3.07it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<00:51,  3.10it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<00:50,  3.11it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:35<00:50,  3.12it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<00:49,  3.13it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:35<00:48,  3.17it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:36<00:48,  3.16it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:48,  3.16it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:36<00:48,  3.15it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:37<00:47,  3.16it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<00:47,  3.16it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:37<00:47,  3.15it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:38<00:46,  3.15it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<00:46,  3.16it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:38<00:46,  3.16it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:38<00:45,  3.16it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:45,  3.15it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:39<00:45,  3.16it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:39<00:44,  3.16it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:44,  3.15it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:40<00:44,  3.15it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:40<00:44,  3.15it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:41<00:43,  3.18it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:41<00:43,  3.18it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:41<00:42,  3.17it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:42<00:42,  3.16it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:42<00:42,  3.16it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:42<00:42,  3.16it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:43<00:41,  3.16it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:43<00:41,  3.15it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:43<00:40,  3.18it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:44<00:40,  3.20it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:44<00:40,  3.19it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:44<00:39,  3.21it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:44<00:39,  3.19it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:45<00:39,  3.18it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:45<00:38,  3.19it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:45<00:38,  3.17it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:46<00:38,  3.17it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:46<00:38,  3.17it/s]\u001b[AI1018 12:32:35.515752 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-400/config.json\n",
      "I1018 12:32:36.806916 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-400/pytorch_model.bin\n",
      "I1018 12:32:36.810024 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-400\n",
      "\n",
      "Iteration:  54%|█████▍    | 140/260 [00:48<01:24,  1.42it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:48<01:09,  1.70it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:48<00:59,  1.99it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:49<00:52,  2.24it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:49<00:47,  2.45it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:49<00:43,  2.63it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:50<00:41,  2.76it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:50<00:39,  2.87it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:50<00:37,  2.95it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:50<00:36,  3.03it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<00:35,  3.06it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:51<00:35,  3.09it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:51<00:34,  3.11it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:34,  3.12it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:33,  3.13it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:52<00:33,  3.13it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:53<00:33,  3.14it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:53<00:32,  3.15it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:53<00:32,  3.15it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:54<00:32,  3.14it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:54<00:31,  3.18it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:54<00:31,  3.17it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:55<00:30,  3.17it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:30,  3.16it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:55<00:30,  3.16it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:56<00:30,  3.16it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:29,  3.16it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:56<00:29,  3.15it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:56<00:29,  3.15it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:28,  3.15it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:57<00:28,  3.16it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:57<00:28,  3.15it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:58<00:27,  3.15it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:58<00:27,  3.15it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:58<00:27,  3.16it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:59<00:26,  3.18it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:59<00:26,  3.17it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:59<00:26,  3.16it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:00<00:25,  3.19it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:00<00:25,  3.18it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:00<00:25,  3.18it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:01<00:24,  3.17it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:01<00:24,  3.19it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:01<00:24,  3.17it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:02<00:23,  3.17it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:02<00:23,  3.17it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:02<00:23,  3.16it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:02<00:23,  3.15it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:03<00:22,  3.16it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:03<00:22,  3.16it/s]\u001b[AI1018 12:32:52.613649 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-450/config.json\n",
      "I1018 12:32:53.908715 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-450/pytorch_model.bin\n",
      "I1018 12:32:53.911550 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-450\n",
      "\n",
      "Iteration:  73%|███████▎  | 190/260 [01:05<00:49,  1.41it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:05<00:40,  1.70it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:05<00:34,  1.97it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:06<00:30,  2.23it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:06<00:26,  2.46it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:06<00:24,  2.63it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:07<00:23,  2.76it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:07<00:21,  2.87it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:07<00:20,  2.95it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:08<00:20,  3.01it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:08<00:19,  3.05it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:08<00:19,  3.08it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:09<00:18,  3.11it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:09<00:18,  3.12it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:09<00:17,  3.15it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:09<00:17,  3.15it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:17,  3.15it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:10<00:16,  3.16it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:10<00:16,  3.18it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:11<00:16,  3.17it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:11<00:15,  3.16it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:11<00:15,  3.16it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:12<00:15,  3.16it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:12<00:14,  3.16it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:12<00:14,  3.15it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:13<00:14,  3.16it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:13<00:13,  3.16it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:13<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:14<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:14<00:12,  3.15it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:14<00:12,  3.16it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:15<00:12,  3.15it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:15<00:12,  3.15it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:15<00:11,  3.15it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:15<00:11,  3.16it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:16<00:11,  3.15it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:16<00:10,  3.15it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:16<00:10,  3.16it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:17<00:10,  3.16it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:17<00:09,  3.16it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:17<00:09,  3.15it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:18<00:09,  3.15it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:18<00:08,  3.16it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:18<00:08,  3.15it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:19<00:08,  3.18it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:19<00:07,  3.17it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:19<00:07,  3.17it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:20<00:07,  3.16it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:20<00:06,  3.16it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:20<00:06,  3.15it/s]\u001b[AI1018 12:33:09.724298 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-500/config.json\n",
      "I1018 12:33:11.016326 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-500/pytorch_model.bin\n",
      "I1018 12:33:11.019556 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  92%|█████████▏| 240/260 [01:22<00:14,  1.42it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:22<00:11,  1.71it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:22<00:09,  1.98it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:23<00:07,  2.23it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:23<00:06,  2.44it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:23<00:05,  2.62it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:24<00:05,  2.76it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:24<00:04,  2.87it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:24<00:04,  2.97it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:25<00:03,  3.02it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:25<00:03,  3.06it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:25<00:02,  3.09it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:26<00:02,  3.11it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:26<00:02,  3.12it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:26<00:01,  3.13it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:27<00:01,  3.14it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:27<00:01,  3.14it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:27<00:00,  3.17it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:28<00:00,  3.16it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:28<00:00,  3.16it/s]\u001b[A\n",
      "Epoch:  20%|██        | 2/10 [02:56<11:47, 88.41s/it]55it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:18,  3.32it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:18,  3.30it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:18,  3.26it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:19,  3.23it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:19,  3.21it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:19,  3.19it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:19,  3.18it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:18,  3.20it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:18,  3.22it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:17,  3.23it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:16,  3.24it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:17,  3.22it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:17,  3.19it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:17,  3.18it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:17,  3.18it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:16,  3.20it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:16,  3.19it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:16,  3.17it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:16,  3.16it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:15,  3.19it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:14,  3.21it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:13,  3.22it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:13,  3.23it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:13,  3.21it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:12,  3.22it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:08<01:12,  3.21it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:13,  3.19it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:13,  3.17it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:09<01:12,  3.17it/s]\u001b[AI1018 12:33:26.607534 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-550/config.json\n",
      "I1018 12:33:27.897883 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-550/pytorch_model.bin\n",
      "I1018 12:33:27.901113 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-550\n",
      "\n",
      "Iteration:  12%|█▏        | 30/260 [00:10<02:41,  1.42it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:10<02:13,  1.71it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:11<01:54,  1.98it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:11<01:41,  2.23it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:11<01:32,  2.45it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:12<01:25,  2.63it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:12<01:20,  2.78it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:12<01:17,  2.88it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:13<01:15,  2.96it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:13<01:13,  3.01it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:13<01:11,  3.09it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:14<01:09,  3.14it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:09,  3.14it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:09,  3.14it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:15<01:08,  3.14it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:08,  3.15it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:07,  3.16it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:16<01:07,  3.15it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:07,  3.15it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:06,  3.15it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:16<01:06,  3.16it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:05,  3.18it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:05,  3.19it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:17<01:05,  3.18it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:05,  3.17it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:04,  3.19it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:04,  3.18it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:03,  3.18it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:03,  3.17it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:03,  3.16it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:20<01:03,  3.16it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:02,  3.16it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:20<01:02,  3.18it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:21<01:02,  3.17it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:01,  3.19it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:21<01:01,  3.17it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:01,  3.17it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<01:00,  3.17it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:22<01:00,  3.19it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:22<01:00,  3.17it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:23<01:00,  3.16it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:23<00:59,  3.16it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:23<00:59,  3.16it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:24<00:58,  3.18it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:24<00:58,  3.17it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:24<00:58,  3.19it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:25<00:57,  3.17it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:25<00:57,  3.20it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:25<00:57,  3.19it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:26<00:56,  3.21it/s]\u001b[AI1018 12:33:43.641373 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-600/config.json\n",
      "I1018 12:33:44.931396 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-600/pytorch_model.bin\n",
      "I1018 12:33:44.934467 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-600\n",
      "\n",
      "Iteration:  31%|███       | 80/260 [00:27<02:06,  1.42it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:28<01:44,  1.71it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:28<01:29,  1.98it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:28<01:19,  2.23it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:28<01:11,  2.45it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:29<01:06,  2.62it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:29<01:03,  2.76it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:29<01:00,  2.87it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:30<00:58,  2.95it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:30<00:56,  3.01it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:30<00:55,  3.07it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:31<00:54,  3.12it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<00:53,  3.15it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:31<00:53,  3.15it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:32<00:52,  3.15it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:32<00:52,  3.16it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:32<00:51,  3.18it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:33<00:51,  3.17it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:33<00:51,  3.16it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:33<00:50,  3.16it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<00:50,  3.16it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<00:50,  3.16it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<00:50,  3.15it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:34<00:49,  3.16it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<00:49,  3.16it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:35<00:48,  3.18it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:35<00:48,  3.17it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:48,  3.16it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:36<00:48,  3.16it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:36<00:47,  3.16it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<00:47,  3.18it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:37<00:47,  3.17it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:37<00:46,  3.16it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<00:46,  3.16it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:38<00:46,  3.16it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:38<00:45,  3.16it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:45,  3.15it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:39<00:44,  3.18it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:39<00:44,  3.18it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:44,  3.17it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:40<00:44,  3.16it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:40<00:43,  3.19it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:40<00:43,  3.20it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:41<00:43,  3.18it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:41<00:42,  3.17it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:41<00:42,  3.20it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:42<00:41,  3.19it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:42<00:41,  3.18it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:42<00:41,  3.19it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:43<00:41,  3.18it/s]\u001b[AI1018 12:34:00.696667 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-650/config.json\n",
      "I1018 12:34:01.988463 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-650/pytorch_model.bin\n",
      "I1018 12:34:01.991781 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-650\n",
      "\n",
      "Iteration:  50%|█████     | 130/260 [00:44<01:31,  1.42it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:45<01:15,  1.71it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:45<01:04,  1.98it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:45<00:57,  2.23it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:46<00:51,  2.44it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:46<00:47,  2.62it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:46<00:44,  2.76it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:46<00:42,  2.86it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:47<00:41,  2.95it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:47<00:39,  3.03it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:47<00:38,  3.10it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:48<00:38,  3.12it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:48<00:37,  3.12it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:48<00:37,  3.13it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:49<00:36,  3.14it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:49<00:36,  3.15it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:49<00:36,  3.15it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:50<00:35,  3.15it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:50<00:35,  3.15it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:50<00:35,  3.15it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:51<00:34,  3.15it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:51<00:34,  3.18it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:51<00:34,  3.17it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:52<00:33,  3.19it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:33,  3.18it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:52<00:33,  3.18it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:52<00:32,  3.17it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:53<00:32,  3.16it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:53<00:31,  3.19it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:53<00:31,  3.18it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:54<00:31,  3.17it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:54<00:31,  3.16it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:54<00:31,  3.16it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:30,  3.16it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:55<00:30,  3.16it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:55<00:29,  3.18it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:29,  3.17it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:56<00:29,  3.16it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:56<00:29,  3.16it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:28,  3.16it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:57<00:28,  3.18it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:57<00:27,  3.20it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:58<00:27,  3.18it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:58<00:27,  3.19it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:58<00:27,  3.18it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:58<00:26,  3.17it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:59<00:26,  3.17it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:59<00:26,  3.16it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:59<00:25,  3.16it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:00<00:25,  3.16it/s]\u001b[AI1018 12:34:17.763982 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-700/config.json\n",
      "I1018 12:34:19.055848 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-700/pytorch_model.bin\n",
      "I1018 12:34:19.058968 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-700\n",
      "\n",
      "Iteration:  69%|██████▉   | 180/260 [01:01<00:56,  1.42it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:02<00:46,  1.71it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:02<00:39,  1.98it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:02<00:34,  2.24it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:03<00:30,  2.45it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:03<00:28,  2.63it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:03<00:26,  2.77it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:04<00:25,  2.87it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:04<00:24,  2.95it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:04<00:23,  3.01it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:04<00:22,  3.08it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:05<00:22,  3.13it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:05<00:21,  3.14it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:05<00:21,  3.14it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:06<00:21,  3.14it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:06<00:20,  3.17it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:06<00:20,  3.17it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:07<00:19,  3.17it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:07<00:19,  3.16it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:07<00:19,  3.16it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:08<00:18,  3.18it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:08<00:18,  3.18it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:08<00:18,  3.17it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:09<00:18,  3.16it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:09<00:17,  3.16it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:09<00:17,  3.16it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:10<00:17,  3.16it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:10<00:16,  3.18it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  80%|████████  | 208/260 [01:10<00:16,  3.17it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:10<00:16,  3.16it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:11<00:15,  3.16it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:11<00:15,  3.16it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:11<00:15,  3.16it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:12<00:14,  3.15it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:12<00:14,  3.16it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:12<00:14,  3.16it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:13<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:13<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:13<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:14<00:12,  3.18it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:14<00:12,  3.18it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:14<00:12,  3.17it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:15<00:12,  3.16it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:15<00:11,  3.16it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:15<00:11,  3.16it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:16<00:11,  3.16it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:16<00:10,  3.15it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:16<00:10,  3.18it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:16<00:10,  3.18it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:17<00:09,  3.17it/s]\u001b[AI1018 12:34:34.831119 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-750/config.json\n",
      "I1018 12:34:36.123646 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-750/pytorch_model.bin\n",
      "I1018 12:34:36.127430 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-750\n",
      "\n",
      "Iteration:  88%|████████▊ | 230/260 [01:18<00:21,  1.42it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:19<00:16,  1.71it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:19<00:14,  1.99it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:19<00:12,  2.24it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:20<00:10,  2.45it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:20<00:09,  2.65it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:20<00:08,  2.78it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:21<00:07,  2.88it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:21<00:07,  2.96it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:21<00:06,  3.04it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:22<00:06,  3.08it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:22<00:06,  3.13it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:22<00:05,  3.14it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:22<00:05,  3.14it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:23<00:05,  3.14it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:23<00:04,  3.18it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:23<00:04,  3.20it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:24<00:04,  3.19it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:24<00:03,  3.18it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:24<00:03,  3.17it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:25<00:03,  3.16it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:25<00:02,  3.16it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:25<00:02,  3.19it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:26<00:02,  3.21it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:26<00:01,  3.20it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:26<00:01,  3.20it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:27<00:01,  3.18it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:27<00:00,  3.17it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:27<00:00,  3.17it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:27<00:00,  3.17it/s]\u001b[A\n",
      "Epoch:  30%|███       | 3/10 [04:25<10:18, 88.34s/it]59it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:20,  3.22it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:20,  3.20it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:20,  3.21it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:19,  3.21it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:19,  3.19it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:20,  3.17it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:19,  3.17it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:19,  3.17it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:18,  3.19it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:18,  3.20it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:17,  3.21it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:17,  3.19it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:17,  3.18it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:17,  3.18it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:17,  3.17it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:17,  3.16it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:16,  3.18it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:16,  3.17it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:16,  3.17it/s]\u001b[AI1018 12:34:51.713102 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-800/config.json\n",
      "I1018 12:34:53.004460 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-800/pytorch_model.bin\n",
      "I1018 12:34:53.008383 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-800\n",
      "\n",
      "Iteration:   8%|▊         | 20/260 [00:07<02:49,  1.42it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:07<02:20,  1.70it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:08<01:59,  1.99it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:08<01:45,  2.25it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:08<01:35,  2.47it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:09<01:28,  2.64it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:09<01:23,  2.80it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:09<01:20,  2.90it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:10<01:17,  2.98it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:10<01:15,  3.05it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:10<01:14,  3.10it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:11<01:12,  3.14it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:11<01:12,  3.14it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:11<01:12,  3.14it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:11<01:11,  3.15it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:12<01:11,  3.15it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:12<01:10,  3.17it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:12<01:09,  3.19it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:13<01:09,  3.17it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:13<01:09,  3.17it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:13<01:09,  3.17it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:14<01:09,  3.17it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:09,  3.16it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:08,  3.18it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:15<01:07,  3.19it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:07,  3.20it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:06,  3.21it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:16<01:06,  3.19it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:06,  3.18it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:05,  3.20it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:16<01:05,  3.19it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:05,  3.17it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:05,  3.19it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:17<01:05,  3.18it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:04,  3.20it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:04,  3.19it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:04,  3.18it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:03,  3.20it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:03,  3.18it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:02,  3.19it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:20<01:02,  3.18it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:02,  3.18it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:20<01:02,  3.17it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:21<01:01,  3.19it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:01,  3.20it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:21<01:00,  3.21it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:00,  3.19it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<01:00,  3.18it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:22<01:00,  3.17it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:22<01:00,  3.17it/s]\u001b[AI1018 12:35:08.686573 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-850/config.json\n",
      "I1018 12:35:09.963856 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-850/pytorch_model.bin\n",
      "I1018 12:35:09.967106 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-850\n",
      "\n",
      "Iteration:  27%|██▋       | 70/260 [00:24<02:12,  1.43it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:24<01:49,  1.73it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:25<01:34,  2.00it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:25<01:23,  2.24it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:25<01:15,  2.46it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:26<01:10,  2.63it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:26<01:06,  2.79it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:26<01:02,  2.91it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:27<01:01,  2.97it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:27<00:59,  3.02it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:27<00:58,  3.06it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:28<00:57,  3.09it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:28<00:57,  3.11it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:28<00:56,  3.12it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:28<00:56,  3.13it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:29<00:55,  3.14it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:29<00:55,  3.14it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:29<00:55,  3.14it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:30<00:54,  3.15it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:30<00:53,  3.18it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:30<00:53,  3.18it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:31<00:52,  3.20it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<00:52,  3.18it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:31<00:52,  3.17it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:32<00:52,  3.17it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:32<00:52,  3.17it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:32<00:51,  3.16it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:33<00:51,  3.15it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:33<00:50,  3.18it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:33<00:50,  3.18it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:34<00:50,  3.17it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<00:50,  3.16it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<00:49,  3.18it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:34<00:49,  3.17it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<00:49,  3.17it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:35<00:48,  3.17it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:35<00:48,  3.16it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:36<00:48,  3.15it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:36<00:47,  3.18it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:36<00:47,  3.18it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<00:46,  3.20it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:37<00:46,  3.22it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:37<00:45,  3.23it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<00:45,  3.23it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:38<00:45,  3.21it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:38<00:45,  3.22it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:45,  3.19it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:39<00:44,  3.18it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:39<00:44,  3.20it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:39<00:44,  3.19it/s]\u001b[AI1018 12:35:25.694445 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-900/config.json\n",
      "I1018 12:35:26.977643 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-900/pytorch_model.bin\n",
      "I1018 12:35:26.981052 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-900\n",
      "\n",
      "Iteration:  46%|████▌     | 120/260 [00:41<01:38,  1.43it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:41<01:21,  1.71it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:42<01:09,  1.98it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:42<01:01,  2.23it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:42<00:55,  2.46it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:43<00:51,  2.64it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:43<00:48,  2.79it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:43<00:45,  2.91it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:44<00:44,  2.97it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:44<00:42,  3.05it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:44<00:41,  3.10it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:44<00:41,  3.14it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:45<00:40,  3.14it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:45<00:40,  3.17it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:45<00:39,  3.17it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:46<00:39,  3.20it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:46<00:38,  3.21it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:46<00:38,  3.22it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:47<00:37,  3.23it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:47<00:37,  3.21it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:47<00:37,  3.22it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:48<00:37,  3.20it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:48<00:36,  3.21it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:48<00:36,  3.19it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:49<00:36,  3.21it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:49<00:36,  3.19it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:49<00:35,  3.21it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:49<00:35,  3.22it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:50<00:34,  3.20it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:50<00:34,  3.21it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:50<00:34,  3.19it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:51<00:34,  3.18it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:51<00:33,  3.20it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:51<00:33,  3.19it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:33,  3.18it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:52<00:33,  3.17it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:52<00:32,  3.16it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:53<00:32,  3.16it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:53<00:32,  3.16it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:53<00:31,  3.18it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:54<00:31,  3.17it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:54<00:31,  3.19it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:54<00:30,  3.17it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:30,  3.17it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:55<00:30,  3.17it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:55<00:30,  3.16it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:55<00:29,  3.15it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:56<00:29,  3.16it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:56<00:28,  3.18it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:56<00:28,  3.18it/s]\u001b[AI1018 12:35:42.657210 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-950/config.json\n",
      "I1018 12:35:43.927452 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-950/pytorch_model.bin\n",
      "I1018 12:35:43.930721 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  65%|██████▌   | 170/260 [00:58<01:02,  1.43it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:58<00:51,  1.72it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:59<00:44,  1.99it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:59<00:38,  2.25it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:59<00:34,  2.47it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [01:00<00:32,  2.64it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [01:00<00:30,  2.77it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [01:00<00:28,  2.90it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:01<00:27,  3.00it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:01<00:26,  3.05it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:01<00:25,  3.10it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:01<00:25,  3.12it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:02<00:24,  3.15it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:02<00:24,  3.18it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:02<00:23,  3.19it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:03<00:23,  3.17it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:03<00:23,  3.19it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:03<00:22,  3.20it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:04<00:22,  3.19it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:04<00:22,  3.21it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:04<00:21,  3.19it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:05<00:21,  3.19it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:05<00:21,  3.17it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:05<00:21,  3.17it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:06<00:20,  3.19it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:06<00:20,  3.21it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:06<00:20,  3.20it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:06<00:19,  3.21it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:07<00:19,  3.20it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:07<00:19,  3.18it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:07<00:18,  3.17it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:08<00:18,  3.17it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:08<00:18,  3.19it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:08<00:17,  3.21it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:09<00:17,  3.20it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:09<00:17,  3.18it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:09<00:17,  3.17it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:10<00:16,  3.17it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:10<00:16,  3.19it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:10<00:16,  3.18it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:11<00:15,  3.17it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:11<00:15,  3.19it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:11<00:15,  3.17it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:11<00:14,  3.20it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:12<00:14,  3.19it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:12<00:14,  3.21it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:12<00:13,  3.22it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:13<00:13,  3.23it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:13<00:13,  3.21it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:13<00:12,  3.19it/s]\u001b[AI1018 12:35:59.584253 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1000/config.json\n",
      "I1018 12:36:00.856244 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1000/pytorch_model.bin\n",
      "I1018 12:36:00.859117 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1000\n",
      "\n",
      "Iteration:  85%|████████▍ | 220/260 [01:15<00:27,  1.44it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:15<00:22,  1.72it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:16<00:19,  2.00it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:16<00:16,  2.26it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:16<00:14,  2.47it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:17<00:13,  2.64it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:17<00:12,  2.79it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:17<00:11,  2.89it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:17<00:10,  2.96it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:18<00:10,  3.02it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:18<00:09,  3.08it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:18<00:09,  3.10it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:19<00:08,  3.14it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:19<00:08,  3.14it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:19<00:08,  3.15it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:20<00:07,  3.15it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:20<00:07,  3.15it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:20<00:07,  3.17it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:21<00:06,  3.19it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:21<00:06,  3.17it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:21<00:06,  3.17it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:22<00:05,  3.20it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:22<00:05,  3.18it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:22<00:05,  3.17it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:22<00:05,  3.16it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:23<00:04,  3.16it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:23<00:04,  3.19it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:23<00:04,  3.21it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:24<00:03,  3.22it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:24<00:03,  3.20it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:24<00:03,  3.21it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:25<00:02,  3.19it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:25<00:02,  3.18it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:25<00:02,  3.20it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:26<00:01,  3.22it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:26<00:01,  3.23it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:26<00:01,  3.23it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:27<00:00,  3.24it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:27<00:00,  3.22it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:27<00:00,  3.23it/s]\u001b[A\n",
      "Epoch:  40%|████      | 4/10 [05:52<08:49, 88.20s/it]61it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:18,  3.31it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:19,  3.26it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:19,  3.23it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:19,  3.20it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:19,  3.21it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:19,  3.21it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:19,  3.19it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:18,  3.21it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:17,  3.22it/s]\u001b[AI1018 12:36:16.399020 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1050/config.json\n",
      "I1018 12:36:17.667402 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1050/pytorch_model.bin\n",
      "I1018 12:36:17.672463 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1050\n",
      "\n",
      "Iteration:   4%|▍         | 10/260 [00:04<02:53,  1.44it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:04<02:23,  1.73it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:05<02:03,  2.00it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:05<01:49,  2.26it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:05<01:39,  2.47it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:05<01:32,  2.64it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:06<01:27,  2.80it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:06<01:23,  2.90it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:06<01:20,  3.00it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:07<01:19,  3.05it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:07<01:17,  3.10it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:07<01:16,  3.11it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:08<01:15,  3.15it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:08<01:14,  3.17it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:08<01:14,  3.16it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:09<01:13,  3.19it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:09<01:13,  3.18it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:09<01:13,  3.18it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:10<01:12,  3.19it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:10<01:12,  3.18it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:10<01:12,  3.19it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:10<01:11,  3.20it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:11<01:11,  3.21it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:11<01:11,  3.19it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:11<01:11,  3.18it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:12<01:10,  3.18it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:12<01:10,  3.17it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:12<01:09,  3.19it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:13<01:09,  3.20it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:13<01:09,  3.18it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:13<01:08,  3.20it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:14<01:08,  3.19it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:07,  3.21it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:07,  3.20it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:15<01:07,  3.21it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:07,  3.19it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:06,  3.20it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:15<01:06,  3.21it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:05,  3.22it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:05,  3.22it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:16<01:05,  3.22it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:05,  3.20it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:04,  3.21it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:17<01:04,  3.23it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:04,  3.21it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:03,  3.22it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:03,  3.23it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:03,  3.21it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:02,  3.22it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:02,  3.22it/s]\u001b[AI1018 12:36:33.292047 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1100/config.json\n",
      "I1018 12:36:34.562381 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1100/pytorch_model.bin\n",
      "I1018 12:36:34.570867 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1100\n",
      "\n",
      "Iteration:  23%|██▎       | 60/260 [00:21<02:19,  1.44it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:21<01:54,  1.73it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:21<01:38,  2.01it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:22<01:27,  2.26it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:22<01:19,  2.46it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:22<01:13,  2.64it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:23<01:09,  2.80it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:23<01:06,  2.92it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:23<01:03,  3.01it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:24<01:01,  3.08it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:24<01:01,  3.11it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:24<01:00,  3.14it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:25<00:59,  3.17it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:25<00:58,  3.18it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:25<00:58,  3.20it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:25<00:57,  3.21it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:26<00:57,  3.21it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:26<00:56,  3.22it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:26<00:56,  3.22it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:27<00:56,  3.20it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:27<00:56,  3.21it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:27<00:55,  3.21it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:28<00:55,  3.22it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:28<00:54,  3.22it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:28<00:55,  3.20it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:29<00:54,  3.21it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:29<00:54,  3.19it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:29<00:54,  3.19it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:30<00:54,  3.17it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:30<00:53,  3.19it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:30<00:53,  3.20it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:30<00:52,  3.21it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<00:52,  3.22it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:31<00:52,  3.19it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:31<00:51,  3.21it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:32<00:51,  3.23it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:32<00:51,  3.21it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:32<00:51,  3.19it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:33<00:50,  3.18it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:33<00:50,  3.17it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:33<00:50,  3.19it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:34<00:49,  3.18it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<00:49,  3.20it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:34<00:49,  3.19it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:35<00:48,  3.20it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:35<00:48,  3.21it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:35<00:48,  3.19it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:35<00:48,  3.17it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:36<00:47,  3.20it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:36<00:47,  3.19it/s]\u001b[AI1018 12:36:50.171590 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1150/config.json\n",
      "I1018 12:36:51.442926 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1150/pytorch_model.bin\n",
      "I1018 12:36:51.445719 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1150\n",
      "\n",
      "Iteration:  42%|████▏     | 110/260 [00:38<01:44,  1.44it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:38<01:25,  1.74it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:38<01:13,  2.01it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:39<01:05,  2.25it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:39<00:59,  2.46it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:39<00:55,  2.64it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:40<00:51,  2.78it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:40<00:49,  2.90it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:40<00:47,  2.97it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:46,  3.04it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:41<00:45,  3.07it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:41<00:44,  3.10it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:41<00:44,  3.12it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:42<00:43,  3.15it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:42<00:43,  3.15it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:42<00:42,  3.17it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:43<00:42,  3.16it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:43<00:41,  3.19it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:43<00:41,  3.21it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:44<00:40,  3.20it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:44<00:40,  3.18it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:44<00:40,  3.17it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:45<00:40,  3.16it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:45<00:40,  3.16it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:45<00:39,  3.16it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:46<00:39,  3.18it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:46<00:38,  3.19it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:46<00:38,  3.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  53%|█████▎    | 138/260 [00:46<00:38,  3.21it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:47<00:37,  3.19it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:47<00:37,  3.20it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:47<00:37,  3.18it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:48<00:36,  3.20it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:48<00:36,  3.19it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:48<00:36,  3.21it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:49<00:35,  3.23it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:49<00:35,  3.21it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:49<00:35,  3.19it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:50<00:35,  3.17it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:50<00:34,  3.20it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:50<00:34,  3.22it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:51<00:34,  3.20it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:51<00:33,  3.22it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:51<00:33,  3.23it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:51<00:32,  3.23it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:52<00:32,  3.21it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:52<00:32,  3.22it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:52<00:32,  3.19it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:53<00:32,  3.18it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:53<00:31,  3.20it/s]\u001b[AI1018 12:37:07.100105 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1200/config.json\n",
      "I1018 12:37:08.370783 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1200/pytorch_model.bin\n",
      "I1018 12:37:08.373717 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1200\n",
      "\n",
      "Iteration:  62%|██████▏   | 160/260 [00:55<01:09,  1.44it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:55<00:57,  1.74it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:55<00:48,  2.02it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:56<00:42,  2.27it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:56<00:38,  2.49it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:56<00:35,  2.66it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:33,  2.81it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:57<00:32,  2.90it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:57<00:30,  2.99it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:29,  3.03it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:58<00:29,  3.07it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:58<00:28,  3.13it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:58<00:27,  3.16it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:59<00:27,  3.19it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:59<00:26,  3.21it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:59<00:26,  3.22it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [01:00<00:25,  3.23it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [01:00<00:25,  3.24it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:00<00:25,  3.22it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:00<00:25,  3.22it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:01<00:25,  3.20it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:01<00:24,  3.18it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:01<00:24,  3.20it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:02<00:23,  3.22it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:02<00:23,  3.20it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:02<00:23,  3.19it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:03<00:23,  3.17it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:03<00:22,  3.19it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:03<00:22,  3.17it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:04<00:22,  3.20it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:04<00:21,  3.19it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:04<00:21,  3.21it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:05<00:21,  3.20it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:05<00:20,  3.21it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:05<00:20,  3.19it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:06<00:20,  3.20it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:06<00:20,  3.18it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:06<00:19,  3.20it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:06<00:19,  3.22it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:07<00:18,  3.22it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:07<00:18,  3.21it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:07<00:18,  3.19it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:08<00:18,  3.20it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:08<00:17,  3.18it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:08<00:17,  3.20it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:09<00:17,  3.21it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:09<00:16,  3.21it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:09<00:16,  3.22it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:10<00:16,  3.22it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:10<00:15,  3.23it/s]\u001b[AI1018 12:37:23.968085 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1250/config.json\n",
      "I1018 12:37:25.236077 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1250/pytorch_model.bin\n",
      "I1018 12:37:25.239793 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1250\n",
      "\n",
      "Iteration:  81%|████████  | 210/260 [01:11<00:34,  1.44it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:12<00:28,  1.74it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:12<00:23,  2.01it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:12<00:20,  2.25it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:13<00:18,  2.46it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:13<00:17,  2.63it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:13<00:15,  2.77it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:14<00:14,  2.90it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:14<00:14,  2.98it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:14<00:13,  3.02it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:15<00:13,  3.06it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:15<00:12,  3.09it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:15<00:12,  3.14it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:16<00:11,  3.15it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:16<00:11,  3.14it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:16<00:11,  3.17it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:16<00:10,  3.19it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:17<00:10,  3.17it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:17<00:10,  3.17it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:17<00:09,  3.17it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:18<00:09,  3.16it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:18<00:09,  3.15it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:18<00:08,  3.18it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:19<00:08,  3.21it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:19<00:08,  3.22it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:19<00:07,  3.21it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:20<00:07,  3.22it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:20<00:07,  3.23it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:20<00:06,  3.24it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:21<00:06,  3.21it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:21<00:06,  3.22it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:21<00:05,  3.22it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:21<00:05,  3.22it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:22<00:05,  3.23it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:22<00:04,  3.20it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:22<00:04,  3.21it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:23<00:04,  3.19it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:23<00:04,  3.18it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:23<00:03,  3.20it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:24<00:03,  3.19it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:24<00:03,  3.17it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:24<00:02,  3.19it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:25<00:02,  3.20it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:25<00:02,  3.18it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:25<00:01,  3.21it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:26<00:01,  3.22it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:26<00:01,  3.23it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:26<00:00,  3.23it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:26<00:00,  3.21it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:27<00:00,  3.23it/s]\u001b[AI1018 12:37:40.752820 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1300/config.json\n",
      "I1018 12:37:42.019203 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1300/pytorch_model.bin\n",
      "I1018 12:37:42.022902 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1300\n",
      "\n",
      "Epoch:  50%|█████     | 5/10 [07:21<07:21, 88.36s/it]52it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:17,  3.35it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:17,  3.31it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:18,  3.29it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:18,  3.24it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:19,  3.22it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:19,  3.20it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:19,  3.18it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:19,  3.17it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:18,  3.19it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:18,  3.18it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:17,  3.20it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:17,  3.22it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:17,  3.20it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:16,  3.21it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:16,  3.19it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:16,  3.20it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:16,  3.18it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:16,  3.18it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:15,  3.20it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:14,  3.22it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:13,  3.23it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:13,  3.24it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:13,  3.21it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:13,  3.22it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:12,  3.22it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:08<01:12,  3.22it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:12,  3.20it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:12,  3.21it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:09<01:11,  3.21it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:09<01:11,  3.22it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:11,  3.22it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:11,  3.20it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:10<01:10,  3.21it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:10,  3.23it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:09,  3.24it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:11<01:09,  3.21it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:11<01:09,  3.19it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:09,  3.21it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:12<01:08,  3.22it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:12<01:08,  3.22it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:12<01:07,  3.23it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:13<01:07,  3.23it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:13<01:07,  3.23it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:13<01:07,  3.20it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:14<01:06,  3.21it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:14<01:07,  3.19it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:14<01:06,  3.18it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:14<01:06,  3.20it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:15<01:05,  3.22it/s]\u001b[AI1018 12:37:57.609851 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1350/config.json\n",
      "I1018 12:37:58.877442 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1350/pytorch_model.bin\n",
      "I1018 12:37:58.881086 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1350\n",
      "\n",
      "Iteration:  19%|█▉        | 50/260 [00:16<02:25,  1.44it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<02:00,  1.73it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:43,  2.01it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:17<01:31,  2.26it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:23,  2.48it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:16,  2.67it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:13,  2.79it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:19<01:09,  2.91it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:07,  2.98it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:05,  3.06it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:19<01:04,  3.09it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:03,  3.13it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:20<01:02,  3.16it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:20<01:02,  3.15it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:02,  3.15it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:21<01:01,  3.18it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:21<01:00,  3.20it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<01:00,  3.22it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:22<00:59,  3.23it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:22<00:59,  3.24it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:23<00:58,  3.24it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:23<00:58,  3.24it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:23<00:57,  3.24it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:23<00:57,  3.25it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:24<00:57,  3.22it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:24<00:57,  3.23it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:24<00:57,  3.21it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:25<00:56,  3.22it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:25<00:56,  3.22it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:25<00:56,  3.22it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:26<00:55,  3.22it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:26<00:55,  3.22it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:26<00:55,  3.22it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:27<00:55,  3.20it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:27<00:54,  3.21it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:27<00:54,  3.21it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:28<00:54,  3.19it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:28<00:53,  3.21it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:28<00:53,  3.19it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:28<00:53,  3.21it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:29<00:52,  3.22it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:29<00:52,  3.23it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:29<00:51,  3.24it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:30<00:51,  3.24it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:30<00:51,  3.24it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:30<00:51,  3.22it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:31<00:50,  3.22it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:31<00:50,  3.20it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:31<00:50,  3.18it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:32<00:50,  3.20it/s]\u001b[AI1018 12:38:14.441774 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1400/config.json\n",
      "I1018 12:38:15.711428 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1400/pytorch_model.bin\n",
      "I1018 12:38:15.714645 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  38%|███▊      | 100/260 [00:33<01:51,  1.44it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:33<01:32,  1.72it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<01:18,  2.00it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:34<01:09,  2.26it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:34<01:03,  2.47it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:35<00:58,  2.66it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:35<00:54,  2.81it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:35<00:52,  2.92it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:36<00:50,  3.01it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:36<00:49,  3.05it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:36<00:48,  3.08it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:37<00:47,  3.13it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:37<00:47,  3.14it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:37<00:46,  3.14it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:38<00:46,  3.16it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:38<00:45,  3.18it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:38<00:45,  3.19it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:38<00:44,  3.20it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:39<00:44,  3.21it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:39<00:43,  3.22it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:39<00:43,  3.20it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:40<00:43,  3.21it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:40<00:43,  3.20it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:40<00:42,  3.21it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:41<00:42,  3.23it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:41<00:42,  3.21it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:41<00:41,  3.21it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:42<00:41,  3.22it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:42<00:41,  3.19it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:42<00:40,  3.20it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:43<00:40,  3.21it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:43<00:40,  3.19it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:43<00:40,  3.18it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:43<00:39,  3.18it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:44<00:39,  3.19it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:44<00:39,  3.17it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:44<00:39,  3.17it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:45<00:38,  3.19it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:45<00:37,  3.21it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:45<00:37,  3.22it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:46<00:37,  3.23it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:46<00:36,  3.24it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:46<00:36,  3.24it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:47<00:36,  3.25it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:47<00:35,  3.25it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:47<00:35,  3.25it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:48<00:35,  3.25it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:48<00:35,  3.23it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:48<00:34,  3.23it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:48<00:34,  3.24it/s]\u001b[AI1018 12:38:31.279193 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1450/config.json\n",
      "I1018 12:38:32.551644 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1450/pytorch_model.bin\n",
      "I1018 12:38:32.555643 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1450\n",
      "\n",
      "Iteration:  58%|█████▊    | 150/260 [00:50<01:16,  1.44it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:50<01:02,  1.74it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:51<00:53,  2.02it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:51<00:47,  2.27it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:51<00:42,  2.49it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:52<00:39,  2.68it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:52<00:36,  2.82it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:52<00:35,  2.91it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:53<00:34,  3.00it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:53<00:32,  3.07it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:53<00:32,  3.09it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:53<00:31,  3.11it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:54<00:31,  3.15it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:54<00:30,  3.18it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:54<00:29,  3.20it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:55<00:29,  3.19it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:55<00:29,  3.20it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:55<00:28,  3.21it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:56<00:28,  3.22it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:56<00:28,  3.22it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:56<00:28,  3.20it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:57<00:27,  3.18it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:57<00:27,  3.20it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:57<00:27,  3.22it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:57<00:26,  3.20it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:58<00:26,  3.22it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:58<00:26,  3.20it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:58<00:26,  3.18it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:59<00:25,  3.20it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:59<00:25,  3.18it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:59<00:25,  3.17it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:00<00:24,  3.20it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:00<00:24,  3.22it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:00<00:23,  3.23it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:01<00:23,  3.23it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:01<00:23,  3.24it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:01<00:22,  3.24it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:02<00:22,  3.24it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:02<00:22,  3.24it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:02<00:22,  3.22it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:02<00:21,  3.20it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:03<00:21,  3.20it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:03<00:21,  3.21it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:03<00:21,  3.19it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:04<00:20,  3.18it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:04<00:20,  3.17it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:04<00:20,  3.19it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:05<00:19,  3.17it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:05<00:19,  3.19it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:05<00:19,  3.18it/s]\u001b[AI1018 12:38:48.151866 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1500/config.json\n",
      "I1018 12:38:49.419776 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1500/pytorch_model.bin\n",
      "I1018 12:38:49.422800 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1500\n",
      "\n",
      "Iteration:  77%|███████▋  | 200/260 [01:07<00:41,  1.43it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:07<00:34,  1.72it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:08<00:28,  2.00it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:08<00:25,  2.26it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:08<00:22,  2.48it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:08<00:20,  2.67it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:09<00:19,  2.81it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:09<00:18,  2.91it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:09<00:17,  3.00it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:10<00:16,  3.04it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:10<00:16,  3.10it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:10<00:15,  3.12it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:11<00:15,  3.13it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:11<00:14,  3.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  82%|████████▏ | 214/260 [01:11<00:14,  3.14it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:12<00:14,  3.14it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:12<00:13,  3.15it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:12<00:13,  3.17it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:13<00:13,  3.19it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:13<00:12,  3.20it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:13<00:12,  3.21it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:13<00:12,  3.19it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:14<00:11,  3.20it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:14<00:11,  3.21it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:14<00:11,  3.21it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:15<00:10,  3.19it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:15<00:10,  3.21it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:15<00:10,  3.22it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:16<00:09,  3.20it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:16<00:09,  3.22it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:16<00:09,  3.23it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:17<00:09,  3.21it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:17<00:08,  3.22it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:17<00:08,  3.22it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:18<00:08,  3.22it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:18<00:07,  3.22it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:18<00:07,  3.22it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:18<00:07,  3.20it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:19<00:06,  3.21it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:19<00:06,  3.21it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:19<00:06,  3.22it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:20<00:05,  3.19it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:20<00:05,  3.21it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:20<00:05,  3.20it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:21<00:04,  3.21it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:21<00:04,  3.22it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:21<00:04,  3.23it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:22<00:04,  3.24it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:22<00:03,  3.24it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:22<00:03,  3.25it/s]\u001b[AI1018 12:39:05.001721 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1550/config.json\n",
      "I1018 12:39:06.270421 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1550/pytorch_model.bin\n",
      "I1018 12:39:06.273645 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1550\n",
      "\n",
      "Iteration:  96%|█████████▌| 250/260 [01:24<00:06,  1.45it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:24<00:05,  1.74it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:24<00:03,  2.03it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:25<00:03,  2.28it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:25<00:02,  2.51it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:25<00:01,  2.67it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:26<00:01,  2.82it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:26<00:01,  2.93it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:26<00:00,  3.01it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:27<00:00,  3.05it/s]\u001b[A\n",
      "Epoch:  60%|██████    | 6/10 [08:48<05:52, 88.03s/it]45it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:18,  3.29it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:18,  3.27it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:19,  3.23it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:19,  3.23it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:18,  3.23it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:18,  3.23it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:18,  3.20it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:18,  3.22it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:17,  3.23it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:17,  3.23it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:16,  3.24it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:16,  3.24it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:16,  3.24it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:15,  3.25it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:15,  3.25it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:15,  3.22it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:15,  3.23it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:14,  3.24it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:14,  3.24it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:13,  3.25it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:13,  3.25it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:13,  3.25it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:12,  3.25it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:12,  3.25it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:12,  3.25it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:08<01:12,  3.25it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:11,  3.25it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:11,  3.25it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:11,  3.25it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:09<01:10,  3.25it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:10,  3.25it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:10,  3.22it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:10<01:10,  3.23it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:10,  3.23it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:09,  3.23it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:11<01:09,  3.23it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:11<01:09,  3.23it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:08,  3.23it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:12<01:08,  3.23it/s]\u001b[AI1018 12:39:21.634057 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1600/config.json\n",
      "I1018 12:39:22.904483 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1600/pytorch_model.bin\n",
      "I1018 12:39:22.907681 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1600\n",
      "\n",
      "Iteration:  15%|█▌        | 40/260 [00:13<02:32,  1.44it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:13<02:05,  1.74it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:48,  2.02it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:35,  2.27it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:14<01:26,  2.49it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:20,  2.66it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:16,  2.81it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:15<01:12,  2.92it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:11,  2.98it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:09,  3.04it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:16<01:07,  3.10it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:06,  3.14it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:05,  3.18it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:17<01:04,  3.20it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:17<01:04,  3.21it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:03,  3.23it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:03,  3.23it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:18<01:02,  3.24it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:02,  3.21it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:02,  3.22it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:19<01:02,  3.22it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:02,  3.20it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:20<01:01,  3.20it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:20<01:01,  3.21it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:00,  3.22it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:21<01:01,  3.20it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:21<01:00,  3.21it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<00:59,  3.22it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:22<00:59,  3.23it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:22<00:58,  3.24it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:22<00:58,  3.24it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:23<00:58,  3.24it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:23<00:58,  3.22it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:23<00:57,  3.23it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:24<00:58,  3.21it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:24<00:57,  3.21it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:24<00:57,  3.22it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:25<00:56,  3.22it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:25<00:56,  3.22it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:25<00:56,  3.22it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:26<00:55,  3.22it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:26<00:55,  3.20it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:26<00:55,  3.21it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:26<00:55,  3.22it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:27<00:54,  3.22it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:27<00:54,  3.19it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:27<00:54,  3.21it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:28<00:53,  3.22it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:28<00:53,  3.20it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:28<00:53,  3.22it/s]\u001b[AI1018 12:39:38.434226 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1650/config.json\n",
      "I1018 12:39:39.701932 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1650/pytorch_model.bin\n",
      "I1018 12:39:39.705099 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1650\n",
      "\n",
      "Iteration:  35%|███▍      | 90/260 [00:30<01:57,  1.44it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:30<01:37,  1.74it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:31<01:23,  2.01it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:31<01:13,  2.27it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:31<01:07,  2.47it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:31<01:02,  2.66it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:32<00:58,  2.79it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:32<00:55,  2.91it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:32<00:54,  2.99it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:33<00:52,  3.06it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:33<00:51,  3.12it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:33<00:50,  3.16it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<00:49,  3.18it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:34<00:48,  3.21it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:34<00:48,  3.22it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:35<00:48,  3.20it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:35<00:48,  3.18it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:35<00:47,  3.20it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:36<00:47,  3.18it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:36<00:47,  3.18it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:36<00:46,  3.20it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:36<00:46,  3.21it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:37<00:46,  3.20it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:37<00:45,  3.21it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:37<00:45,  3.21it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:38<00:45,  3.22it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:38<00:45,  3.20it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:38<00:44,  3.21it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:39<00:44,  3.21it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:39<00:44,  3.19it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:39<00:43,  3.21it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:40<00:43,  3.22it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:40<00:42,  3.23it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:40<00:42,  3.24it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:41<00:41,  3.24it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:41<00:41,  3.25it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:41<00:41,  3.25it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:41<00:40,  3.25it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:42<00:40,  3.25it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:42<00:40,  3.23it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:42<00:40,  3.23it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:43<00:39,  3.24it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:43<00:39,  3.24it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:43<00:39,  3.24it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:44<00:39,  3.22it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:44<00:39,  3.19it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:44<00:39,  3.18it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:45<00:38,  3.20it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:45<00:37,  3.22it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:45<00:37,  3.23it/s]\u001b[AI1018 12:39:55.237014 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1700/config.json\n",
      "I1018 12:39:56.504633 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1700/pytorch_model.bin\n",
      "I1018 12:39:56.507539 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1700\n",
      "\n",
      "Iteration:  54%|█████▍    | 140/260 [00:47<01:22,  1.45it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:47<01:08,  1.74it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:47<00:58,  2.02it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:48<00:51,  2.28it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:48<00:46,  2.51it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:48<00:42,  2.69it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:49<00:40,  2.84it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:49<00:38,  2.95it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:49<00:36,  3.03it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:50<00:36,  3.07it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:50<00:35,  3.13it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:50<00:34,  3.16it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:50<00:33,  3.19it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:51<00:33,  3.18it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:51<00:33,  3.20it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:51<00:32,  3.21it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:52<00:32,  3.21it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:52<00:32,  3.21it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:52<00:31,  3.22it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:53<00:31,  3.22it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:53<00:31,  3.20it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:53<00:30,  3.20it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:54<00:30,  3.21it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:54<00:30,  3.19it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:54<00:29,  3.21it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:54<00:29,  3.19it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:55<00:29,  3.21it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:55<00:28,  3.23it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:55<00:28,  3.24it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:56<00:28,  3.24it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:56<00:27,  3.24it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:56<00:27,  3.25it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:57<00:27,  3.25it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:57<00:27,  3.22it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:57<00:26,  3.22it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:58<00:26,  3.23it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:58<00:26,  3.20it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:58<00:26,  3.18it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:59<00:25,  3.20it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:59<00:25,  3.22it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:59<00:25,  3.20it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:59<00:24,  3.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  70%|███████   | 182/260 [01:00<00:24,  3.22it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:00<00:23,  3.23it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:00<00:23,  3.21it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:01<00:23,  3.22it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:01<00:22,  3.22it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:01<00:22,  3.22it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:02<00:22,  3.22it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:02<00:22,  3.23it/s]\u001b[AI1018 12:40:12.013824 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1750/config.json\n",
      "I1018 12:40:13.273501 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1750/pytorch_model.bin\n",
      "I1018 12:40:13.276376 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1750\n",
      "\n",
      "Iteration:  73%|███████▎  | 190/260 [01:04<00:48,  1.45it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:04<00:39,  1.74it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:04<00:33,  2.02it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:04<00:29,  2.28it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:05<00:26,  2.50it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:05<00:24,  2.66it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:05<00:22,  2.79it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:06<00:21,  2.91it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:06<00:20,  3.01it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:06<00:19,  3.05it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:07<00:19,  3.08it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:07<00:18,  3.13it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:07<00:18,  3.16it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:08<00:17,  3.18it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:08<00:17,  3.20it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:08<00:17,  3.20it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:08<00:16,  3.21it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:09<00:16,  3.19it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:09<00:16,  3.20it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:09<00:15,  3.21it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:10<00:15,  3.22it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:10<00:15,  3.22it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:10<00:15,  3.20it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:11<00:14,  3.21it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:11<00:14,  3.20it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:11<00:13,  3.21it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:12<00:13,  3.23it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:12<00:13,  3.23it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:12<00:12,  3.24it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:13<00:12,  3.24it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:13<00:12,  3.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:13<00:12,  3.22it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:13<00:11,  3.22it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:14<00:11,  3.22it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:14<00:11,  3.23it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:14<00:10,  3.22it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:15<00:10,  3.20it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:15<00:10,  3.18it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:15<00:09,  3.20it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:16<00:09,  3.22it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:16<00:09,  3.23it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:16<00:09,  3.21it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:17<00:08,  3.22it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:17<00:08,  3.20it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:17<00:08,  3.21it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:18<00:07,  3.19it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:18<00:07,  3.20it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:18<00:07,  3.21it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:18<00:06,  3.19it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:19<00:06,  3.21it/s]\u001b[AI1018 12:40:28.833695 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1800/config.json\n",
      "I1018 12:40:30.089453 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1800/pytorch_model.bin\n",
      "I1018 12:40:30.092688 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1800\n",
      "\n",
      "Iteration:  92%|█████████▏| 240/260 [01:20<00:13,  1.45it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:21<00:10,  1.75it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:21<00:08,  2.03it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:21<00:07,  2.29it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:22<00:06,  2.51it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:22<00:05,  2.70it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:22<00:04,  2.84it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:22<00:04,  2.95it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:23<00:03,  3.04it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:23<00:03,  3.08it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:23<00:03,  3.13it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:24<00:02,  3.14it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:24<00:02,  3.17it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:24<00:02,  3.18it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:25<00:01,  3.20it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:25<00:01,  3.18it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:25<00:01,  3.19it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:26<00:00,  3.20it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:26<00:00,  3.21it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:26<00:00,  3.21it/s]\u001b[A\n",
      "Epoch:  70%|███████   | 7/10 [10:15<04:23, 87.69s/it]63it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:20,  3.22it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:20,  3.22it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:20,  3.19it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:19,  3.20it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:20,  3.18it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:19,  3.20it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:18,  3.22it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:18,  3.23it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:17,  3.23it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:17,  3.24it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:16,  3.24it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:17,  3.22it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:16,  3.23it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:16,  3.24it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:15,  3.24it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:15,  3.21it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:15,  3.22it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:15,  3.22it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:14,  3.23it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:14,  3.23it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:14,  3.23it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:13,  3.22it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:13,  3.23it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:13,  3.23it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:12,  3.23it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:08<01:12,  3.23it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:12,  3.23it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:11,  3.23it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:11,  3.23it/s]\u001b[AI1018 12:40:45.481066 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1850/config.json\n",
      "I1018 12:40:46.730350 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1850/pytorch_model.bin\n",
      "I1018 12:40:46.733461 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|█▏        | 30/260 [00:10<02:38,  1.45it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:10<02:10,  1.75it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:11<01:52,  2.03it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:11<01:39,  2.28it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:11<01:30,  2.49it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:12<01:24,  2.67it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:12<01:19,  2.82it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:12<01:16,  2.93it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:13<01:13,  3.01it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:13<01:11,  3.08it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:13<01:10,  3.12it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:13<01:09,  3.15it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:08,  3.18it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:07,  3.19it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:14<01:07,  3.21it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:06,  3.21it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:07,  3.19it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:15<01:06,  3.21it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:06,  3.20it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:05,  3.21it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:16<01:05,  3.23it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:05,  3.21it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:04,  3.22it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:17<01:04,  3.22it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:18<01:03,  3.22it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:03,  3.22it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:03,  3.23it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:18<01:02,  3.23it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:02,  3.23it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:02,  3.23it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:19<01:01,  3.23it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:20<01:01,  3.23it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:20<01:01,  3.21it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:20<01:01,  3.21it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:21<01:00,  3.22it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:21<01:01,  3.20it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:21<01:00,  3.21it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:22<00:59,  3.22it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:22<00:59,  3.20it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:22<00:59,  3.22it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:22<00:58,  3.23it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:23<00:58,  3.24it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:23<00:58,  3.21it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:23<00:58,  3.22it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:24<00:57,  3.22it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:24<00:57,  3.23it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:24<00:57,  3.22it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:25<00:56,  3.23it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:25<00:56,  3.23it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:25<00:56,  3.23it/s]\u001b[AI1018 12:41:02.246856 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-1900/config.json\n",
      "I1018 12:41:03.493013 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-1900/pytorch_model.bin\n",
      "I1018 12:41:03.498073 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-1900\n",
      "\n",
      "Iteration:  31%|███       | 80/260 [00:27<02:03,  1.46it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:27<01:42,  1.75it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:27<01:27,  2.02it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:28<01:17,  2.28it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:28<01:10,  2.50it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:28<01:05,  2.68it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:29<01:01,  2.83it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:29<00:58,  2.94it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:05<00:20,  3.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:05<00:19,  3.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:06<00:19,  3.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:06<00:19,  3.22it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:06<00:18,  3.23it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:06<00:18,  3.24it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:07<00:18,  3.24it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:07<00:17,  3.25it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:07<00:17,  3.25it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:08<00:17,  3.25it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:08<00:16,  3.24it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:08<00:16,  3.25it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:09<00:16,  3.25it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:09<00:15,  3.25it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:09<00:15,  3.25it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:10<00:15,  3.25it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:10<00:15,  3.25it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:10<00:14,  3.25it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:10<00:14,  3.25it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:11<00:14,  3.26it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:11<00:13,  3.25it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:11<00:13,  3.25it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:12<00:13,  3.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:12<00:13,  3.23it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:12<00:12,  3.23it/s]\u001b[AI1018 12:43:16.040043 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-2300/config.json\n",
      "I1018 12:43:17.286528 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-2300/pytorch_model.bin\n",
      "I1018 12:43:17.289577 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-2300\n",
      "\n",
      "Iteration:  85%|████████▍ | 220/260 [01:14<00:27,  1.46it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:14<00:22,  1.75it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:14<00:18,  2.03it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:15<00:16,  2.29it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:15<00:14,  2.51it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:15<00:13,  2.69it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:16<00:12,  2.81it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:16<00:11,  2.92it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:16<00:10,  3.01it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:17<00:10,  3.07it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:17<00:09,  3.12it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:17<00:09,  3.15it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:18<00:08,  3.17it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:18<00:08,  3.19it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:18<00:08,  3.17it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:19<00:07,  3.19it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:19<00:07,  3.21it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:19<00:07,  3.20it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:19<00:06,  3.22it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:20<00:06,  3.23it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:20<00:06,  3.23it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:20<00:05,  3.24it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:21<00:05,  3.24it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:21<00:05,  3.24it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:21<00:04,  3.25it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:22<00:04,  3.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:22<00:04,  3.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:22<00:03,  3.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:23<00:03,  3.25it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:23<00:03,  3.25it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:23<00:03,  3.22it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:23<00:02,  3.23it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:24<00:02,  3.23it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:24<00:02,  3.20it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:24<00:01,  3.21it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:25<00:01,  3.22it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:25<00:01,  3.22it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:25<00:00,  3.22it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:26<00:00,  3.20it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:26<00:00,  3.22it/s]\u001b[A\n",
      "Epoch:  90%|█████████ | 9/10 [13:09<01:27, 87.18s/it]63it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:18,  3.29it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:18,  3.27it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:18,  3.26it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:18,  3.25it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:18,  3.24it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:19,  3.21it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:02<01:18,  3.22it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:18,  3.22it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:17,  3.22it/s]\u001b[AI1018 12:43:32.681277 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-2350/config.json\n",
      "I1018 12:43:33.926352 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-2350/pytorch_model.bin\n",
      "I1018 12:43:33.929393 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-2350\n",
      "\n",
      "Iteration:   4%|▍         | 10/260 [00:04<02:52,  1.45it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:04<02:22,  1.75it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:04<02:02,  2.03it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:05<01:47,  2.29it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:05<01:38,  2.50it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:05<01:31,  2.69it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:06<01:26,  2.81it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:06<01:23,  2.93it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:06<01:20,  3.01it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:07<01:18,  3.08it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:07<01:16,  3.12it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:07<01:15,  3.15it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:08<01:15,  3.15it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:08<01:15,  3.15it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:08<01:14,  3.18it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:09<01:13,  3.20it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:09<01:12,  3.22it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:09<01:12,  3.23it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:09<01:11,  3.24it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:10<01:11,  3.24it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:10<01:10,  3.25it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:10<01:10,  3.25it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:11<01:10,  3.25it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:11<01:09,  3.25it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:11<01:09,  3.26it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:12<01:09,  3.25it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:12<01:08,  3.25it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:12<01:08,  3.25it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:13<01:08,  3.25it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:13<01:07,  3.25it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:13<01:07,  3.25it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:13<01:07,  3.25it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:14<01:07,  3.23it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:14<01:07,  3.24it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:14<01:06,  3.24it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:15<01:06,  3.24it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:15<01:05,  3.25it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:15<01:06,  3.22it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:16<01:05,  3.22it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:16<01:05,  3.22it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:16<01:05,  3.23it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:17<01:04,  3.23it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:17<01:04,  3.23it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:17<01:04,  3.23it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:17<01:03,  3.23it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:18<01:03,  3.23it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:18<01:03,  3.23it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:18<01:02,  3.23it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:19<01:02,  3.23it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:19<01:02,  3.23it/s]\u001b[AI1018 12:43:49.385796 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-2400/config.json\n",
      "I1018 12:43:50.647360 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-2400/pytorch_model.bin\n",
      "I1018 12:43:50.651474 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-2400\n",
      "\n",
      "Iteration:  23%|██▎       | 60/260 [00:21<02:18,  1.45it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:21<01:54,  1.74it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:21<01:38,  2.01it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:22<01:26,  2.27it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:22<01:18,  2.49it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:22<01:12,  2.67it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:22<01:08,  2.82it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:23<01:05,  2.93it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:23<01:03,  3.02it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:23<01:01,  3.08it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:24<01:00,  3.13it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:24<00:59,  3.16it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:24<00:59,  3.18it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:25<00:58,  3.20it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:25<00:57,  3.21it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:25<00:57,  3.21it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:26<00:57,  3.22it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:26<00:56,  3.22it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:26<00:56,  3.22it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:26<00:56,  3.23it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:27<00:55,  3.22it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:27<00:55,  3.23it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:27<00:55,  3.23it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:28<00:54,  3.23it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:28<00:54,  3.23it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:28<00:54,  3.23it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:29<00:53,  3.23it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:29<00:53,  3.23it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:29<00:53,  3.23it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:30<00:52,  3.23it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:30<00:52,  3.23it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:30<00:52,  3.23it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:30<00:51,  3.23it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:31<00:51,  3.23it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:31<00:51,  3.23it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:31<00:51,  3.23it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:32<00:50,  3.23it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:32<00:50,  3.23it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:32<00:50,  3.23it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:33<00:49,  3.23it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:33<00:49,  3.23it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:33<00:49,  3.23it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:34<00:49,  3.21it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:34<00:48,  3.22it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:34<00:48,  3.23it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  40%|████      | 105/260 [00:35<00:47,  3.24it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:35<00:47,  3.24it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:35<00:47,  3.25it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:35<00:47,  3.22it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:36<00:46,  3.23it/s]\u001b[AI1018 12:44:06.129973 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-2450/config.json\n",
      "I1018 12:44:07.367489 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-2450/pytorch_model.bin\n",
      "I1018 12:44:07.370390 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-2450\n",
      "\n",
      "Iteration:  42%|████▏     | 110/260 [00:37<01:42,  1.46it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:38<01:24,  1.76it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:38<01:12,  2.04it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:38<01:03,  2.30it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:39<00:57,  2.52it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:39<00:53,  2.71it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:39<00:50,  2.85it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:39<00:48,  2.96it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:40<00:46,  3.04it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:40<00:45,  3.10it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:40<00:44,  3.12it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:41<00:44,  3.16it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:41<00:43,  3.18it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:41<00:42,  3.19it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:42<00:42,  3.20it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:42<00:42,  3.21it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:42<00:42,  3.19it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:43<00:41,  3.20it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:43<00:41,  3.21it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:43<00:40,  3.21it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:43<00:40,  3.22it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:44<00:40,  3.22it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:44<00:39,  3.22it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:44<00:39,  3.23it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:45<00:39,  3.23it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:45<00:38,  3.23it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:45<00:38,  3.23it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:46<00:38,  3.23it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:46<00:37,  3.23it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:46<00:37,  3.23it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:47<00:37,  3.23it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:47<00:36,  3.23it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:47<00:36,  3.23it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:48<00:36,  3.23it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:48<00:35,  3.23it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:48<00:35,  3.23it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:48<00:35,  3.23it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:49<00:34,  3.23it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:49<00:34,  3.21it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:49<00:34,  3.19it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:50<00:34,  3.22it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:50<00:33,  3.23it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:50<00:33,  3.24it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:51<00:33,  3.24it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:51<00:32,  3.24it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:51<00:32,  3.25it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:52<00:32,  3.22it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:52<00:31,  3.22it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:52<00:31,  3.23it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:52<00:31,  3.23it/s]\u001b[AI1018 12:44:22.853758 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-2500/config.json\n",
      "I1018 12:44:24.091199 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-2500/pytorch_model.bin\n",
      "I1018 12:44:24.094791 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-2500\n",
      "\n",
      "Iteration:  62%|██████▏   | 160/260 [00:54<01:08,  1.46it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:54<00:56,  1.75it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:55<00:48,  2.03it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:55<00:42,  2.29it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:55<00:38,  2.50it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:56<00:35,  2.68it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:56<00:33,  2.83it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:56<00:31,  2.94it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:56<00:30,  3.02it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:57<00:29,  3.08it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:57<00:28,  3.12it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:57<00:28,  3.16it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:58<00:27,  3.15it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:58<00:27,  3.18it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:58<00:26,  3.20it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:59<00:26,  3.22it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:59<00:26,  3.23it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:59<00:25,  3.24it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [01:00<00:25,  3.24it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [01:00<00:24,  3.24it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [01:00<00:24,  3.25it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [01:01<00:24,  3.25it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [01:01<00:23,  3.25it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [01:01<00:23,  3.26it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:01<00:23,  3.26it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:02<00:23,  3.26it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:02<00:22,  3.23it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:02<00:22,  3.23it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:03<00:22,  3.24it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:03<00:21,  3.24it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [01:03<00:21,  3.25it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:04<00:21,  3.25it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:04<00:20,  3.25it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:04<00:20,  3.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:05<00:20,  3.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:05<00:19,  3.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:05<00:19,  3.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:05<00:19,  3.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:06<00:19,  3.25it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:06<00:18,  3.26it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:06<00:18,  3.26it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:07<00:18,  3.23it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:07<00:17,  3.23it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:07<00:17,  3.23it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:08<00:17,  3.23it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:08<00:17,  3.23it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:08<00:16,  3.20it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:09<00:16,  3.21it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:09<00:16,  3.22it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:09<00:15,  3.22it/s]\u001b[AI1018 12:44:39.537353 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-2550/config.json\n",
      "I1018 12:44:40.778655 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-2550/pytorch_model.bin\n",
      "I1018 12:44:40.781817 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-2550\n",
      "\n",
      "Iteration:  81%|████████  | 210/260 [01:11<00:34,  1.46it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:11<00:27,  1.76it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:11<00:23,  2.03it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:12<00:20,  2.29it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:12<00:18,  2.51it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:12<00:16,  2.69it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:13<00:15,  2.83it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:13<00:14,  2.94it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:13<00:13,  3.02it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:13<00:13,  3.08it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:14<00:12,  3.13it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:14<00:12,  3.16it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:14<00:11,  3.18it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:15<00:11,  3.19it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:15<00:11,  3.20it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:15<00:10,  3.21it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:16<00:10,  3.21it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:16<00:10,  3.22it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:16<00:09,  3.22it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:17<00:09,  3.23it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:17<00:09,  3.23it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:17<00:08,  3.23it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:18<00:08,  3.23it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:18<00:08,  3.23it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:18<00:08,  3.23it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:18<00:07,  3.23it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:19<00:07,  3.23it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:19<00:07,  3.23it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:19<00:06,  3.23it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:20<00:06,  3.23it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:20<00:06,  3.23it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:20<00:05,  3.23it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:21<00:05,  3.23it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:21<00:05,  3.23it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:21<00:04,  3.23it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:22<00:04,  3.23it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:22<00:04,  3.23it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:22<00:04,  3.23it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:22<00:03,  3.23it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:23<00:03,  3.23it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:23<00:03,  3.20it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:23<00:02,  3.22it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:24<00:02,  3.20it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:24<00:02,  3.22it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:24<00:01,  3.23it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:25<00:01,  3.23it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:25<00:01,  3.24it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:25<00:00,  3.24it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:26<00:00,  3.21it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:26<00:00,  3.19it/s]\u001b[AI1018 12:44:56.158555 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/checkpoint-2600/config.json\n",
      "I1018 12:44:57.393826 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/checkpoint-2600/pytorch_model.bin\n",
      "I1018 12:44:57.397670 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_multilingual_uncased/checkpoint-2600\n",
      "\n",
      "Epoch: 100%|██████████| 10/10 [14:37<00:00, 87.38s/it]4it/s]\u001b[A\n",
      "I1018 12:44:57.404314 47382659590592 <ipython-input-15-fb4439387059>:148]  global_step = 2600, average loss = 0.10311647675609073\n",
      "I1018 12:44:57.405145 47382659590592 <ipython-input-15-fb4439387059>:157] Saving model checkpoint to bert_output_multilingual_uncased\n",
      "I1018 12:44:57.408215 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_multilingual_uncased/config.json\n",
      "I1018 12:44:58.641710 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_multilingual_uncased/pytorch_model.bin\n",
      "I1018 12:44:58.814792 47382659590592 configuration_utils.py:148] loading configuration file bert_output_multilingual_uncased/config.json\n",
      "I1018 12:44:58.816537 47382659590592 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "I1018 12:44:58.818094 47382659590592 modeling_utils.py:334] loading weights file bert_output_multilingual_uncased/pytorch_model.bin\n",
      "I1018 12:45:03.757362 47382659590592 tokenization_utils.py:306] Model name 'bert_output_multilingual_uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_output_multilingual_uncased' is a path or url to a directory containing tokenizer files.\n",
      "I1018 12:45:03.759442 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual_uncased/vocab.txt\n",
      "I1018 12:45:03.760251 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual_uncased/added_tokens.json\n",
      "I1018 12:45:03.761074 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual_uncased/special_tokens_map.json\n",
      "I1018 12:45:03.761922 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual_uncased/tokenizer_config.json\n",
      "I1018 12:45:04.138984 47382659590592 tokenization_utils.py:306] Model name 'bert_output_multilingual_uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_output_multilingual_uncased' is a path or url to a directory containing tokenizer files.\n",
      "I1018 12:45:04.140701 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual_uncased/vocab.txt\n",
      "I1018 12:45:04.141457 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual_uncased/added_tokens.json\n",
      "I1018 12:45:04.142272 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual_uncased/special_tokens_map.json\n",
      "I1018 12:45:04.143099 47382659590592 tokenization_utils.py:370] loading file bert_output_multilingual_uncased/tokenizer_config.json\n",
      "I1018 12:45:04.396867 47382659590592 <ipython-input-15-fb4439387059>:181] Evaluate the following checkpoints: ['bert_output_multilingual_uncased']\n",
      "I1018 12:45:04.398410 47382659590592 configuration_utils.py:148] loading configuration file bert_output_multilingual_uncased/config.json\n",
      "I1018 12:45:04.399684 47382659590592 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1018 12:45:04.401160 47382659590592 modeling_utils.py:334] loading weights file bert_output_multilingual_uncased/pytorch_model.bin\n",
      "I1018 12:45:09.326989 47382659590592 <ipython-input-14-5385282ede45>:15] Loading features from cached file dataset/0/cached_dev_bert-base-multilingual-uncased_128_frame\n",
      "I1018 12:45:09.358324 47382659590592 <ipython-input-13-7f03f770a8ad>:19] ***** Running evaluation  *****\n",
      "I1018 12:45:09.359139 47382659590592 <ipython-input-13-7f03f770a8ad>:20]   Num examples = 263\n",
      "I1018 12:45:09.360001 47382659590592 <ipython-input-13-7f03f770a8ad>:21]   Batch size = 8\n",
      "Evaluating: 100%|██████████| 33/33 [00:04<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape:  (263, 9)\n",
      "out label ids:  (263, 9)\n",
      "[[0.00641785 0.00774827 0.11744928 0.07964159 0.85637    0.00788516\n",
      "  0.00494396 0.01533365 0.0042123 ]\n",
      " [0.01451894 0.0134449  0.00871762 0.02746829 0.02761191 0.9738574\n",
      "  0.03275537 0.03378139 0.01475895]\n",
      " [0.02999844 0.00911674 0.01203873 0.8710075  0.03402162 0.01464205\n",
      "  0.04743391 0.08513666 0.01431633]\n",
      " [0.02069904 0.02251911 0.01240212 0.9034599  0.04326384 0.02238856\n",
      "  0.01424799 0.03493809 0.01531762]\n",
      " [0.01016908 0.00928711 0.02098522 0.01296748 0.07638957 0.9483169\n",
      "  0.0223646  0.01315499 0.01251543]]\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]]\n",
      "length:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1018 12:45:14.055046 47382659590592 <ipython-input-13-7f03f770a8ad>:93] ***** Eval results  *****\n",
      "I1018 12:45:14.055802 47382659590592 <ipython-input-13-7f03f770a8ad>:95]   auc = 0.9453030232769214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.9453030232769214}\n",
      "Hamming loss (proportion of wrong labels among all labels):  0.04224757076468103\n",
      "Exact match:  0.7338403041825095\n",
      "Number of articles with multiple frames:  59\n",
      "Accuracy among those:  0.4915254237288136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc_': 0.9453030232769214}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multilingual uncased\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1018 13:30:35.065402 47382659590592 <ipython-input-15-fb4439387059>:110] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "I1018 13:30:35.174237 47382659590592 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1018 13:30:35.176744 47382659590592 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1018 13:30:35.762551 47382659590592 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I1018 13:30:35.912993 47382659590592 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I1018 13:30:40.092534 47382659590592 modeling_utils.py:405] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1018 13:30:40.093681 47382659590592 modeling_utils.py:408] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1018 13:30:40.163558 47382659590592 <ipython-input-15-fb4439387059>:141] Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='/projectnb/llamagrp/feyzanb', config_name='', data_dir='dataset/0', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bertmultilabel', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='bert_output_uncased', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=50, seed=42, server_ip='', server_port='', task_name='frame', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "I1018 13:30:40.167085 47382659590592 <ipython-input-14-5385282ede45>:15] Loading features from cached file dataset/0/cached_train_bert-base-uncased_128_frame\n",
      "I1018 13:30:40.248275 47382659590592 <ipython-input-11-ce0a3a7e9c33>:42] ***** Running training *****\n",
      "I1018 13:30:40.249180 47382659590592 <ipython-input-11-ce0a3a7e9c33>:43]   Num examples = 1037\n",
      "I1018 13:30:40.250022 47382659590592 <ipython-input-11-ce0a3a7e9c33>:44]   Num Epochs = 10\n",
      "I1018 13:30:40.250890 47382659590592 <ipython-input-11-ce0a3a7e9c33>:45]   Instantaneous batch size per GPU = 4\n",
      "I1018 13:30:40.251698 47382659590592 <ipython-input-11-ce0a3a7e9c33>:47]   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "I1018 13:30:40.252515 47382659590592 <ipython-input-11-ce0a3a7e9c33>:48]   Gradient Accumulation steps = 1\n",
      "I1018 13:30:40.253316 47382659590592 <ipython-input-11-ce0a3a7e9c33>:49]   Total optimization steps = 2600\n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:09,  3.74it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:09,  3.69it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:10,  3.66it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:10,  3.64it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:10,  3.62it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:10,  3.60it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:10,  3.60it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:09,  3.60it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:09,  3.59it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:09,  3.59it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:09,  3.59it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:09,  3.59it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:08,  3.58it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:08,  3.58it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:08,  3.58it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:08,  3.59it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:07,  3.58it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:07,  3.58it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:07,  3.58it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:05<01:06,  3.58it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:05<01:06,  3.58it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:06,  3.57it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:06,  3.58it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:06<01:05,  3.58it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:06<01:05,  3.58it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:05,  3.58it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:05,  3.58it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:07<01:04,  3.59it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:04,  3.58it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:04,  3.58it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:08<01:03,  3.58it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:08<01:03,  3.59it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:03,  3.58it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:03,  3.58it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:09<01:02,  3.58it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:02,  3.59it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:02,  3.58it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:10<01:02,  3.58it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:10<01:01,  3.58it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:01,  3.58it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<01:01,  3.58it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:11<01:00,  3.58it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:11<01:00,  3.58it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<01:00,  3.59it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:12<01:00,  3.58it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:12<00:59,  3.58it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:59,  3.59it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:59,  3.59it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:13<00:58,  3.58it/s]\u001b[AI1018 13:30:54.220740 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-50/config.json\n",
      "I1018 13:30:54.905176 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-50/pytorch_model.bin\n",
      "I1018 13:30:54.908012 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-50\n",
      "\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<01:42,  2.05it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<01:28,  2.36it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:15<01:19,  2.63it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<01:12,  2.86it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<01:07,  3.04it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:16<01:04,  3.19it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<01:01,  3.30it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<01:00,  3.38it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:58,  3.43it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:17<00:57,  3.48it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:56,  3.51it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:56,  3.53it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:55,  3.54it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:18<00:55,  3.56it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:54,  3.57it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:54,  3.57it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:19<00:54,  3.57it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:53,  3.58it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:53,  3.58it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:53,  3.58it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:20<00:53,  3.57it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:52,  3.58it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:20<00:52,  3.59it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:21<00:52,  3.58it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<00:52,  3.57it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:51,  3.58it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:21<00:51,  3.58it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:51,  3.58it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:50,  3.57it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:50,  3.58it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:23<00:50,  3.58it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<00:50,  3.58it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:49,  3.57it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:23<00:49,  3.58it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:49,  3.59it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:48,  3.58it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:48,  3.58it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:24<00:48,  3.58it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:47,  3.58it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:47,  3.58it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:25<00:47,  3.58it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<00:47,  3.58it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<00:46,  3.59it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:46,  3.58it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:26<00:46,  3.58it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:46,  3.58it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:27<00:45,  3.58it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:27<00:45,  3.58it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:45,  3.57it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:44,  3.58it/s]\u001b[AI1018 13:31:08.866729 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-100/config.json\n",
      "I1018 13:31:09.551189 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-100/pytorch_model.bin\n",
      "I1018 13:31:09.556176 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-100\n",
      "\n",
      "Iteration:  38%|███▊      | 100/260 [00:29<01:17,  2.05it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:29<01:07,  2.37it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<01:00,  2.63it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:30<00:54,  2.86it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:30<00:51,  3.05it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:48,  3.19it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:46,  3.29it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:31<00:45,  3.38it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:31<00:44,  3.44it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:43,  3.48it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:32<00:42,  3.50it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:32<00:42,  3.53it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:41,  3.55it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:41,  3.56it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:33<00:40,  3.56it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:33<00:40,  3.57it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:40,  3.58it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:34<00:40,  3.57it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:34<00:39,  3.57it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:34<00:39,  3.58it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:39,  3.58it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:35<00:38,  3.58it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:35<00:38,  3.58it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:38,  3.58it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:35<00:37,  3.59it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:37,  3.58it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:37,  3.58it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:37,  3.58it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:37<00:36,  3.59it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:37<00:36,  3.58it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:37<00:36,  3.57it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:36,  3.58it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:35,  3.59it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:35,  3.58it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:35,  3.58it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:39<00:34,  3.59it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:34,  3.59it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:34,  3.58it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:34,  3.58it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:40<00:33,  3.58it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:33,  3.59it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:40<00:32,  3.61it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:41<00:32,  3.60it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:32,  3.59it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:41<00:32,  3.59it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:41<00:32,  3.59it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:42<00:31,  3.59it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:31,  3.58it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:42<00:31,  3.58it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:42<00:30,  3.59it/s]\u001b[AI1018 13:31:23.507076 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-150/config.json\n",
      "I1018 13:31:24.190148 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-150/pytorch_model.bin\n",
      "I1018 13:31:24.193688 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-150\n",
      "\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:53,  2.05it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:44<00:46,  2.37it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:44<00:40,  2.64it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:44<00:37,  2.86it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:45<00:34,  3.04it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:45<00:32,  3.18it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:45<00:31,  3.30it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:30,  3.38it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:46<00:29,  3.43it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:46<00:29,  3.47it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:46<00:28,  3.51it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:27,  3.54it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:47<00:27,  3.55it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:47<00:27,  3.55it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:47<00:26,  3.56it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:48<00:26,  3.57it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:48<00:26,  3.57it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:48<00:26,  3.57it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:48<00:25,  3.58it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:49<00:25,  3.58it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  65%|██████▌   | 170/260 [00:49<00:25,  3.58it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:49<00:24,  3.57it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:50<00:24,  3.58it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:50<00:24,  3.58it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:50<00:24,  3.58it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:50<00:23,  3.58it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:51<00:23,  3.58it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:51<00:23,  3.59it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:51<00:22,  3.58it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:52<00:22,  3.57it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:52<00:22,  3.58it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:22,  3.58it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:52<00:21,  3.58it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:53<00:21,  3.58it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:21,  3.58it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:53<00:20,  3.59it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:53<00:20,  3.58it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:54<00:20,  3.58it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:20,  3.58it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:54<00:19,  3.58it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:55<00:19,  3.58it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:55<00:19,  3.57it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:55<00:18,  3.58it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:55<00:18,  3.58it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:56<00:18,  3.58it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:18,  3.57it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:56<00:17,  3.58it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:57<00:17,  3.59it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:57<00:17,  3.60it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:16,  3.59it/s]\u001b[AI1018 13:31:38.153697 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-200/config.json\n",
      "I1018 13:31:38.829152 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-200/pytorch_model.bin\n",
      "I1018 13:31:38.832226 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-200\n",
      "\n",
      "Iteration:  77%|███████▋  | 200/260 [00:58<00:29,  2.07it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:58<00:24,  2.38it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:59<00:21,  2.65it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:59<00:19,  2.87it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:59<00:18,  3.05it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:59<00:17,  3.20it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:00<00:16,  3.31it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:00<00:15,  3.38it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:00<00:15,  3.43it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:01<00:14,  3.48it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:01<00:14,  3.51it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:01<00:13,  3.53it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:01<00:13,  3.54it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:02<00:13,  3.56it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:02<00:12,  3.57it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:02<00:12,  3.57it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:03<00:12,  3.57it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:03<00:12,  3.58it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:03<00:11,  3.58it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:03<00:11,  3.58it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:04<00:11,  3.57it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:04<00:10,  3.58it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:04<00:10,  3.59it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:04<00:10,  3.58it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:05<00:10,  3.58it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:05<00:09,  3.58it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:05<00:09,  3.58it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:06<00:09,  3.58it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:06<00:08,  3.57it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:06<00:08,  3.58it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:06<00:08,  3.59it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:07<00:08,  3.58it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:07<00:07,  3.58it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:07<00:07,  3.58it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:08<00:07,  3.59it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:08<00:06,  3.58it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:08<00:06,  3.57it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:08<00:06,  3.58it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:09<00:06,  3.59it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:09<00:05,  3.58it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:09<00:05,  3.58it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:10<00:05,  3.58it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:10<00:05,  3.58it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:10<00:04,  3.58it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:10<00:04,  3.57it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:11<00:04,  3.58it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:11<00:03,  3.58it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:11<00:03,  3.58it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:11<00:03,  3.57it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:12<00:03,  3.60it/s]\u001b[AI1018 13:31:52.782045 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-250/config.json\n",
      "I1018 13:31:53.456494 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-250/pytorch_model.bin\n",
      "I1018 13:31:53.460210 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-250\n",
      "\n",
      "Iteration:  96%|█████████▌| 250/260 [01:13<00:04,  2.07it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:13<00:03,  2.39it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:13<00:03,  2.65it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:14<00:02,  2.87it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:14<00:01,  3.05it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:14<00:01,  3.20it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:14<00:01,  3.30it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:15<00:00,  3.37it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:15<00:00,  3.44it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:15<00:00,  3.48it/s]\u001b[A\n",
      "Epoch:  10%|█         | 1/10 [01:15<11:22, 75.87s/it]01it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:10,  3.68it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:10,  3.64it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:11,  3.62it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:10,  3.61it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:10,  3.61it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:10,  3.59it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:10,  3.59it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:10,  3.59it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:09,  3.59it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:09,  3.58it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:09,  3.57it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:09,  3.58it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:08,  3.59it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:08,  3.58it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:08,  3.58it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:08,  3.58it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:07,  3.59it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:07,  3.58it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:07,  3.57it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:05<01:07,  3.58it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:05<01:06,  3.58it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:06,  3.58it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:06,  3.57it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:06<01:05,  3.60it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  10%|▉         | 25/260 [00:06<01:05,  3.60it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:05,  3.60it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:04,  3.59it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:07<01:04,  3.58it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:04,  3.59it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:04,  3.59it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:08<01:03,  3.58it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:08<01:03,  3.58it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:03,  3.58it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:03,  3.58it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:09<01:02,  3.58it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:02,  3.58it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:02,  3.58it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:10<01:01,  3.59it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:10<01:01,  3.58it/s]\u001b[AI1018 13:32:07.309577 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-300/config.json\n",
      "I1018 13:32:08.002875 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-300/pytorch_model.bin\n",
      "I1018 13:32:08.006287 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-300\n",
      "\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:48,  2.03it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:12<01:33,  2.35it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<01:23,  2.62it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<01:16,  2.85it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<01:11,  3.03it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:13<01:07,  3.18it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<01:04,  3.29it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<01:03,  3.37it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:14<01:01,  3.43it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<01:00,  3.50it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:59,  3.53it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:58,  3.55it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:15<00:58,  3.55it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:58,  3.56it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:57,  3.57it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:16<00:56,  3.60it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<00:56,  3.60it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:56,  3.59it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:56,  3.58it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:17<00:56,  3.58it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:55,  3.59it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:55,  3.58it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:55,  3.58it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:18<00:54,  3.58it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:54,  3.61it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:53,  3.63it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:19<00:53,  3.62it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:53,  3.60it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:53,  3.59it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:53,  3.59it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:20<00:52,  3.62it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:52,  3.61it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:20<00:52,  3.60it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:21<00:52,  3.59it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<00:51,  3.62it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:50,  3.63it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:21<00:50,  3.63it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:50,  3.62it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:50,  3.60it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:50,  3.59it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:22<00:50,  3.59it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<00:49,  3.60it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:49,  3.59it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:23<00:49,  3.58it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:49,  3.58it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:48,  3.59it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:48,  3.58it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:24<00:48,  3.58it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:48,  3.58it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:47,  3.59it/s]\u001b[AI1018 13:32:21.913473 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-350/config.json\n",
      "I1018 13:32:22.584346 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-350/pytorch_model.bin\n",
      "I1018 13:32:22.587497 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-350\n",
      "\n",
      "Iteration:  35%|███▍      | 90/260 [00:26<01:22,  2.07it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<01:10,  2.38it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:27<01:03,  2.65it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:27<00:58,  2.88it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:54,  3.06it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:51,  3.19it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:28<00:49,  3.30it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:28<00:48,  3.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:47,  3.44it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:46,  3.48it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:29<00:45,  3.51it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:29<00:44,  3.54it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:44,  3.55it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:30<00:44,  3.55it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:30<00:43,  3.55it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:43,  3.59it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:42,  3.59it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:31<00:42,  3.58it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:31<00:42,  3.58it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:42,  3.58it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:32<00:41,  3.58it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:32<00:41,  3.58it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:41,  3.57it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:41,  3.58it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:33<00:40,  3.58it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:33<00:40,  3.58it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:40,  3.57it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:39,  3.58it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:34<00:39,  3.59it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:34<00:39,  3.58it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:39,  3.58it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:35<00:38,  3.58it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:35<00:38,  3.59it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:38,  3.58it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:35<00:38,  3.57it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:37,  3.58it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:37,  3.58it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:37,  3.58it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:37<00:36,  3.58it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:37<00:36,  3.58it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:37<00:36,  3.59it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:36,  3.58it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:35,  3.57it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:35,  3.60it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:34,  3.62it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:38<00:34,  3.62it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:34,  3.63it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:33,  3.62it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:33,  3.61it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:40<00:33,  3.60it/s]\u001b[AI1018 13:32:36.524936 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-400/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1018 13:32:37.193723 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-400/pytorch_model.bin\n",
      "I1018 13:32:37.196815 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-400\n",
      "\n",
      "Iteration:  54%|█████▍    | 140/260 [00:41<00:57,  2.08it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:41<00:49,  2.39it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:41<00:44,  2.65it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:40,  2.87it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:42<00:37,  3.06it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:42<00:35,  3.20it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:42<00:34,  3.30it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:43<00:33,  3.38it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:43<00:32,  3.44it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:43<00:31,  3.51it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:31,  3.53it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:44<00:30,  3.54it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:44<00:30,  3.55it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:44<00:30,  3.56it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:29,  3.57it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:45<00:29,  3.57it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:45<00:29,  3.57it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:28,  3.58it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:46<00:28,  3.58it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:46<00:28,  3.58it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:46<00:27,  3.58it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:27,  3.58it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:47<00:27,  3.58it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:47<00:26,  3.61it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:47<00:26,  3.59it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:48<00:26,  3.58it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:48<00:26,  3.59it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:48<00:25,  3.59it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:48<00:25,  3.59it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:49<00:25,  3.58it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:49<00:25,  3.58it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:49<00:24,  3.59it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:49<00:24,  3.58it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:50<00:24,  3.57it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:50<00:24,  3.58it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:50<00:23,  3.60it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:51<00:23,  3.60it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:51<00:23,  3.59it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:51<00:22,  3.61it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:51<00:22,  3.59it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:52<00:22,  3.60it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:21,  3.60it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:52<00:21,  3.61it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:53<00:21,  3.60it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:21,  3.61it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:53<00:20,  3.60it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:53<00:20,  3.60it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:54<00:20,  3.60it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:20,  3.59it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:54<00:19,  3.58it/s]\u001b[AI1018 13:32:51.124323 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-450/config.json\n",
      "I1018 13:32:51.813468 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-450/pytorch_model.bin\n",
      "I1018 13:32:51.816955 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-450\n",
      "\n",
      "Iteration:  73%|███████▎  | 190/260 [00:55<00:34,  2.05it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:55<00:29,  2.37it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:56<00:25,  2.63it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:56<00:23,  2.86it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:56<00:21,  3.06it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:57<00:20,  3.20it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:57<00:19,  3.31it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:57<00:18,  3.38it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:57<00:18,  3.43it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:58<00:17,  3.48it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:58<00:17,  3.51it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:58<00:16,  3.53it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:59<00:16,  3.54it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:59<00:15,  3.58it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:59<00:15,  3.61it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:59<00:15,  3.60it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:00<00:15,  3.60it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:00<00:14,  3.59it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:00<00:14,  3.59it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:00<00:14,  3.59it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:01<00:13,  3.59it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:01<00:13,  3.59it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:01<00:13,  3.58it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:02<00:13,  3.59it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:02<00:12,  3.61it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:02<00:12,  3.61it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:02<00:12,  3.60it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:03<00:11,  3.59it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:03<00:11,  3.59it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:03<00:11,  3.59it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:04<00:11,  3.58it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:04<00:10,  3.58it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:04<00:10,  3.58it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:04<00:10,  3.59it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:05<00:10,  3.58it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:05<00:09,  3.58it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:05<00:09,  3.58it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:05<00:09,  3.59it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:06<00:08,  3.58it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:06<00:08,  3.58it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:06<00:08,  3.58it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:07<00:08,  3.59it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:07<00:07,  3.60it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:07<00:07,  3.59it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:07<00:07,  3.58it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:08<00:06,  3.59it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:08<00:06,  3.59it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:08<00:06,  3.61it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:09<00:06,  3.62it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:09<00:05,  3.60it/s]\u001b[AI1018 13:33:05.725418 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-500/config.json\n",
      "I1018 13:33:06.482009 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-500/pytorch_model.bin\n",
      "I1018 13:33:06.485700 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-500\n",
      "\n",
      "Iteration:  92%|█████████▏| 240/260 [01:10<00:10,  1.98it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:10<00:08,  2.30it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:10<00:06,  2.58it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:11<00:06,  2.82it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:11<00:05,  3.01it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:11<00:04,  3.15it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:12<00:04,  3.27it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:12<00:03,  3.39it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:12<00:03,  3.45it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:12<00:03,  3.48it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:13<00:02,  3.53it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:13<00:02,  3.54it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:13<00:02,  3.58it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:13<00:01,  3.59it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:14<00:01,  3.59it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:14<00:01,  3.58it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:14<00:01,  3.58it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:15<00:00,  3.58it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:15<00:00,  3.59it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:15<00:00,  3.58it/s]\u001b[A\n",
      "Epoch:  20%|██        | 2/10 [02:31<10:06, 75.85s/it]09it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:09,  3.72it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:09,  3.70it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:10,  3.66it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:10,  3.63it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:10,  3.62it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:09,  3.64it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:09,  3.63it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:09,  3.63it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:09,  3.61it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:09,  3.60it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:09,  3.60it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:08,  3.60it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:08,  3.59it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:08,  3.58it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:08,  3.59it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:07,  3.61it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:07,  3.61it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:07,  3.60it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:07,  3.59it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:05<01:06,  3.59it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:05<01:06,  3.62it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:05,  3.63it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:05,  3.63it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:06<01:05,  3.61it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:06<01:05,  3.60it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:05,  3.60it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:04,  3.60it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:07<01:04,  3.59it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:04,  3.58it/s]\u001b[AI1018 13:33:20.259714 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-550/config.json\n",
      "I1018 13:33:20.938992 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-550/pytorch_model.bin\n",
      "I1018 13:33:20.942260 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-550\n",
      "\n",
      "Iteration:  12%|█▏        | 30/260 [00:09<01:51,  2.06it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:36,  2.38it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:26,  2.64it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:19,  2.86it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:14,  3.05it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:10,  3.20it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:07,  3.32it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:05,  3.41it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:04,  3.46it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:11<01:03,  3.49it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:02,  3.52it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:12<01:01,  3.55it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<01:00,  3.57it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<01:00,  3.60it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<01:00,  3.59it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:13<01:00,  3.58it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<00:59,  3.59it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:59,  3.59it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:14<00:59,  3.58it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:59,  3.57it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:58,  3.58it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:58,  3.58it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:15<00:58,  3.58it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:57,  3.60it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:57,  3.59it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:56,  3.61it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<00:56,  3.61it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:56,  3.60it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:56,  3.59it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:17<00:56,  3.59it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:55,  3.61it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:55,  3.60it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:54,  3.62it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:18<00:54,  3.61it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:54,  3.62it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:54,  3.61it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:19<00:53,  3.59it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:53,  3.62it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:52,  3.64it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:52,  3.62it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:20<00:52,  3.61it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:52,  3.60it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:20<00:52,  3.59it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:20<00:52,  3.59it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<00:51,  3.60it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:51,  3.61it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:21<00:51,  3.60it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:50,  3.61it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:50,  3.60it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:50,  3.60it/s]\u001b[AI1018 13:33:34.915303 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-600/config.json\n",
      "I1018 13:33:35.798815 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-600/pytorch_model.bin\n",
      "I1018 13:33:35.803474 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-600\n",
      "\n",
      "Iteration:  31%|███       | 80/260 [00:23<01:43,  1.75it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:24<01:26,  2.08it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:24<01:14,  2.38it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:24<01:06,  2.65it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<01:01,  2.87it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:25<00:57,  3.06it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:25<00:54,  3.20it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:25<00:52,  3.30it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:26<00:50,  3.38it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:26<00:49,  3.46it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:26<00:48,  3.53it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<00:47,  3.57it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:27<00:46,  3.58it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:27<00:46,  3.58it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:46,  3.58it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:28<00:45,  3.59it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:28<00:45,  3.58it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:28<00:45,  3.59it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:44,  3.61it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:29<00:44,  3.61it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:29<00:44,  3.60it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:29<00:44,  3.59it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:44,  3.59it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:30<00:43,  3.61it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:30<00:43,  3.61it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:43,  3.60it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:31<00:42,  3.58it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  41%|████      | 107/260 [00:31<00:42,  3.59it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:31<00:42,  3.61it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:41,  3.63it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:32<00:41,  3.64it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:32<00:41,  3.63it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:40,  3.61it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:33<00:40,  3.60it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:33<00:40,  3.60it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:33<00:40,  3.60it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:40,  3.59it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:34<00:39,  3.58it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:34<00:39,  3.59it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:34<00:39,  3.59it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:38,  3.60it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:35<00:38,  3.62it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:35<00:38,  3.62it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:37,  3.61it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:36<00:37,  3.60it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:37,  3.59it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:37,  3.60it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:37,  3.59it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:37<00:36,  3.58it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:37<00:36,  3.59it/s]\u001b[AI1018 13:33:49.680025 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-650/config.json\n",
      "I1018 13:33:50.333403 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-650/pytorch_model.bin\n",
      "I1018 13:33:50.337050 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-650\n",
      "\n",
      "Iteration:  50%|█████     | 130/260 [00:38<01:02,  2.10it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:38<00:53,  2.41it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:47,  2.68it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:39<00:43,  2.89it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:39<00:40,  3.07it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:39<00:38,  3.21it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:40<00:37,  3.33it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:40<00:36,  3.40it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:40<00:35,  3.47it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:40<00:34,  3.49it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:41<00:34,  3.52it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:41<00:33,  3.54it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:41<00:33,  3.57it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:42<00:32,  3.57it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:42<00:32,  3.57it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:42<00:32,  3.58it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:42<00:31,  3.58it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:43<00:31,  3.58it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:43<00:31,  3.57it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:43<00:30,  3.58it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:30,  3.59it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:44<00:30,  3.58it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:44<00:29,  3.60it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:44<00:29,  3.59it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:45<00:29,  3.60it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:45<00:29,  3.60it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:45<00:29,  3.59it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:28,  3.60it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:46<00:28,  3.59it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:46<00:27,  3.62it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:46<00:27,  3.64it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:47<00:27,  3.65it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:47<00:26,  3.66it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:47<00:26,  3.66it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:47<00:26,  3.64it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:48<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:48<00:25,  3.64it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:48<00:25,  3.61it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:48<00:25,  3.60it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:49<00:25,  3.60it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:49<00:24,  3.62it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:49<00:24,  3.64it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:50<00:24,  3.63it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:50<00:24,  3.61it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:50<00:23,  3.60it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:50<00:23,  3.60it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:51<00:23,  3.62it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:51<00:22,  3.63it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:51<00:22,  3.63it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:51<00:22,  3.63it/s]\u001b[AI1018 13:34:04.210410 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-700/config.json\n",
      "I1018 13:34:04.864017 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-700/pytorch_model.bin\n",
      "I1018 13:34:04.900070 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-700\n",
      "\n",
      "Iteration:  69%|██████▉   | 180/260 [00:52<00:39,  2.03it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:53<00:33,  2.36it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:53<00:29,  2.62it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:53<00:27,  2.85it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:54<00:24,  3.04it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:54<00:23,  3.19it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:54<00:22,  3.29it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:54<00:21,  3.37it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:55<00:20,  3.46it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:55<00:20,  3.50it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:55<00:19,  3.53it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:56<00:19,  3.54it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:56<00:19,  3.55it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:56<00:18,  3.56it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:56<00:18,  3.57it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:57<00:18,  3.57it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:57<00:17,  3.57it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:57<00:17,  3.58it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:57<00:17,  3.58it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:58<00:17,  3.58it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:58<00:16,  3.60it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:58<00:16,  3.59it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:59<00:16,  3.59it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:59<00:15,  3.59it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:59<00:15,  3.58it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:59<00:15,  3.58it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:00<00:15,  3.58it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:00<00:14,  3.61it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:00<00:14,  3.63it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:01<00:14,  3.62it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:01<00:13,  3.60it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:01<00:13,  3.59it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:01<00:13,  3.59it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:02<00:13,  3.59it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:02<00:12,  3.58it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:02<00:12,  3.58it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:02<00:12,  3.58it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:03<00:11,  3.58it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:03<00:11,  3.58it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:03<00:11,  3.60it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:04<00:11,  3.59it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:04<00:10,  3.59it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:04<00:10,  3.59it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:04<00:10,  3.58it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:05<00:10,  3.58it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:05<00:09,  3.58it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:05<00:09,  3.59it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:06<00:09,  3.58it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:06<00:08,  3.60it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:06<00:08,  3.59it/s]\u001b[AI1018 13:34:18.962393 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-750/config.json\n",
      "I1018 13:34:19.717335 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-750/pytorch_model.bin\n",
      "I1018 13:34:19.720825 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-750\n",
      "\n",
      "Iteration:  88%|████████▊ | 230/260 [01:07<00:16,  1.82it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:08<00:13,  2.15it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:08<00:11,  2.45it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:08<00:09,  2.70it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:08<00:08,  2.91it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:09<00:08,  3.11it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:09<00:07,  3.24it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:09<00:06,  3.36it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:09<00:06,  3.43it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:10<00:06,  3.49it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:10<00:05,  3.54it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:10<00:05,  3.55it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:11<00:05,  3.58it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:11<00:04,  3.57it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:11<00:04,  3.60it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:11<00:04,  3.62it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:12<00:03,  3.64it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:12<00:03,  3.62it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:12<00:03,  3.62it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:13<00:03,  3.60it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:13<00:02,  3.59it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:13<00:02,  3.62it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:13<00:02,  3.64it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:14<00:01,  3.62it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:14<00:01,  3.62it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:14<00:01,  3.60it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:14<00:01,  3.59it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:15<00:00,  3.62it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:15<00:00,  3.61it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:15<00:00,  3.63it/s]\u001b[A\n",
      "Epoch:  30%|███       | 3/10 [03:47<08:51, 75.88s/it]14it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:10,  3.67it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:10,  3.68it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:09,  3.68it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:09,  3.68it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:09,  3.65it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:09,  3.65it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:09,  3.65it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:09,  3.64it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:08,  3.64it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:08,  3.64it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:08,  3.64it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:08,  3.62it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:08,  3.60it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:08,  3.60it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:08,  3.60it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:07,  3.59it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:07,  3.61it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:07,  3.59it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:06,  3.62it/s]\u001b[AI1018 13:34:33.413119 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-800/config.json\n",
      "I1018 13:34:34.089629 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-800/pytorch_model.bin\n",
      "I1018 13:34:34.093121 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-800\n",
      "\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:55,  2.07it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:39,  2.40it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:28,  2.68it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:21,  2.90it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:16,  3.09it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:12,  3.22it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:10,  3.34it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:08,  3.40it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:06,  3.48it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:05,  3.54it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:04,  3.58it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:03,  3.61it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:03,  3.60it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:02,  3.62it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:02,  3.61it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:02,  3.60it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:02,  3.59it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:01,  3.62it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:01,  3.61it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:11<01:00,  3.63it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:00,  3.61it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<01:00,  3.60it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<01:00,  3.59it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<01:00,  3.62it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<00:59,  3.63it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:13<00:59,  3.62it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:58,  3.65it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:58,  3.63it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:58,  3.61it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:57,  3.62it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:15<00:57,  3.63it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:57,  3.61it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:57,  3.61it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:56,  3.60it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<00:56,  3.59it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:56,  3.58it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:55,  3.61it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:16<00:55,  3.61it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:55,  3.60it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:55,  3.59it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:55,  3.58it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:18<00:54,  3.61it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:54,  3.60it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:53,  3.63it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:18<00:53,  3.64it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:52,  3.65it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:52,  3.63it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:52,  3.63it/s]\u001b[AI1018 13:34:48.089295 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-850/config.json\n",
      "I1018 13:34:48.966760 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-850/pytorch_model.bin\n",
      "I1018 13:34:48.970148 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-850\n",
      "\n",
      "Iteration:  27%|██▋       | 70/260 [00:21<01:53,  1.67it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  27%|██▋       | 71/260 [00:21<01:34,  2.00it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:21<01:21,  2.30it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:21<01:12,  2.59it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:22<01:05,  2.84it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:22<01:01,  3.02it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:22<00:57,  3.19it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:55,  3.32it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:23<00:53,  3.42it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:23<00:51,  3.49it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:23<00:51,  3.52it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:24<00:50,  3.54it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:24<00:50,  3.55it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:24<00:49,  3.55it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:49,  3.57it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:25<00:48,  3.60it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:25<00:48,  3.60it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:25<00:47,  3.61it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:26<00:47,  3.60it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:26<00:47,  3.61it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:26<00:47,  3.60it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<00:46,  3.62it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:27<00:46,  3.63it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:27<00:46,  3.62it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:45,  3.62it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:45,  3.62it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:28<00:45,  3.61it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:28<00:45,  3.60it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:44,  3.62it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:29<00:44,  3.64it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:29<00:43,  3.65it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:29<00:43,  3.66it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:43,  3.64it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:30<00:43,  3.65it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:30<00:42,  3.66it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:42,  3.67it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:42,  3.65it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:31<00:42,  3.62it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:31<00:41,  3.63it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:41,  3.61it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:32<00:41,  3.63it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:32<00:40,  3.64it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:40,  3.65it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:40,  3.66it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:33<00:40,  3.64it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:33<00:39,  3.65it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:39,  3.66it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:34<00:39,  3.64it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:34<00:39,  3.62it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:34<00:39,  3.60it/s]\u001b[AI1018 13:35:02.752919 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-900/config.json\n",
      "I1018 13:35:03.417767 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-900/pytorch_model.bin\n",
      "I1018 13:35:03.420488 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-900\n",
      "\n",
      "Iteration:  46%|████▌     | 120/260 [00:35<01:07,  2.09it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:35<00:57,  2.41it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:36<00:51,  2.67it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:36<00:47,  2.90it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:36<00:43,  3.09it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:41,  3.22it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:37<00:40,  3.32it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:37<00:38,  3.42it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:37<00:38,  3.47it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:38<00:37,  3.51it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:38<00:36,  3.55it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:38<00:36,  3.57it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:35,  3.56it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:39<00:35,  3.59it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:39<00:35,  3.58it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:39<00:34,  3.61it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:34,  3.63it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:40<00:33,  3.64it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:40<00:33,  3.66it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:40<00:33,  3.66it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:41<00:32,  3.64it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:41<00:32,  3.62it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:41<00:32,  3.63it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:32,  3.61it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:42<00:32,  3.60it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:42<00:31,  3.60it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:42<00:31,  3.62it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:43<00:30,  3.63it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:43<00:30,  3.63it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:30,  3.61it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:44<00:30,  3.60it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:44<00:29,  3.62it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:44<00:29,  3.64it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:29,  3.65it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:45<00:28,  3.63it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:45<00:28,  3.65it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:28,  3.63it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:46<00:28,  3.61it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:46<00:27,  3.62it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:46<00:27,  3.63it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:27,  3.63it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:47<00:27,  3.61it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:47<00:26,  3.61it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:47<00:26,  3.60it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:47<00:26,  3.62it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:48<00:26,  3.60it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:48<00:25,  3.61it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:48<00:25,  3.62it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:49<00:25,  3.63it/s]\u001b[AI1018 13:35:17.428049 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-950/config.json\n",
      "I1018 13:35:18.389193 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-950/pytorch_model.bin\n",
      "I1018 13:35:18.392459 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-950\n",
      "\n",
      "Iteration:  65%|██████▌   | 170/260 [00:50<00:56,  1.59it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:50<00:46,  1.92it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:51<00:39,  2.23it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:51<00:34,  2.53it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:51<00:30,  2.78it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:51<00:28,  2.97it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:52<00:26,  3.13it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:52<00:25,  3.27it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:52<00:24,  3.38it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:52<00:23,  3.44it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:53<00:22,  3.51it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:53<00:22,  3.53it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:53<00:21,  3.57it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:54<00:21,  3.59it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:54<00:21,  3.60it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:54<00:20,  3.62it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:54<00:20,  3.60it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:55<00:20,  3.59it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:55<00:19,  3.61it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:55<00:19,  3.63it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:56<00:19,  3.62it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:56<00:19,  3.61it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:56<00:18,  3.60it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:56<00:18,  3.59it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:57<00:18,  3.61it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:57<00:17,  3.63it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:57<00:17,  3.65it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:57<00:17,  3.66it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:58<00:17,  3.64it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:58<00:16,  3.65it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:58<00:16,  3.66it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:59<00:16,  3.64it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:59<00:16,  3.62it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:59<00:15,  3.60it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:59<00:15,  3.60it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:00<00:15,  3.60it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:00<00:15,  3.59it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:00<00:14,  3.58it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:00<00:14,  3.61it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:01<00:14,  3.61it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:01<00:13,  3.60it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:01<00:13,  3.59it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:02<00:13,  3.61it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:02<00:12,  3.62it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:02<00:12,  3.63it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:02<00:12,  3.63it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:03<00:12,  3.61it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:03<00:11,  3.61it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:03<00:11,  3.63it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:04<00:11,  3.62it/s]\u001b[AI1018 13:35:32.409915 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1000/config.json\n",
      "I1018 13:35:33.257107 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1000/pytorch_model.bin\n",
      "I1018 13:35:33.316009 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1000\n",
      "\n",
      "Iteration:  85%|████████▍ | 220/260 [01:05<00:24,  1.64it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:05<00:19,  1.97it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:05<00:16,  2.29it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:06<00:14,  2.58it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:06<00:12,  2.83it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:06<00:11,  3.03it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:07<00:10,  3.18it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:07<00:09,  3.31it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:07<00:09,  3.38it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:07<00:09,  3.43it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:08<00:08,  3.50it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:08<00:08,  3.53it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:08<00:07,  3.57it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:08<00:07,  3.60it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:09<00:07,  3.60it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:09<00:06,  3.59it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:09<00:06,  3.58it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:10<00:06,  3.61it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:10<00:06,  3.63it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:10<00:05,  3.62it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:10<00:05,  3.64it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:11<00:05,  3.65it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:11<00:04,  3.65it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:11<00:04,  3.64it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:12<00:04,  3.64it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:12<00:04,  3.62it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:12<00:03,  3.63it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:12<00:03,  3.63it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:13<00:03,  3.63it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:13<00:03,  3.62it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:13<00:02,  3.63it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:13<00:02,  3.62it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:14<00:02,  3.64it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:14<00:01,  3.65it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:14<00:01,  3.66it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:15<00:01,  3.66it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:15<00:01,  3.67it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:15<00:00,  3.67it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:15<00:00,  3.65it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:16<00:00,  3.65it/s]\u001b[A\n",
      "Epoch:  40%|████      | 4/10 [05:03<07:36, 76.01s/it]16it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:09,  3.75it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:09,  3.70it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:10,  3.66it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:09,  3.66it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:09,  3.65it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:09,  3.65it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:09,  3.62it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:09,  3.62it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:09,  3.64it/s]\u001b[AI1018 13:35:47.053579 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1050/config.json\n",
      "I1018 13:35:47.721282 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1050/pytorch_model.bin\n",
      "I1018 13:35:47.724355 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1050\n",
      "\n",
      "Iteration:   4%|▍         | 10/260 [00:03<02:06,  1.98it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:47,  2.31it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:04<01:35,  2.60it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:26,  2.85it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:21,  3.03it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:17,  3.17it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:14,  3.30it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:12,  3.37it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:09,  3.46it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:08,  3.52it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:07,  3.56it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:06,  3.60it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:05,  3.62it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:07<01:05,  3.61it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:04,  3.63it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:04,  3.62it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:04,  3.61it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:04,  3.62it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:04,  3.60it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:03,  3.62it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:09<01:03,  3.61it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:03,  3.63it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:03,  3.62it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:02,  3.62it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:10<01:02,  3.63it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:02,  3.61it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:02,  3.59it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:02,  3.60it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:01,  3.62it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:11<01:00,  3.64it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:00,  3.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  16%|█▌        | 41/260 [00:12<01:00,  3.63it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<00:59,  3.64it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<01:00,  3.61it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<00:59,  3.62it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:13<00:59,  3.60it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<00:58,  3.63it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:58,  3.63it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:57,  3.64it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:57,  3.63it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:57,  3.61it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:15<00:57,  3.62it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:57,  3.62it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:56,  3.63it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:56,  3.61it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<00:56,  3.63it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:56,  3.62it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:55,  3.63it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:17<00:55,  3.65it/s]\u001b[AI1018 13:36:01.500783 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1100/config.json\n",
      "I1018 13:36:03.290987 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1100/pytorch_model.bin\n",
      "I1018 13:36:03.294382 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1100\n",
      "\n",
      "Iteration:  23%|██▎       | 60/260 [00:19<02:42,  1.23it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:19<02:09,  1.54it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:19<01:46,  1.87it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:19<01:30,  2.18it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:20<01:19,  2.47it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:20<01:11,  2.72it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:20<01:05,  2.95it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:21<01:01,  3.13it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:21<00:58,  3.28it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:21<00:56,  3.39it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:21<00:54,  3.47it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:22<00:53,  3.53it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:22<00:52,  3.57it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:22<00:51,  3.60it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:22<00:51,  3.62it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:23<00:50,  3.64it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:23<00:50,  3.65it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:23<00:50,  3.65it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:24<00:49,  3.66it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:24<00:49,  3.64it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:24<00:49,  3.65it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:24<00:48,  3.66it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:25<00:48,  3.66it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:25<00:48,  3.67it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:25<00:48,  3.65it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:25<00:47,  3.65it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:26<00:48,  3.62it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:26<00:48,  3.60it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:26<00:47,  3.62it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:27<00:47,  3.64it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:27<00:46,  3.65it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:27<00:46,  3.66it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:27<00:45,  3.66it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:28<00:45,  3.65it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:28<00:45,  3.65it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:28<00:45,  3.66it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:28<00:45,  3.64it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:29<00:45,  3.61it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:29<00:45,  3.59it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:29<00:44,  3.60it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:30<00:44,  3.62it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:30<00:43,  3.64it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:30<00:43,  3.65it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:30<00:43,  3.63it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:31<00:42,  3.64it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:31<00:42,  3.62it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:31<00:42,  3.60it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:31<00:42,  3.60it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:32<00:41,  3.63it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:32<00:41,  3.64it/s]\u001b[AI1018 13:36:17.040568 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1150/config.json\n",
      "I1018 13:36:18.993387 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1150/pytorch_model.bin\n",
      "I1018 13:36:19.348749 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1150\n",
      "\n",
      "Iteration:  42%|████▏     | 110/260 [00:35<02:26,  1.03it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:35<01:53,  1.31it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:35<01:31,  1.62it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:35<01:15,  1.95it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:36<01:04,  2.25it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:36<00:57,  2.54it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:36<00:51,  2.80it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:37<00:47,  3.00it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:37<00:45,  3.15it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:37<00:42,  3.29it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:37<00:41,  3.38it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:38<00:40,  3.46it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:38<00:39,  3.52it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:38<00:38,  3.54it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:39<00:38,  3.55it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:39<00:37,  3.58it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:39<00:37,  3.60it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:39<00:36,  3.61it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:40<00:36,  3.62it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:40<00:36,  3.63it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:40<00:35,  3.64it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:40<00:35,  3.61it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:41<00:35,  3.61it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:41<00:35,  3.63it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:41<00:34,  3.64it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:42<00:34,  3.65it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:42<00:33,  3.66it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:42<00:33,  3.66it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:42<00:33,  3.67it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:43<00:33,  3.64it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:43<00:32,  3.64it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:43<00:32,  3.64it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:43<00:32,  3.64it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:44<00:32,  3.64it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:44<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:44<00:31,  3.65it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:45<00:31,  3.62it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:45<00:31,  3.60it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:45<00:30,  3.63it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:45<00:30,  3.62it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:46<00:30,  3.63it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:46<00:30,  3.62it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:46<00:29,  3.63it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:46<00:29,  3.63it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:47<00:29,  3.64it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:47<00:29,  3.61it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:47<00:28,  3.62it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:48<00:28,  3.61it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:48<00:28,  3.60it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:48<00:27,  3.63it/s]\u001b[AI1018 13:36:33.115269 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1200/config.json\n",
      "I1018 13:36:33.797490 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1200/pytorch_model.bin\n",
      "I1018 13:36:33.800570 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1200\n",
      "\n",
      "Iteration:  62%|██████▏   | 160/260 [00:49<00:48,  2.08it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:49<00:41,  2.40it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:50<00:36,  2.68it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:50<00:33,  2.90it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:50<00:31,  3.07it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:50<00:29,  3.20it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:51<00:28,  3.33it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:51<00:27,  3.43it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:51<00:26,  3.50it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:52<00:25,  3.53it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:52<00:25,  3.54it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:52<00:24,  3.57it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:52<00:24,  3.59it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:53<00:24,  3.61it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:53<00:23,  3.62it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:53<00:23,  3.60it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:54<00:23,  3.61it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:54<00:22,  3.62it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:54<00:22,  3.63it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:54<00:22,  3.61it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:55<00:22,  3.60it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:55<00:21,  3.60it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:55<00:21,  3.61it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:55<00:21,  3.62it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:56<00:20,  3.63it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:56<00:20,  3.61it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:56<00:20,  3.60it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:57<00:20,  3.62it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:57<00:19,  3.64it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:57<00:19,  3.65it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:57<00:19,  3.65it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:58<00:18,  3.66it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:58<00:18,  3.67it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:58<00:18,  3.67it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:58<00:18,  3.64it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:59<00:17,  3.63it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:59<00:17,  3.61it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:59<00:17,  3.62it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:00<00:17,  3.60it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:00<00:16,  3.62it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:00<00:16,  3.64it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:00<00:16,  3.65it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:01<00:15,  3.63it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:01<00:15,  3.62it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:01<00:15,  3.62it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:01<00:15,  3.63it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:02<00:14,  3.63it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:02<00:14,  3.64it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:02<00:14,  3.64it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:03<00:14,  3.64it/s]\u001b[AI1018 13:36:47.777287 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1250/config.json\n",
      "I1018 13:36:48.683655 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1250/pytorch_model.bin\n",
      "I1018 13:36:48.689075 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1250\n",
      "\n",
      "Iteration:  81%|████████  | 210/260 [01:04<00:30,  1.64it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:04<00:24,  1.97it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:05<00:21,  2.28it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:05<00:18,  2.56it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:05<00:16,  2.80it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:05<00:15,  3.00it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:06<00:13,  3.17it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:06<00:13,  3.30it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:06<00:12,  3.37it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:06<00:11,  3.45it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:07<00:11,  3.48it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:07<00:11,  3.54it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:07<00:10,  3.58it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:08<00:10,  3.61it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:08<00:10,  3.60it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:08<00:09,  3.60it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:08<00:09,  3.59it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:09<00:09,  3.59it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:09<00:08,  3.59it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:09<00:08,  3.59it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:10<00:08,  3.60it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:10<00:08,  3.60it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:10<00:07,  3.62it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:10<00:07,  3.62it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:11<00:07,  3.61it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:11<00:06,  3.60it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:11<00:06,  3.60it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:11<00:06,  3.59it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:12<00:06,  3.61it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:12<00:05,  3.60it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:12<00:05,  3.61it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:13<00:05,  3.62it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:13<00:04,  3.63it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:13<00:04,  3.63it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:13<00:04,  3.61it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:14<00:04,  3.63it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:14<00:03,  3.64it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:14<00:03,  3.63it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:14<00:03,  3.64it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:15<00:03,  3.63it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:15<00:02,  3.63it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:15<00:02,  3.63it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:16<00:02,  3.64it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:16<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:16<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:16<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:17<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:17<00:00,  3.64it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:17<00:00,  3.64it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:18<00:00,  3.64it/s]\u001b[AI1018 13:37:02.377210 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1300/config.json\n",
      "I1018 13:37:03.254425 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1300/pytorch_model.bin\n",
      "I1018 13:37:03.257763 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1300\n",
      "\n",
      "Epoch:  50%|█████     | 5/10 [06:23<06:24, 76.93s/it]98it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:08,  3.80it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:08,  3.76it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:08,  3.74it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:08,  3.72it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   2%|▏         | 5/260 [00:01<01:09,  3.68it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:09,  3.68it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:09,  3.65it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:08,  3.66it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:08,  3.65it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:08,  3.65it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:08,  3.64it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:08,  3.62it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:08,  3.60it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:07,  3.62it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:07,  3.61it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:07,  3.63it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:07,  3.62it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:06,  3.62it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:06,  3.64it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:05<01:06,  3.61it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:05<01:05,  3.62it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:05,  3.63it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:05,  3.63it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:06<01:04,  3.64it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:06<01:04,  3.64it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:04,  3.62it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:04,  3.64it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:07<01:03,  3.65it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:07<01:03,  3.66it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:02,  3.66it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:08<01:02,  3.67it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:08<01:02,  3.65it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:02,  3.66it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:01,  3.66it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:09<01:01,  3.67it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:09<01:01,  3.64it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:01,  3.62it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:10<01:01,  3.62it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:10<01:00,  3.63it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:10<01:00,  3.63it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<01:00,  3.64it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:11<00:59,  3.64it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:11<00:59,  3.64it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<00:59,  3.62it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:12<00:59,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:12<00:59,  3.62it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:12<00:58,  3.63it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:13<00:57,  3.66it/s]\u001b[AI1018 13:37:16.999501 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1350/config.json\n",
      "I1018 13:37:17.697288 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1350/pytorch_model.bin\n",
      "I1018 13:37:17.700470 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1350\n",
      "\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<01:41,  2.06it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<01:27,  2.39it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:14<01:18,  2.67it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<01:11,  2.91it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<01:06,  3.10it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<01:03,  3.25it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<01:00,  3.37it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:58,  3.45it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:57,  3.52it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:16<00:56,  3.56it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:56,  3.57it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:55,  3.59it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:54,  3.60it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:17<00:54,  3.62it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:54,  3.60it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:53,  3.61it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:18<00:53,  3.62it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:53,  3.63it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:52,  3.63it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:52,  3.64it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:19<00:52,  3.64it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:51,  3.64it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:20<00:51,  3.64it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:20<00:51,  3.64it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<00:51,  3.62it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:50,  3.63it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:21<00:50,  3.62it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:21<00:50,  3.63it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:49,  3.65it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:49,  3.65it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:22<00:49,  3.66it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:22<00:48,  3.67it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:48,  3.67it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:23<00:48,  3.67it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:23<00:47,  3.67it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:47,  3.67it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:47,  3.67it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:24<00:47,  3.68it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:24<00:46,  3.68it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:46,  3.68it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:25<00:46,  3.65it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:25<00:46,  3.65it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:25<00:46,  3.65it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:45,  3.65it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:26<00:45,  3.65it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:26<00:45,  3.62it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:27<00:45,  3.63it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:27<00:45,  3.61it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:27<00:44,  3.63it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:27<00:44,  3.64it/s]\u001b[AI1018 13:37:31.406409 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1400/config.json\n",
      "I1018 13:37:32.127989 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1400/pytorch_model.bin\n",
      "I1018 13:37:32.217090 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1400\n",
      "\n",
      "Iteration:  38%|███▊      | 100/260 [00:28<01:23,  1.92it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:29<01:10,  2.25it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<01:02,  2.55it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:55,  2.80it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:30<00:51,  3.00it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:48,  3.17it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:46,  3.30it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:30<00:45,  3.38it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:31<00:43,  3.46it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:43,  3.51it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:31<00:42,  3.52it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:31<00:41,  3.56it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:41,  3.60it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:40,  3.60it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:32<00:40,  3.62it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:33<00:39,  3.64it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:39,  3.65it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:39,  3.66it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:33<00:39,  3.64it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:34<00:38,  3.64it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:38,  3.62it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:34<00:38,  3.63it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:34<00:38,  3.63it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:37,  3.63it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:35<00:37,  3.63it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:35<00:37,  3.61it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:36,  3.63it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:36,  3.64it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:36<00:36,  3.65it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:36<00:35,  3.66it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:37<00:35,  3.67it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:35,  3.66it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:37<00:34,  3.67it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:34,  3.67it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:34,  3.67it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:38<00:33,  3.68it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:38<00:33,  3.68it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:33,  3.67it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:33,  3.67it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:39<00:32,  3.67it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:39<00:32,  3.67it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:40<00:32,  3.67it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:40<00:32,  3.67it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:40<00:31,  3.67it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:40<00:31,  3.67it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:41<00:31,  3.67it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:41<00:31,  3.67it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:41<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:42<00:30,  3.66it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:42<00:30,  3.66it/s]\u001b[AI1018 13:37:45.903952 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1450/config.json\n",
      "I1018 13:37:47.380675 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1450/pytorch_model.bin\n",
      "I1018 13:37:47.570779 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1450\n",
      "\n",
      "Iteration:  58%|█████▊    | 150/260 [00:44<01:25,  1.29it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:44<01:07,  1.61it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:44<00:56,  1.93it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:45<00:47,  2.23it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:45<00:41,  2.53it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:45<00:37,  2.77it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:45<00:34,  2.99it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:46<00:32,  3.17it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:46<00:30,  3.30it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:46<00:29,  3.41it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:47<00:28,  3.46it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:47<00:28,  3.52it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:47<00:27,  3.56it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:47<00:26,  3.60it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:48<00:26,  3.59it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:48<00:26,  3.61it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:48<00:25,  3.62it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:48<00:25,  3.62it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:49<00:25,  3.63it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:49<00:25,  3.63it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:49<00:24,  3.61it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:50<00:24,  3.62it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:50<00:24,  3.63it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:50<00:24,  3.61it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:50<00:23,  3.63it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:51<00:23,  3.64it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:51<00:23,  3.65it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:51<00:22,  3.63it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:52<00:22,  3.64it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:52<00:22,  3.63it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:52<00:22,  3.61it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:21,  3.62it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:53<00:21,  3.62it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:53<00:21,  3.63it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:20,  3.63it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:53<00:20,  3.63it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:54<00:20,  3.63it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:54<00:20,  3.63it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:19,  3.64it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:55<00:19,  3.62it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:55<00:19,  3.61it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:55<00:18,  3.63it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:55<00:18,  3.64it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:56<00:18,  3.62it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:56<00:18,  3.61it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:18,  3.59it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:56<00:17,  3.62it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:57<00:17,  3.60it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:57<00:17,  3.62it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:16,  3.62it/s]\u001b[AI1018 13:38:01.350618 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1500/config.json\n",
      "I1018 13:38:02.013699 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1500/pytorch_model.bin\n",
      "I1018 13:38:02.016945 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1500\n",
      "\n",
      "Iteration:  77%|███████▋  | 200/260 [00:58<00:28,  2.09it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:59<00:24,  2.40it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:59<00:21,  2.68it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:59<00:19,  2.91it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:59<00:18,  3.09it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:00<00:17,  3.22it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:00<00:16,  3.34it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:00<00:15,  3.42it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:00<00:14,  3.49it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:01<00:14,  3.54it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:01<00:13,  3.58it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:01<00:13,  3.59it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:02<00:13,  3.60it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:02<00:13,  3.61it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:02<00:12,  3.60it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:02<00:12,  3.59it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:03<00:12,  3.61it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:03<00:11,  3.63it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:03<00:11,  3.64it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:03<00:11,  3.65it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:04<00:10,  3.66it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:04<00:10,  3.66it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:04<00:10,  3.66it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:05<00:10,  3.67it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:05<00:09,  3.67it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:05<00:09,  3.65it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:05<00:09,  3.66it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:06<00:09,  3.66it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:06<00:08,  3.66it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:06<00:08,  3.66it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:06<00:08,  3.67it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:07<00:07,  3.67it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:07<00:07,  3.67it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:07<00:07,  3.67it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:08<00:07,  3.67it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:08<00:06,  3.67it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  91%|█████████ | 236/260 [01:08<00:06,  3.67it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:08<00:06,  3.65it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:09<00:06,  3.65it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:09<00:05,  3.62it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:09<00:05,  3.63it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:10<00:05,  3.60it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:10<00:04,  3.62it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:10<00:04,  3.62it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:10<00:04,  3.63it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:11<00:04,  3.65it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:11<00:03,  3.66it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:11<00:03,  3.64it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:11<00:03,  3.64it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:12<00:03,  3.64it/s]\u001b[AI1018 13:38:15.738078 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1550/config.json\n",
      "I1018 13:38:16.420038 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1550/pytorch_model.bin\n",
      "I1018 13:38:16.423201 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1550\n",
      "\n",
      "Iteration:  96%|█████████▌| 250/260 [01:13<00:04,  2.08it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:13<00:03,  2.40it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:13<00:02,  2.67it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:13<00:02,  2.89it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:14<00:01,  3.06it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:14<00:01,  3.22it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:14<00:01,  3.34it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:15<00:00,  3.42it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:15<00:00,  3.49it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:15<00:00,  3.54it/s]\u001b[A\n",
      "Epoch:  60%|██████    | 6/10 [07:38<05:06, 76.59s/it]06it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:09,  3.75it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:09,  3.73it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:09,  3.71it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:09,  3.70it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:09,  3.69it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:09,  3.68it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:09,  3.65it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:08,  3.66it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:08,  3.66it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:08,  3.67it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:02<01:07,  3.67it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:07,  3.67it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:07,  3.67it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:07,  3.67it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:06,  3.67it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:06,  3.67it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:06,  3.67it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:05,  3.67it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:05,  3.67it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:05<01:05,  3.67it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:05<01:05,  3.67it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:05<01:04,  3.67it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:04,  3.67it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:06<01:04,  3.67it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:06<01:04,  3.67it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:03,  3.67it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:03,  3.67it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:07<01:03,  3.67it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:07<01:02,  3.67it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:02,  3.67it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:08<01:02,  3.65it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:08<01:02,  3.62it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:02,  3.61it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:02,  3.62it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:09<01:01,  3.64it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:09<01:01,  3.65it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:00,  3.66it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:10<01:00,  3.66it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:10<01:00,  3.66it/s]\u001b[AI1018 13:38:31.975862 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1600/config.json\n",
      "I1018 13:38:38.511368 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1600/pytorch_model.bin\n",
      "I1018 13:38:38.514431 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1600\n",
      "\n",
      "Iteration:  15%|█▌        | 40/260 [00:19<10:23,  2.83s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:19<07:31,  2.06s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:19<05:32,  1.53s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:20<04:09,  1.15s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:20<03:11,  1.13it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:20<02:31,  1.42it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:21<02:02,  1.74it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:21<01:43,  2.07it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:21<01:29,  2.37it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:21<01:19,  2.64it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:22<01:12,  2.88it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:22<01:08,  3.07it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:22<01:04,  3.22it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:23<01:02,  3.34it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:23<01:00,  3.40it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:23<00:59,  3.47it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:23<00:57,  3.52it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:24<00:57,  3.55it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:24<00:56,  3.56it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:24<00:55,  3.59it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:24<00:55,  3.61it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:25<00:55,  3.61it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:25<00:54,  3.63it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:25<00:54,  3.64it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:26<00:53,  3.65it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:26<00:53,  3.66it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:26<00:52,  3.66it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:26<00:52,  3.67it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:27<00:52,  3.67it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:27<00:52,  3.67it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:27<00:51,  3.67it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:27<00:51,  3.68it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:28<00:51,  3.68it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:28<00:50,  3.68it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:28<00:50,  3.68it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:29<00:50,  3.67it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:29<00:50,  3.68it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:29<00:49,  3.67it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:29<00:49,  3.67it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:30<00:49,  3.67it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:30<00:49,  3.67it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:30<00:48,  3.67it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:30<00:48,  3.67it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:31<00:48,  3.67it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:31<00:47,  3.67it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:31<00:47,  3.67it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:32<00:47,  3.67it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:32<00:47,  3.67it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:32<00:46,  3.67it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:32<00:46,  3.67it/s]\u001b[AI1018 13:38:52.180356 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1650/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1018 13:38:52.839066 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1650/pytorch_model.bin\n",
      "I1018 13:38:52.842558 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1650\n",
      "\n",
      "Iteration:  35%|███▍      | 90/260 [00:33<01:20,  2.12it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:34<01:09,  2.44it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:34<01:01,  2.71it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:34<00:56,  2.94it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:34<00:53,  3.13it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:35<00:50,  3.27it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:35<00:48,  3.38it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:35<00:47,  3.46it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:35<00:46,  3.50it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:36<00:45,  3.54it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:36<00:44,  3.57it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:36<00:44,  3.59it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:37<00:43,  3.61it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:37<00:43,  3.62it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:37<00:43,  3.62it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:37<00:42,  3.63it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:38<00:42,  3.63it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:38<00:42,  3.64it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:38<00:41,  3.63it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:38<00:41,  3.64it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:39<00:41,  3.61it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:39<00:41,  3.62it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:39<00:40,  3.63it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:40<00:40,  3.63it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:40<00:40,  3.61it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:40<00:39,  3.63it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:40<00:39,  3.65it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:41<00:39,  3.63it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:41<00:38,  3.64it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:41<00:38,  3.65it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:42<00:38,  3.66it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:42<00:37,  3.66it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:42<00:37,  3.67it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:42<00:37,  3.67it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:43<00:37,  3.67it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:43<00:36,  3.67it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:43<00:36,  3.67it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:43<00:36,  3.65it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:44<00:36,  3.65it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:44<00:35,  3.65it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:44<00:35,  3.64it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:45<00:35,  3.64it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:45<00:35,  3.64it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:45<00:34,  3.64it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:45<00:34,  3.62it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:46<00:34,  3.63it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:46<00:34,  3.61it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:46<00:33,  3.63it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:46<00:33,  3.64it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:47<00:33,  3.65it/s]\u001b[AI1018 13:39:06.556415 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1700/config.json\n",
      "I1018 13:39:07.234431 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1700/pytorch_model.bin\n",
      "I1018 13:39:07.237698 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1700\n",
      "\n",
      "Iteration:  54%|█████▍    | 140/260 [00:48<00:57,  2.09it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:48<00:49,  2.41it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:48<00:43,  2.69it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:48<00:40,  2.92it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:49<00:37,  3.11it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:49<00:35,  3.26it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:49<00:33,  3.37it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:50<00:32,  3.46it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:50<00:31,  3.52it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:50<00:31,  3.54it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:50<00:30,  3.56it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:51<00:30,  3.58it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:51<00:30,  3.60it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:51<00:29,  3.59it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:52<00:29,  3.61it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:52<00:29,  3.62it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:52<00:28,  3.62it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:52<00:28,  3.63it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:53<00:28,  3.63it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:53<00:27,  3.64it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:53<00:27,  3.61it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:53<00:27,  3.63it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:54<00:26,  3.64it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:54<00:26,  3.63it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:54<00:26,  3.64it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:55<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:55<00:25,  3.66it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:55<00:25,  3.66it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:55<00:25,  3.67it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:56<00:24,  3.65it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:56<00:24,  3.64it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:56<00:24,  3.64it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:56<00:24,  3.64it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:57<00:24,  3.62it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:57<00:23,  3.62it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:57<00:23,  3.63it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:58<00:23,  3.61it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:58<00:23,  3.60it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:58<00:22,  3.62it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:58<00:22,  3.61it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:59<00:22,  3.62it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:59<00:21,  3.63it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:59<00:21,  3.63it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:59<00:21,  3.64it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [01:00<00:20,  3.64it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [01:00<00:20,  3.64it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [01:00<00:20,  3.64it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [01:01<00:20,  3.64it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [01:01<00:19,  3.64it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [01:01<00:19,  3.62it/s]\u001b[AI1018 13:39:20.981810 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1750/config.json\n",
      "I1018 13:39:21.643485 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1750/pytorch_model.bin\n",
      "I1018 13:39:21.646486 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1750\n",
      "\n",
      "Iteration:  73%|███████▎  | 190/260 [01:02<00:33,  2.10it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [01:02<00:28,  2.42it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [01:03<00:25,  2.69it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [01:03<00:22,  2.92it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [01:03<00:21,  3.09it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [01:03<00:20,  3.24it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [01:04<00:19,  3.36it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [01:04<00:18,  3.43it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [01:04<00:17,  3.47it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [01:05<00:17,  3.50it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [01:05<00:16,  3.54it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [01:05<00:16,  3.57it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [01:05<00:16,  3.59it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [01:06<00:15,  3.58it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [01:06<00:15,  3.61it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [01:06<00:15,  3.62it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [01:06<00:14,  3.64it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [01:07<00:14,  3.63it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [01:07<00:14,  3.64it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [01:07<00:13,  3.65it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:08<00:13,  3.66it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:08<00:13,  3.66it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:08<00:13,  3.66it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:08<00:12,  3.66it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:09<00:12,  3.64it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:09<00:12,  3.64it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:09<00:12,  3.64it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:10<00:11,  3.62it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:10<00:11,  3.62it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:10<00:11,  3.63it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:10<00:11,  3.63it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:11<00:10,  3.61it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:11<00:10,  3.61it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:11<00:10,  3.63it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:11<00:09,  3.64it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:12<00:09,  3.63it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:12<00:09,  3.63it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:12<00:09,  3.64it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:13<00:08,  3.64it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:13<00:08,  3.64it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:13<00:08,  3.64it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:13<00:07,  3.64it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:14<00:07,  3.64it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:14<00:07,  3.61it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:14<00:07,  3.62it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:14<00:06,  3.62it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:15<00:06,  3.63it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:15<00:06,  3.63it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:15<00:06,  3.64it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:16<00:05,  3.63it/s]\u001b[AI1018 13:39:35.409217 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1800/config.json\n",
      "I1018 13:39:36.065387 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1800/pytorch_model.bin\n",
      "I1018 13:39:36.069604 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1800\n",
      "\n",
      "Iteration:  92%|█████████▏| 240/260 [01:17<00:09,  2.10it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:17<00:07,  2.42it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:17<00:06,  2.69it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:17<00:05,  2.92it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:18<00:05,  3.11it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:18<00:04,  3.23it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:18<00:04,  3.35it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:18<00:03,  3.44it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:19<00:03,  3.51it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:19<00:03,  3.53it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:19<00:02,  3.57it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:20<00:02,  3.60it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:20<00:02,  3.62it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:20<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:20<00:01,  3.65it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:21<00:01,  3.65it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:21<00:01,  3.66it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:21<00:00,  3.66it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:21<00:00,  3.67it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:22<00:00,  3.67it/s]\u001b[A\n",
      "Epoch:  70%|███████   | 7/10 [09:01<03:54, 78.32s/it]20it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:09,  3.71it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:09,  3.69it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:09,  3.67it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:09,  3.66it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:09,  3.66it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:09,  3.65it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:09,  3.65it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:09,  3.65it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:08,  3.65it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:08,  3.65it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:08,  3.65it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:08,  3.64it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:07,  3.64it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:07,  3.64it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:07,  3.64it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:07,  3.64it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:07,  3.61it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:06,  3.63it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:06,  3.64it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:05<01:05,  3.65it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:05<01:05,  3.66it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:05,  3.66it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:04,  3.66it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:06<01:04,  3.67it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:06<01:04,  3.67it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:03,  3.67it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:03,  3.67it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:07<01:03,  3.67it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:07<01:02,  3.67it/s]\u001b[AI1018 13:39:49.648003 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1850/config.json\n",
      "I1018 13:39:50.306177 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1850/pytorch_model.bin\n",
      "I1018 13:39:50.310289 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1850\n",
      "\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:49,  2.11it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:34,  2.43it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:24,  2.71it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:17,  2.93it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:12,  3.12it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:08,  3.27it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:06,  3.38it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:04,  3.46it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:02,  3.52it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:11<01:01,  3.57it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:01,  3.60it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<01:00,  3.62it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<00:59,  3.64it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<00:59,  3.65it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<00:59,  3.66it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:12<00:58,  3.66it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:58,  3.65it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:57,  3.66it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:57,  3.66it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:57,  3.66it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:57,  3.65it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:14<00:57,  3.65it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:56,  3.65it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:56,  3.65it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:56,  3.64it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  22%|██▏       | 56/260 [00:15<00:55,  3.64it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:55,  3.64it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:55,  3.64it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:16<00:55,  3.64it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:54,  3.64it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:54,  3.64it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:54,  3.62it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:17<00:54,  3.62it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:54,  3.60it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:53,  3.62it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:18<00:53,  3.63it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:52,  3.65it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:52,  3.63it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:52,  3.65it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:19<00:51,  3.66it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:51,  3.66it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:20<00:51,  3.64it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:20<00:51,  3.64it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:20<00:51,  3.64it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:50,  3.64it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:21<00:50,  3.64it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:21<00:50,  3.64it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:49,  3.64it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:50,  3.62it/s]\u001b[AI1018 13:40:04.011443 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1900/config.json\n",
      "I1018 13:40:04.677295 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1900/pytorch_model.bin\n",
      "I1018 13:40:04.680196 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1900\n",
      "\n",
      "Iteration:  31%|███       | 80/260 [00:23<01:26,  2.09it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<01:14,  2.40it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<01:06,  2.68it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:24<01:00,  2.92it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:56,  3.11it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:53,  3.26it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:51,  3.37it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:25<00:50,  3.46it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:48,  3.52it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:48,  3.54it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:25<00:47,  3.58it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<00:46,  3.61it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<00:46,  3.63it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:45,  3.64it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:45,  3.65it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:45,  3.63it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:27<00:45,  3.64it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:27<00:45,  3.61it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:44,  3.60it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:44,  3.62it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:28<00:43,  3.64it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:29<00:43,  3.65it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:43,  3.65it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:42,  3.66it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:29<00:42,  3.66it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:42,  3.67it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:41,  3.67it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:30<00:41,  3.67it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:30<00:41,  3.67it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:41,  3.68it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:31<00:40,  3.67it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:31<00:40,  3.67it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:31<00:40,  3.68it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:40,  3.65it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:32<00:39,  3.66it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:32<00:39,  3.66it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:39,  3.67it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:38,  3.67it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:33<00:38,  3.67it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:33<00:38,  3.67it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:38,  3.65it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:34<00:38,  3.64it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:34<00:37,  3.64it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:37,  3.64it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:35<00:37,  3.64it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:35<00:37,  3.64it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:35<00:36,  3.64it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:36,  3.62it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:36<00:36,  3.63it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:36<00:36,  3.63it/s]\u001b[AI1018 13:40:18.370541 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-1950/config.json\n",
      "I1018 13:40:19.053827 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-1950/pytorch_model.bin\n",
      "I1018 13:40:19.058024 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-1950\n",
      "\n",
      "Iteration:  50%|█████     | 130/260 [00:37<01:02,  2.07it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:53,  2.39it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:48,  2.67it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:43,  2.90it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:40,  3.09it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:38<00:38,  3.23it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:37,  3.35it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:35,  3.43it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:34,  3.49it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:40<00:34,  3.54it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:33,  3.57it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:40<00:33,  3.59it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:40<00:32,  3.58it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:32,  3.61it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:41<00:31,  3.63it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:41<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:42<00:31,  3.63it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:42<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:42<00:30,  3.63it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:30,  3.64it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:43<00:29,  3.64it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:43<00:29,  3.64it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:43<00:29,  3.64it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:29,  3.64it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:44<00:28,  3.64it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:44<00:28,  3.64it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:45<00:28,  3.64it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:45<00:27,  3.64it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:45<00:27,  3.64it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:45<00:27,  3.64it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:27,  3.64it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:46<00:26,  3.64it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:46<00:26,  3.64it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:46<00:26,  3.64it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:47<00:26,  3.64it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:47<00:25,  3.64it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:47<00:25,  3.64it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:48<00:25,  3.64it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:48<00:24,  3.64it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:48<00:24,  3.64it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:48<00:24,  3.64it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:49<00:24,  3.64it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:49<00:23,  3.64it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:49<00:23,  3.62it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:49<00:23,  3.63it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:50<00:23,  3.61it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:50<00:22,  3.63it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:50<00:22,  3.64it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:51<00:22,  3.65it/s]\u001b[AI1018 13:40:32.788425 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-2000/config.json\n",
      "I1018 13:40:33.459379 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-2000/pytorch_model.bin\n",
      "I1018 13:40:33.462872 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-2000\n",
      "\n",
      "Iteration:  69%|██████▉   | 180/260 [00:52<00:38,  2.09it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:32,  2.42it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:52<00:28,  2.70it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:52<00:26,  2.93it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:24,  3.12it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:53<00:22,  3.27it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:53<00:21,  3.38it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:53<00:21,  3.46it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:20,  3.52it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:54<00:19,  3.56it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:54<00:19,  3.60it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:55<00:19,  3.62it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:55<00:18,  3.63it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:55<00:18,  3.65it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:55<00:18,  3.63it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:17,  3.65it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:56<00:17,  3.65it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:56<00:17,  3.66it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:56<00:17,  3.64it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:16,  3.65it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:57<00:16,  3.65it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:57<00:16,  3.62it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:58<00:16,  3.62it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:58<00:15,  3.61it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:58<00:15,  3.62it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:58<00:15,  3.64it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:59<00:14,  3.65it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [00:59<00:14,  3.66it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:59<00:14,  3.66it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [00:59<00:13,  3.67it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:00<00:13,  3.67it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:00<00:13,  3.67it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:00<00:13,  3.67it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:01<00:12,  3.67it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:01<00:12,  3.67it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:01<00:12,  3.67it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:01<00:11,  3.68it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:02<00:11,  3.68it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:02<00:11,  3.65it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:02<00:11,  3.66it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [01:02<00:10,  3.66it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:03<00:10,  3.64it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:03<00:10,  3.64it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:03<00:10,  3.64it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:04<00:09,  3.64it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:04<00:09,  3.64it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:04<00:09,  3.64it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:04<00:09,  3.63it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:05<00:08,  3.64it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:05<00:08,  3.64it/s]\u001b[AI1018 13:40:47.142343 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-2050/config.json\n",
      "I1018 13:40:47.815175 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-2050/pytorch_model.bin\n",
      "I1018 13:40:47.818238 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-2050\n",
      "\n",
      "Iteration:  88%|████████▊ | 230/260 [01:06<00:14,  2.09it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:06<00:12,  2.41it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:06<00:10,  2.68it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:07<00:09,  2.91it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:07<00:08,  3.10it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:07<00:07,  3.25it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:08<00:07,  3.36it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:08<00:06,  3.44it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:08<00:06,  3.49it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:08<00:05,  3.54it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:09<00:05,  3.57it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:09<00:05,  3.59it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:09<00:04,  3.61it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:09<00:04,  3.62it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:10<00:04,  3.63it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:10<00:04,  3.63it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:10<00:03,  3.63it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:11<00:03,  3.63it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:11<00:03,  3.63it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:11<00:03,  3.64it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:11<00:02,  3.64it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 251/260 [01:12<00:02,  3.64it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:12<00:02,  3.64it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:12<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:12<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:13<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:13<00:01,  3.64it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:13<00:00,  3.64it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:14<00:00,  3.62it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:14<00:00,  3.62it/s]\u001b[A\n",
      "Epoch:  80%|████████  | 8/10 [10:15<02:34, 77.18s/it]16it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:09,  3.75it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:09,  3.73it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:09,  3.71it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:09,  3.70it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:09,  3.69it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:08,  3.68it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:08,  3.68it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:08,  3.68it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:08,  3.68it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:08,  3.68it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:02<01:07,  3.67it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:07,  3.67it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:03<01:07,  3.67it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:03<01:06,  3.68it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:07,  3.65it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:04<01:06,  3.65it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:04<01:06,  3.65it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:04<01:06,  3.65it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:06,  3.65it/s]\u001b[AI1018 13:41:01.401292 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-2100/config.json\n",
      "I1018 13:41:02.072125 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-2100/pytorch_model.bin\n",
      "I1018 13:41:02.075739 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:54,  2.09it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:39,  2.41it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:28,  2.68it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:21,  2.91it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:16,  3.10it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:12,  3.25it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:09,  3.36it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:08<01:08,  3.41it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:06,  3.48it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:05,  3.50it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:04,  3.55it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:03,  3.59it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:03,  3.61it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:02,  3.63it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:02,  3.64it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:01,  3.65it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:01,  3.66it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:00,  3.67it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:11<01:00,  3.67it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:11<01:00,  3.67it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<01:00,  3.65it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<00:59,  3.66it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<00:59,  3.66it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<00:59,  3.64it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<00:59,  3.64it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:12<00:59,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:58,  3.62it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:57,  3.63it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:57,  3.63it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:14<00:57,  3.61it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:57,  3.63it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:56,  3.64it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:56,  3.65it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:16<00:55,  3.66it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:55,  3.67it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:55,  3.67it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:16<00:54,  3.67it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<00:54,  3.67it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<00:54,  3.67it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:17<00:53,  3.68it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:17<00:53,  3.68it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<00:53,  3.65it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:18<00:53,  3.66it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:18<00:52,  3.67it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:52,  3.66it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:52,  3.67it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:19<00:52,  3.67it/s]\u001b[AI1018 13:41:15.762850 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-2150/config.json\n",
      "I1018 13:41:16.430375 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-2150/pytorch_model.bin\n",
      "I1018 13:41:16.433336 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-2150\n",
      "\n",
      "Iteration:  27%|██▋       | 70/260 [00:20<01:30,  2.11it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<01:17,  2.43it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:21<01:09,  2.69it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:21<01:04,  2.92it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<00:59,  3.10it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:56,  3.25it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:22<00:54,  3.36it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:53,  3.44it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:52,  3.50it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:51,  3.54it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:23<00:50,  3.57it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<00:49,  3.59it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:49,  3.59it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:24<00:49,  3.60it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:48,  3.59it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:48,  3.62it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:47,  3.63it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:25<00:47,  3.64it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:47,  3.65it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:46,  3.66it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:25<00:46,  3.66it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<00:46,  3.67it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<00:45,  3.67it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:45,  3.67it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:27<00:45,  3.67it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:44,  3.67it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:27<00:44,  3.68it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:27<00:44,  3.68it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:44,  3.68it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:43,  3.67it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:28<00:43,  3.67it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:28<00:43,  3.68it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:42,  3.68it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:42,  3.68it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:29<00:42,  3.68it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:30<00:42,  3.68it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:41,  3.68it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:30<00:41,  3.68it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:30<00:41,  3.68it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:41,  3.68it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:31<00:40,  3.68it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:31<00:40,  3.68it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:31<00:40,  3.68it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:39,  3.68it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:32<00:39,  3.68it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:32<00:39,  3.68it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:39,  3.68it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:38,  3.68it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:33<00:38,  3.68it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:33<00:38,  3.68it/s]\u001b[AI1018 13:41:30.081070 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-2200/config.json\n",
      "I1018 13:41:30.729682 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-2200/pytorch_model.bin\n",
      "I1018 13:41:30.732553 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-2200\n",
      "\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<01:05,  2.13it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:35<00:56,  2.45it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:35<00:50,  2.73it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:46,  2.96it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:35<00:43,  3.14it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:41,  3.27it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:39,  3.38it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:38,  3.44it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:36<00:37,  3.50it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:37<00:36,  3.54it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:37<00:36,  3.57it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:35,  3.60it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:35,  3.61it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:35,  3.62it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:34,  3.63it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:38<00:34,  3.63it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:34,  3.64it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:33,  3.64it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:33,  3.64it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:39<00:33,  3.64it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:32,  3.64it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:40<00:32,  3.64it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:40<00:32,  3.64it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:32,  3.64it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:41<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:41<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:41<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:42<00:31,  3.64it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:42<00:30,  3.64it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:42<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:43<00:30,  3.65it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 151/260 [00:43<00:29,  3.64it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:43<00:29,  3.62it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:43<00:29,  3.62it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:44<00:29,  3.63it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:44<00:28,  3.64it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:44<00:28,  3.64it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:44<00:28,  3.64it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:45<00:28,  3.64it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:45<00:27,  3.62it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:45<00:27,  3.63it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:46<00:27,  3.65it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:46<00:26,  3.66it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:46<00:26,  3.64it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:46<00:26,  3.65it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:47<00:25,  3.66it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:47<00:25,  3.67it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:47<00:25,  3.67it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:47<00:25,  3.67it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:48<00:24,  3.67it/s]\u001b[AI1018 13:41:44.438599 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-2250/config.json\n",
      "I1018 13:41:45.105449 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-2250/pytorch_model.bin\n",
      "I1018 13:41:45.108338 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-2250\n",
      "\n",
      "Iteration:  65%|██████▌   | 170/260 [00:49<00:42,  2.10it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:49<00:36,  2.43it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:49<00:32,  2.70it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:49<00:29,  2.94it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:50<00:27,  3.11it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:50<00:26,  3.25it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:50<00:25,  3.36it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:51<00:24,  3.44it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:51<00:23,  3.50it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:51<00:23,  3.52it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:51<00:22,  3.55it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:52<00:22,  3.58it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:52<00:21,  3.60it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:52<00:21,  3.61it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:53<00:20,  3.62it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:53<00:20,  3.63it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:53<00:20,  3.63it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:53<00:20,  3.64it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:54<00:19,  3.64it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:54<00:19,  3.64it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:54<00:19,  3.64it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:54<00:18,  3.64it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:55<00:18,  3.64it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:55<00:18,  3.64it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:55<00:18,  3.64it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:56<00:17,  3.64it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:56<00:17,  3.64it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:56<00:17,  3.64it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:56<00:17,  3.64it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:57<00:16,  3.64it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:57<00:16,  3.64it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 201/260 [00:57<00:16,  3.64it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:57<00:15,  3.64it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:58<00:15,  3.64it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:58<00:15,  3.64it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:58<00:15,  3.64it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:59<00:14,  3.64it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [00:59<00:14,  3.64it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:59<00:14,  3.64it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [00:59<00:13,  3.65it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [01:00<00:13,  3.65it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [01:00<00:13,  3.65it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [01:00<00:13,  3.65it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [01:00<00:12,  3.64it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [01:01<00:12,  3.65it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [01:01<00:12,  3.65it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [01:01<00:12,  3.65it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [01:02<00:11,  3.65it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [01:02<00:11,  3.65it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [01:02<00:11,  3.65it/s]\u001b[AI1018 13:41:58.831426 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-2300/config.json\n",
      "I1018 13:41:59.490828 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-2300/pytorch_model.bin\n",
      "I1018 13:41:59.493948 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-2300\n",
      "\n",
      "Iteration:  85%|████████▍ | 220/260 [01:03<00:18,  2.11it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [01:03<00:16,  2.43it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [01:04<00:14,  2.70it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [01:04<00:12,  2.92it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [01:04<00:11,  3.11it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [01:04<00:10,  3.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [01:05<00:10,  3.36it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [01:05<00:09,  3.44it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [01:05<00:09,  3.50it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [01:06<00:08,  3.54it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [01:06<00:08,  3.58it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [01:06<00:08,  3.60it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [01:06<00:07,  3.61it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [01:07<00:07,  3.62it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [01:07<00:07,  3.63it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [01:07<00:06,  3.64it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [01:07<00:06,  3.64it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [01:08<00:06,  3.64it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [01:08<00:06,  3.61it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [01:08<00:05,  3.63it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [01:09<00:05,  3.65it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [01:09<00:05,  3.63it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [01:09<00:04,  3.62it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [01:09<00:04,  3.60it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [01:10<00:04,  3.61it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [01:10<00:04,  3.62it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [01:10<00:03,  3.63it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [01:10<00:03,  3.63it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [01:11<00:03,  3.61it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [01:11<00:03,  3.63it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [01:11<00:02,  3.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  97%|█████████▋| 251/260 [01:12<00:02,  3.63it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [01:12<00:02,  3.65it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [01:12<00:01,  3.66it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [01:12<00:01,  3.66it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [01:13<00:01,  3.66it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [01:13<00:01,  3.67it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [01:13<00:00,  3.66it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [01:13<00:00,  3.67it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [01:14<00:00,  3.65it/s]\u001b[A\n",
      "Epoch:  90%|█████████ | 9/10 [11:30<01:16, 76.35s/it]19it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<01:09,  3.74it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<01:09,  3.72it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<01:09,  3.71it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:01<01:09,  3.70it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:01<01:09,  3.69it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:01<01:08,  3.69it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:01<01:08,  3.69it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:02<01:08,  3.68it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:02<01:08,  3.68it/s]\u001b[AI1018 13:42:13.076464 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-2350/config.json\n",
      "I1018 13:42:13.727029 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-2350/pytorch_model.bin\n",
      "I1018 13:42:13.732233 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-2350\n",
      "\n",
      "Iteration:   4%|▍         | 10/260 [00:03<01:57,  2.13it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:03<01:41,  2.45it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:03<01:31,  2.72it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:04<01:23,  2.95it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:04<01:18,  3.12it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:04<01:14,  3.27it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:05<01:12,  3.38it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:05<01:10,  3.47it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:05<01:08,  3.52it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:05<01:07,  3.57it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:06<01:06,  3.60it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:06<01:05,  3.62it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:06<01:05,  3.64it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:06<01:04,  3.65it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:07<01:04,  3.66it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:07<01:04,  3.66it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:07<01:03,  3.66it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:07<01:03,  3.67it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:08<01:03,  3.67it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:08<01:02,  3.67it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:08<01:02,  3.67it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:09<01:02,  3.67it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:09<01:02,  3.67it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:09<01:01,  3.67it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:09<01:01,  3.68it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:10<01:01,  3.67it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:10<01:00,  3.67it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:10<01:00,  3.68it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:10<01:00,  3.68it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:11<01:00,  3.68it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:11<00:59,  3.68it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:11<00:59,  3.68it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:12<00:59,  3.65it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:12<00:59,  3.65it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:12<00:59,  3.65it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:12<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:13<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:13<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:13<00:58,  3.64it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:14<00:57,  3.64it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:14<00:57,  3.64it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 51/260 [00:14<00:57,  3.65it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:14<00:57,  3.62it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:15<00:57,  3.63it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:15<00:56,  3.63it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:15<00:56,  3.63it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:15<00:56,  3.64it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:16<00:55,  3.64it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:16<00:55,  3.64it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:16<00:55,  3.64it/s]\u001b[AI1018 13:42:27.393678 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-2400/config.json\n",
      "I1018 13:42:28.060781 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-2400/pytorch_model.bin\n",
      "I1018 13:42:28.063749 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-2400\n",
      "\n",
      "Iteration:  23%|██▎       | 60/260 [00:17<01:35,  2.10it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:17<01:22,  2.42it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:18<01:14,  2.67it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:18<01:07,  2.91it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:18<01:03,  3.11it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:19<00:59,  3.26it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:19<00:57,  3.37it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:19<00:55,  3.46it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:19<00:54,  3.52it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:20<00:53,  3.57it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:20<00:52,  3.60it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:20<00:52,  3.62it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:20<00:51,  3.64it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:21<00:51,  3.65it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:21<00:50,  3.66it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:21<00:50,  3.66it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:22<00:50,  3.66it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:22<00:49,  3.67it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:22<00:49,  3.67it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:22<00:49,  3.67it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:23<00:48,  3.68it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:23<00:48,  3.68it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:23<00:48,  3.68it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:23<00:48,  3.68it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:24<00:47,  3.68it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:24<00:47,  3.68it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:24<00:47,  3.68it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:25<00:47,  3.68it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:25<00:46,  3.68it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:25<00:46,  3.68it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:25<00:46,  3.67it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:26<00:46,  3.67it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:26<00:45,  3.67it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:26<00:45,  3.67it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:26<00:45,  3.67it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:27<00:44,  3.67it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:27<00:44,  3.68it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:27<00:44,  3.67it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:28<00:44,  3.68it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:28<00:43,  3.68it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:28<00:43,  3.68it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 101/260 [00:28<00:43,  3.68it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:29<00:43,  3.65it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:29<00:42,  3.66it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:29<00:42,  3.66it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:29<00:42,  3.67it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:30<00:41,  3.67it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:30<00:41,  3.67it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:30<00:41,  3.65it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:31<00:41,  3.65it/s]\u001b[AI1018 13:42:41.692795 47382659590592 configuration_utils.py:70] Configuration saved in bert_output_uncased/checkpoint-2450/config.json\n",
      "I1018 13:42:42.344162 47382659590592 modeling_utils.py:205] Model weights saved in bert_output_uncased/checkpoint-2450/pytorch_model.bin\n",
      "I1018 13:42:42.347359 47382659590592 <ipython-input-11-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_uncased/checkpoint-2450\n",
      "\n",
      "Iteration:  42%|████▏     | 110/260 [00:31<01:10,  2.12it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:32<01:01,  2.43it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:32<00:54,  2.70it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:32<00:50,  2.93it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:33<00:46,  3.11it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:33<00:44,  3.25it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:33<00:42,  3.36it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:33<00:41,  3.44it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:34<00:40,  3.50it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:34<00:39,  3.54it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:34<00:39,  3.57it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:35<00:38,  3.60it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:35<00:38,  3.61it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:35<00:37,  3.62it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:35<00:37,  3.63it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:36<00:37,  3.64it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:36<00:36,  3.63it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:36<00:36,  3.64it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:36<00:36,  3.64it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:37<00:35,  3.64it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:37<00:35,  3.64it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:37<00:35,  3.64it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:38<00:35,  3.64it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:38<00:34,  3.64it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:38<00:34,  3.64it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:38<00:34,  3.64it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:39<00:34,  3.64it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:39<00:33,  3.64it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:39<00:33,  3.64it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:39<00:33,  3.64it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:40<00:32,  3.64it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:40<00:32,  3.65it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:40<00:32,  3.65it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:41<00:32,  3.65it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:41<00:31,  3.65it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "#english uncased\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1014 18:42:22.917361 47346561829312 <ipython-input-18-fb4439387059>:110] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "I1014 18:42:23.098289 47346561829312 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/33b56ce0f312e47e4d77a57791a4fc6233ae4a560dd2bdd186107058294e58ab.3d3939ed0a2ebc86dd3c4703e5a591dcfb3341e9bbf87d411dea195948a37c74\n",
      "I1014 18:42:23.099963 47346561829312 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "I1014 18:42:23.180962 47346561829312 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/bb773818882b0524dc53a1b31a2cc95bc489f000e7e19773ba07846011a6c711.535306b226c42cebebbc0dabc83b92ab11260e9919e21e2ab0beb301f267b4c7\n",
      "I1014 18:42:23.485458 47346561829312 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/cc4042a0d6f70eae595ea0e6d49521b17bd6251f973b3e37d303ce7945b90eed.54b4dad9cc3db9aa8448458b782d11ab07c80dedb951906fd2f684a00ecdb1ee\n",
      "I1014 18:42:28.409197 47346561829312 modeling_utils.py:405] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1014 18:42:28.410543 47346561829312 modeling_utils.py:408] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1014 18:42:32.923222 47346561829312 <ipython-input-18-fb4439387059>:141] Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='/projectnb/llamagrp/feyzanb', config_name='', data_dir='dataset/0', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-multilingual-uncased', model_type='bertmultilabel', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='bert_output_mutlilingual_cased', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=50, seed=42, server_ip='', server_port='', task_name='frame', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "I1014 18:42:32.925797 47346561829312 <ipython-input-16-5385282ede45>:15] Loading features from cached file dataset/0/cached_train_bert-base-multilingual-uncased_128_frame\n",
      "I1014 18:42:32.965181 47346561829312 <ipython-input-13-ce0a3a7e9c33>:42] ***** Running training *****\n",
      "I1014 18:42:32.966042 47346561829312 <ipython-input-13-ce0a3a7e9c33>:43]   Num examples = 1037\n",
      "I1014 18:42:32.966898 47346561829312 <ipython-input-13-ce0a3a7e9c33>:44]   Num Epochs = 10\n",
      "I1014 18:42:32.968005 47346561829312 <ipython-input-13-ce0a3a7e9c33>:45]   Instantaneous batch size per GPU = 4\n",
      "I1014 18:42:32.968664 47346561829312 <ipython-input-13-ce0a3a7e9c33>:47]   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "I1014 18:42:32.969307 47346561829312 <ipython-input-13-ce0a3a7e9c33>:48]   Gradient Accumulation steps = 1\n",
      "I1014 18:42:32.969969 47346561829312 <ipython-input-13-ce0a3a7e9c33>:49]   Total optimization steps = 2600\n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/260 [00:00<00:25,  9.98it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/260 [00:00<00:24, 10.58it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 5/260 [00:00<00:22, 11.28it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 7/260 [00:00<00:21, 11.87it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 9/260 [00:00<00:20, 12.33it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 11/260 [00:00<00:19, 12.67it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 13/260 [00:01<00:19, 12.93it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 15/260 [00:01<00:18, 13.10it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 17/260 [00:01<00:18, 13.22it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 19/260 [00:01<00:18, 13.32it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 21/260 [00:01<00:17, 13.38it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 23/260 [00:01<00:17, 13.41it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 25/260 [00:01<00:17, 13.45it/s]\u001b[A\n",
      "Iteration:  10%|█         | 27/260 [00:02<00:17, 13.48it/s]\u001b[A\n",
      "Iteration:  11%|█         | 29/260 [00:02<00:17, 13.56it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 31/260 [00:02<00:16, 13.56it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 33/260 [00:02<00:16, 13.55it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 35/260 [00:02<00:16, 13.54it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 37/260 [00:02<00:16, 13.53it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 39/260 [00:02<00:16, 13.54it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 41/260 [00:03<00:16, 13.46it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 43/260 [00:03<00:15, 13.62it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 45/260 [00:03<00:15, 13.66it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 47/260 [00:03<00:15, 13.69it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 49/260 [00:03<00:15, 13.56it/s]\u001b[AI1014 18:42:36.712917 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-50/config.json\n",
      "I1014 18:42:38.088311 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-50/pytorch_model.bin\n",
      "I1014 18:42:38.092061 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-50\n",
      "\n",
      "Iteration:  20%|█▉        | 51/260 [00:05<00:58,  3.55it/s]\u001b[A\n",
      "Iteration:  20%|██        | 53/260 [00:05<00:45,  4.57it/s]\u001b[A\n",
      "Iteration:  21%|██        | 55/260 [00:05<00:35,  5.71it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 57/260 [00:05<00:29,  6.91it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 59/260 [00:05<00:24,  8.13it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 61/260 [00:05<00:21,  9.27it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 63/260 [00:06<00:19, 10.28it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 65/260 [00:06<00:17, 11.13it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 67/260 [00:06<00:16, 11.86it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 69/260 [00:06<00:15, 12.32it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 71/260 [00:06<00:14, 12.66it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 73/260 [00:06<00:14, 12.97it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 75/260 [00:06<00:14, 13.19it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 77/260 [00:07<00:13, 13.29it/s]\u001b[A\n",
      "Iteration:  30%|███       | 79/260 [00:07<00:13, 13.43it/s]\u001b[A\n",
      "Iteration:  31%|███       | 81/260 [00:07<00:13, 13.59it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 83/260 [00:07<00:12, 13.64it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 85/260 [00:07<00:12, 13.60it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 87/260 [00:07<00:12, 13.64it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 89/260 [00:07<00:12, 13.60it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 91/260 [00:08<00:12, 13.57it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 93/260 [00:08<00:12, 13.55it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 95/260 [00:08<00:12, 13.54it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 97/260 [00:08<00:11, 13.60it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 99/260 [00:08<00:11, 13.57it/s]\u001b[AI1014 18:42:41.755141 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-100/config.json\n",
      "I1014 18:42:43.120466 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-100/pytorch_model.bin\n",
      "I1014 18:42:43.124769 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-100\n",
      "\n",
      "Iteration:  39%|███▉      | 101/260 [00:10<00:44,  3.57it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 103/260 [00:10<00:34,  4.58it/s]\u001b[A\n",
      "Iteration:  40%|████      | 105/260 [00:10<00:27,  5.71it/s]\u001b[A\n",
      "Iteration:  41%|████      | 107/260 [00:10<00:22,  6.90it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 109/260 [00:10<00:18,  8.09it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 111/260 [00:10<00:16,  9.19it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 113/260 [00:11<00:14, 10.16it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 115/260 [00:11<00:13, 10.99it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 117/260 [00:11<00:12, 11.64it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 119/260 [00:11<00:11, 12.14it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 121/260 [00:11<00:11, 12.52it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 123/260 [00:11<00:10, 12.86it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 125/260 [00:11<00:10, 13.17it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 127/260 [00:12<00:09, 13.33it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 129/260 [00:12<00:09, 13.44it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 131/260 [00:12<00:09, 13.46it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 133/260 [00:12<00:09, 13.54it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 135/260 [00:12<00:09, 13.53it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 137/260 [00:12<00:09, 13.52it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 139/260 [00:13<00:08, 13.52it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 141/260 [00:13<00:08, 13.58it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 143/260 [00:13<00:08, 13.56it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 145/260 [00:13<00:08, 13.61it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 147/260 [00:13<00:08, 13.59it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 149/260 [00:13<00:08, 13.56it/s]\u001b[AI1014 18:42:46.815375 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-150/config.json\n",
      "I1014 18:42:48.151119 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-150/pytorch_model.bin\n",
      "I1014 18:42:48.154917 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-150\n",
      "\n",
      "Iteration:  58%|█████▊    | 151/260 [00:15<00:30,  3.63it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 153/260 [00:15<00:23,  4.65it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 155/260 [00:15<00:18,  5.80it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 157/260 [00:15<00:14,  7.01it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 159/260 [00:15<00:12,  8.21it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 161/260 [00:15<00:10,  9.32it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 163/260 [00:16<00:09, 10.35it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 165/260 [00:16<00:08, 11.16it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 167/260 [00:16<00:07, 11.80it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 169/260 [00:16<00:07, 12.31it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 171/260 [00:16<00:07, 12.68it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 173/260 [00:16<00:06, 12.95it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 175/260 [00:17<00:06, 13.14it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 177/260 [00:17<00:06, 13.28it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 179/260 [00:17<00:06, 13.38it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 181/260 [00:17<00:05, 13.38it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 183/260 [00:17<00:05, 13.44it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 185/260 [00:17<00:05, 13.50it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 187/260 [00:17<00:05, 13.53it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 189/260 [00:18<00:05, 13.57it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 191/260 [00:18<00:05, 13.59it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 193/260 [00:18<00:04, 13.61it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 195/260 [00:18<00:04, 13.62it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 197/260 [00:18<00:04, 13.63it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 199/260 [00:18<00:04, 13.71it/s]\u001b[AI1014 18:42:51.826250 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-200/config.json\n",
      "I1014 18:42:53.159300 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-200/pytorch_model.bin\n",
      "I1014 18:42:53.163955 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-200\n",
      "\n",
      "Iteration:  77%|███████▋  | 201/260 [00:20<00:16,  3.64it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 203/260 [00:20<00:12,  4.65it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 205/260 [00:20<00:09,  5.78it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 207/260 [00:20<00:07,  6.97it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 209/260 [00:20<00:06,  8.15it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 211/260 [00:21<00:05,  9.27it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 213/260 [00:21<00:04, 10.22it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 215/260 [00:21<00:04, 11.01it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 217/260 [00:21<00:03, 11.63it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 219/260 [00:21<00:03, 12.18it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 221/260 [00:21<00:03, 12.55it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 223/260 [00:21<00:02, 12.80it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 225/260 [00:22<00:02, 13.00it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 227/260 [00:22<00:02, 13.13it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 229/260 [00:22<00:02, 13.23it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 231/260 [00:22<00:02, 13.30it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 233/260 [00:22<00:02, 13.35it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 235/260 [00:22<00:01, 13.31it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 237/260 [00:22<00:01, 13.36it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 239/260 [00:23<00:01, 13.41it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 241/260 [00:23<00:01, 13.44it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 243/260 [00:23<00:01, 13.45it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 245/260 [00:23<00:01, 13.53it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 247/260 [00:23<00:00, 13.52it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 249/260 [00:23<00:00, 13.58it/s]\u001b[AI1014 18:42:56.881092 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-250/config.json\n",
      "I1014 18:42:58.205156 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-250/pytorch_model.bin\n",
      "I1014 18:42:58.210010 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-250\n",
      "\n",
      "Iteration:  97%|█████████▋| 251/260 [00:25<00:02,  3.65it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 253/260 [00:25<00:01,  4.67it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 255/260 [00:25<00:00,  5.82it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 257/260 [00:25<00:00,  7.03it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 259/260 [00:25<00:00,  8.21it/s]\u001b[A\n",
      "Epoch:  10%|█         | 1/10 [00:25<03:53, 25.98s/it]01it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<00:18, 13.67it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:00<00:18, 13.64it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:00<00:18, 13.61it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:00<00:18, 13.59it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:00<00:18, 13.57it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:00<00:18, 13.56it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:01<00:18, 13.55it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:01<00:18, 13.54it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:01<00:17, 13.53it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:01<00:17, 13.53it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:01<00:17, 13.60it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:01<00:17, 13.55it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:01<00:17, 13.61it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:02<00:17, 13.58it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:02<00:16, 13.53it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:02<00:16, 13.52it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:02<00:16, 13.51it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  14%|█▍        | 36/260 [00:02<00:16, 13.51it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:02<00:16, 13.51it/s]\u001b[AI1014 18:43:01.915029 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-300/config.json\n",
      "I1014 18:43:03.227858 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-300/pytorch_model.bin\n",
      "I1014 18:43:03.232137 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-300\n",
      "\n",
      "Iteration:  15%|█▌        | 40/260 [00:04<00:59,  3.67it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:04<00:46,  4.69it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:04<00:36,  5.85it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:04<00:30,  7.05it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:04<00:25,  8.24it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:05<00:22,  9.34it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:05<00:20, 10.30it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:05<00:18, 11.15it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:05<00:17, 11.83it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:05<00:16, 12.30it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:05<00:15, 12.65it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:05<00:15, 12.91it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:06<00:14, 13.10it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:06<00:14, 13.30it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:06<00:14, 13.38it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:06<00:14, 13.43it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:06<00:13, 13.47it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:06<00:13, 13.48it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:06<00:13, 13.50it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:07<00:13, 13.59it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:07<00:13, 13.58it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:07<00:13, 13.52it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:07<00:13, 13.53it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:07<00:12, 13.53it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:07<00:12, 13.53it/s]\u001b[AI1014 18:43:06.918548 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-350/config.json\n",
      "I1014 18:43:08.224039 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-350/pytorch_model.bin\n",
      "I1014 18:43:08.228836 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-350\n",
      "\n",
      "Iteration:  35%|███▍      | 90/260 [00:09<00:46,  3.69it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:09<00:35,  4.71it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:09<00:28,  5.86it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:09<00:23,  7.06it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:09<00:19,  8.27it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:10<00:17,  9.40it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:10<00:15, 10.35it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:10<00:14, 11.14it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:10<00:13, 11.78it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:10<00:12, 12.31it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:10<00:11, 12.66it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:10<00:11, 12.91it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:11<00:11, 13.10it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:11<00:10, 13.24it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:11<00:10, 13.33it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:11<00:10, 13.40it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:11<00:10, 13.44it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:11<00:10, 13.48it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:11<00:09, 13.50it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:12<00:09, 13.51it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:12<00:09, 13.53it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:12<00:09, 13.53it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:12<00:09, 13.61it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:12<00:09, 13.59it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:12<00:09, 13.37it/s]\u001b[AI1014 18:43:11.928454 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-400/config.json\n",
      "I1014 18:43:13.233118 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-400/pytorch_model.bin\n",
      "I1014 18:43:13.238798 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-400\n",
      "\n",
      "Iteration:  54%|█████▍    | 140/260 [00:14<00:32,  3.67it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:14<00:25,  4.70it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:14<00:19,  5.85it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:14<00:16,  7.06it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:14<00:13,  8.26it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:15<00:11,  9.38it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:15<00:10, 10.37it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:15<00:09, 11.19it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:15<00:08, 11.84it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:15<00:08, 12.34it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:15<00:07, 12.72it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:15<00:07, 13.00it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:16<00:07, 13.26it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:16<00:07, 13.37it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:16<00:06, 13.47it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:16<00:06, 13.53it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:16<00:06, 13.59it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:16<00:06, 13.69it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:16<00:06, 13.83it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:17<00:05, 13.86it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:17<00:05, 13.80it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:17<00:05, 13.84it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:17<00:05, 13.80it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:17<00:05, 13.77it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:17<00:05, 13.75it/s]\u001b[AI1014 18:43:16.879869 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-450/config.json\n",
      "I1014 18:43:18.183320 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-450/pytorch_model.bin\n",
      "I1014 18:43:18.187431 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-450\n",
      "\n",
      "Iteration:  73%|███████▎  | 190/260 [00:19<00:18,  3.71it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:19<00:14,  4.74it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:19<00:11,  5.90it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:19<00:08,  7.11it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:19<00:07,  8.31it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:19<00:06,  9.42it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:20<00:05, 10.43it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:20<00:04, 11.23it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:20<00:04, 11.87it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:20<00:04, 12.37it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [00:20<00:03, 12.80it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [00:20<00:03, 13.05it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [00:20<00:03, 13.24it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [00:21<00:03, 13.37it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [00:21<00:03, 13.47it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [00:21<00:02, 13.54it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [00:21<00:02, 13.65it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [00:21<00:02, 13.67it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [00:21<00:02, 13.67it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [00:22<00:02, 13.67it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [00:22<00:02, 13.68it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [00:22<00:02, 13.69it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [00:22<00:01, 13.70it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [00:22<00:01, 13.70it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [00:22<00:01, 13.69it/s]\u001b[AI1014 18:43:21.838320 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-500/config.json\n",
      "I1014 18:43:23.137017 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-500/pytorch_model.bin\n",
      "I1014 18:43:23.142724 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-500\n",
      "\n",
      "Iteration:  92%|█████████▏| 240/260 [00:24<00:05,  3.71it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [00:24<00:03,  4.74it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [00:24<00:02,  5.91it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [00:24<00:01,  7.13it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [00:24<00:01,  8.33it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [00:24<00:01,  9.43it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [00:25<00:00, 10.40it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [00:25<00:00, 11.21it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [00:25<00:00, 11.85it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [00:25<00:00, 12.41it/s]\u001b[A\n",
      "Epoch:  20%|██        | 2/10 [00:51<03:27, 25.88s/it]00it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<00:18, 14.28it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:00<00:18, 14.09it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:00<00:18, 13.96it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:00<00:18, 13.88it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:00<00:17, 13.90it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:00<00:17, 13.91it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:01<00:17, 13.84it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:01<00:17, 13.79it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:01<00:17, 13.76it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:01<00:17, 13.74it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:01<00:17, 13.86it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:01<00:17, 13.88it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:01<00:16, 13.82it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:02<00:16, 13.77it/s]\u001b[AI1014 18:43:26.770068 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-550/config.json\n",
      "I1014 18:43:28.070386 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-550/pytorch_model.bin\n",
      "I1014 18:43:28.074751 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-550\n",
      "\n",
      "Iteration:  12%|█▏        | 30/260 [00:03<01:01,  3.72it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:03<00:47,  4.76it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:03<00:38,  5.92it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:03<00:31,  7.13it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:04<00:26,  8.33it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:04<00:23,  9.47it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:04<00:20, 10.44it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:04<00:19, 11.24it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:04<00:18, 11.88it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:04<00:17, 12.37it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:04<00:16, 12.74it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:05<00:15, 13.07it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:05<00:15, 13.25it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:05<00:15, 13.45it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:05<00:14, 13.52it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:05<00:14, 13.57it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:05<00:14, 13.61it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:05<00:14, 13.70it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:06<00:14, 13.71it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:06<00:14, 13.71it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:06<00:13, 13.70it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:06<00:13, 13.70it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:06<00:13, 13.84it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:06<00:13, 13.87it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:06<00:13, 13.82it/s]\u001b[AI1014 18:43:31.713613 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-600/config.json\n",
      "I1014 18:43:33.012522 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-600/pytorch_model.bin\n",
      "I1014 18:43:33.017206 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-600\n",
      "\n",
      "Iteration:  31%|███       | 80/260 [00:08<00:48,  3.72it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:08<00:37,  4.76it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:08<00:29,  5.92it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:08<00:24,  7.17it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:08<00:20,  8.41it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:09<00:17,  9.56it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:09<00:15, 10.50it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:09<00:14, 11.28it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:09<00:13, 11.90it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:09<00:13, 12.43it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:09<00:12, 12.83it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:10<00:12, 13.12it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:10<00:11, 13.27it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:10<00:11, 13.37it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:10<00:11, 13.51it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:10<00:11, 13.30it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:10<00:11, 13.35it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:10<00:10, 13.43it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:11<00:10, 13.49it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:11<00:10, 13.59it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:11<00:10, 13.61it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:11<00:10, 13.76it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:11<00:09, 13.72it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:11<00:09, 13.70it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:11<00:09, 13.75it/s]\u001b[AI1014 18:43:36.666796 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-650/config.json\n",
      "I1014 18:43:37.968832 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-650/pytorch_model.bin\n",
      "I1014 18:43:37.973000 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-650\n",
      "\n",
      "Iteration:  50%|█████     | 130/260 [00:13<00:35,  3.71it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:13<00:26,  4.75it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:13<00:21,  5.91it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:13<00:17,  7.12it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:13<00:14,  8.29it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:14<00:12,  9.39it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:14<00:11, 10.35it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:14<00:10, 11.17it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:14<00:09, 11.81it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:14<00:09, 12.29it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:14<00:08, 12.68it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:14<00:08, 13.02it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:15<00:08, 13.23it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:15<00:07, 13.40it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:15<00:07, 13.58it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:15<00:07, 13.64it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:15<00:07, 13.75it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:15<00:06, 13.76it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:15<00:06, 13.88it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:16<00:06, 13.82it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:16<00:06, 13.83it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:16<00:06, 13.86it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:16<00:06, 13.82it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:16<00:06, 13.80it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  68%|██████▊   | 178/260 [00:16<00:05, 13.85it/s]\u001b[AI1014 18:43:41.608886 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-700/config.json\n",
      "I1014 18:43:42.900787 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-700/pytorch_model.bin\n",
      "I1014 18:43:42.905409 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-700\n",
      "\n",
      "Iteration:  69%|██████▉   | 180/260 [00:18<00:21,  3.74it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:18<00:16,  4.77it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:18<00:12,  5.94it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:18<00:10,  7.16it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:18<00:08,  8.40it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:19<00:07,  9.50it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:19<00:06, 10.44it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:19<00:05, 11.21it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:19<00:05, 11.89it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:19<00:05, 12.37it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:19<00:04, 12.78it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:19<00:04, 13.03it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:20<00:04, 13.22it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:20<00:04, 13.38it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:20<00:03, 13.53it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [00:20<00:03, 13.60it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [00:20<00:03, 13.67it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [00:20<00:03, 13.72it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [00:20<00:03, 13.80it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [00:21<00:03, 13.86it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [00:21<00:02, 13.92it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [00:21<00:02, 13.90it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [00:21<00:02, 13.96it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [00:21<00:02, 13.92it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [00:21<00:02, 13.96it/s]\u001b[AI1014 18:43:46.528897 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-750/config.json\n",
      "I1014 18:43:47.818396 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-750/pytorch_model.bin\n",
      "I1014 18:43:47.823662 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-750\n",
      "\n",
      "Iteration:  88%|████████▊ | 230/260 [00:23<00:08,  3.75it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [00:23<00:05,  4.80it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [00:23<00:04,  5.96it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [00:23<00:03,  7.19it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [00:23<00:02,  8.41it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [00:23<00:02,  9.55it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [00:24<00:01, 10.50it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [00:24<00:01, 11.29it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [00:24<00:01, 11.91it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [00:24<00:00, 12.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [00:24<00:00, 12.74it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [00:24<00:00, 13.07it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [00:24<00:00, 13.31it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [00:25<00:00, 13.49it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [00:25<00:00, 13.54it/s]\u001b[A\n",
      "Epoch:  30%|███       | 3/10 [01:17<03:00, 25.73s/it]93it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<00:18, 13.81it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:00<00:18, 13.92it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:00<00:18, 13.86it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:00<00:18, 13.80it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:00<00:17, 13.91it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:00<00:17, 13.99it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:01<00:17, 13.90it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:01<00:17, 13.84it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:01<00:17, 13.80it/s]\u001b[AI1014 18:43:51.442579 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-800/config.json\n",
      "I1014 18:43:52.724961 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-800/pytorch_model.bin\n",
      "I1014 18:43:52.729429 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-800\n",
      "\n",
      "Iteration:   8%|▊         | 20/260 [00:02<01:03,  3.75it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:02<00:49,  4.80it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:03<00:39,  5.97it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:03<00:32,  7.18it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:03<00:27,  8.35it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:03<00:24,  9.48it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:03<00:21, 10.47it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:03<00:20, 11.26it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:03<00:18, 11.93it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:04<00:17, 12.44it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:04<00:17, 12.84it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:04<00:16, 12.99it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:04<00:16, 13.31it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:04<00:15, 13.48it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:04<00:15, 13.53it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:04<00:15, 13.56it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:05<00:15, 13.59it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:05<00:15, 13.60it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:05<00:14, 13.62it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:05<00:14, 13.69it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:05<00:14, 13.75it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:05<00:14, 13.79it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:05<00:14, 13.89it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:06<00:13, 13.95it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:06<00:13, 13.93it/s]\u001b[AI1014 18:43:56.361198 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-850/config.json\n",
      "I1014 18:43:57.655901 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-850/pytorch_model.bin\n",
      "I1014 18:43:57.659904 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-850\n",
      "\n",
      "Iteration:  27%|██▋       | 70/260 [00:07<00:50,  3.74it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:07<00:39,  4.78it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:07<00:31,  5.95it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:08<00:25,  7.18it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:08<00:21,  8.38it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:08<00:18,  9.51it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:08<00:17, 10.46it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:08<00:15, 11.26it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:08<00:14, 11.88it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:08<00:13, 12.36it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:09<00:13, 12.79it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:09<00:12, 13.10it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:09<00:12, 13.26it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:09<00:12, 13.44it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:09<00:11, 13.57it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:09<00:11, 13.60it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:09<00:11, 13.61it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:10<00:11, 13.69it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:10<00:11, 13.75it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:10<00:11, 13.79it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:10<00:10, 13.82it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:10<00:10, 13.84it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:10<00:10, 13.92it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:10<00:10, 13.91it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:11<00:10, 13.90it/s]\u001b[AI1014 18:44:01.287068 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-900/config.json\n",
      "I1014 18:44:02.579361 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-900/pytorch_model.bin\n",
      "I1014 18:44:02.583086 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-900\n",
      "\n",
      "Iteration:  46%|████▌     | 120/260 [00:12<00:37,  3.74it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:12<00:28,  4.77it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:12<00:22,  5.94it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:13<00:18,  7.15it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:13<00:15,  8.37it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:13<00:13,  9.50it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:13<00:12, 10.49it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:13<00:11, 11.27it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:13<00:10, 12.00it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:13<00:09, 12.50it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:14<00:09, 12.88it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:14<00:09, 13.10it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:14<00:08, 13.32it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:14<00:08, 13.42it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:14<00:08, 13.55it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:14<00:08, 13.50it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:14<00:07, 13.68it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:15<00:07, 13.73it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:15<00:07, 13.77it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:15<00:07, 13.73it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:15<00:07, 13.70it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:15<00:07, 13.76it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:15<00:06, 13.79it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:15<00:06, 13.74it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:16<00:06, 13.78it/s]\u001b[AI1014 18:44:06.215353 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-950/config.json\n",
      "I1014 18:44:07.499447 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-950/pytorch_model.bin\n",
      "I1014 18:44:07.503714 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-950\n",
      "\n",
      "Iteration:  65%|██████▌   | 170/260 [00:17<00:23,  3.75it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:17<00:18,  4.79it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:17<00:14,  5.96it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:17<00:11,  7.19it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:18<00:09,  8.38it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:18<00:08,  9.51it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:18<00:07, 10.51it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:18<00:06, 11.33it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:18<00:06, 11.94it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:18<00:05, 12.46it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:18<00:05, 12.80it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:19<00:05, 13.17it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:19<00:04, 13.36it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:19<00:04, 13.52it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:19<00:04, 13.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:19<00:04, 13.60it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:19<00:04, 13.62it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:19<00:04, 13.63it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:20<00:03, 13.55it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:20<00:03, 13.64it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [00:20<00:03, 13.65it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [00:20<00:03, 13.72it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [00:20<00:03, 13.76it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [00:20<00:03, 13.88it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [00:20<00:03, 13.95it/s]\u001b[AI1014 18:44:11.134510 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1000/config.json\n",
      "I1014 18:44:12.425775 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1000/pytorch_model.bin\n",
      "I1014 18:44:12.430174 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1000\n",
      "\n",
      "Iteration:  85%|████████▍ | 220/260 [00:22<00:10,  3.75it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [00:22<00:07,  4.78it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [00:22<00:06,  5.97it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [00:22<00:04,  7.18it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [00:23<00:03,  8.36it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [00:23<00:03,  9.49it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [00:23<00:02, 10.54it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [00:23<00:02, 11.32it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [00:23<00:02, 11.94it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [00:23<00:01, 12.47it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [00:23<00:01, 12.81it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [00:24<00:01, 13.13it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [00:24<00:01, 13.28it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [00:24<00:01, 13.45it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [00:24<00:00, 13.57it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [00:24<00:00, 13.65it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [00:24<00:00, 13.64it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [00:24<00:00, 13.76it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [00:25<00:00, 13.79it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [00:25<00:00, 13.81it/s]\u001b[A\n",
      "Epoch:  40%|████      | 4/10 [01:42<02:33, 25.61s/it]06it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<00:18, 13.73it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:00<00:18, 13.77it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:00<00:18, 13.85it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:00<00:18, 13.93it/s]\u001b[AI1014 18:44:16.046963 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1050/config.json\n",
      "I1014 18:44:17.370316 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1050/pytorch_model.bin\n",
      "I1014 18:44:17.375025 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1050\n",
      "\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:07,  3.68it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:02<00:52,  4.72it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:02<00:41,  5.89it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:02<00:34,  7.12it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:02<00:28,  8.37it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:02<00:25,  9.50it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:02<00:22, 10.50it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:03<00:20, 11.33it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:03<00:19, 12.00it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:03<00:18, 12.46it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:03<00:17, 12.80it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:03<00:17, 13.11it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:03<00:17, 13.29it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:03<00:16, 13.41it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:04<00:16, 13.56it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:04<00:16, 13.73it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:04<00:15, 13.79it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:04<00:15, 13.82it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:04<00:15, 13.84it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:04<00:15, 13.86it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:04<00:15, 13.94it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:05<00:14, 13.93it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:05<00:14, 13.93it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:05<00:14, 13.89it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  22%|██▏       | 58/260 [00:05<00:14, 13.89it/s]\u001b[AI1014 18:44:20.978689 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1100/config.json\n",
      "I1014 18:44:22.653881 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1100/pytorch_model.bin\n",
      "I1014 18:44:22.658090 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1100\n",
      "\n",
      "Iteration:  23%|██▎       | 60/260 [00:07<01:04,  3.08it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:07<00:49,  4.02it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:07<00:38,  5.10it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:07<00:30,  6.30it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:07<00:25,  7.54it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:08<00:21,  8.77it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:08<00:19,  9.87it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:08<00:17, 10.86it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:08<00:15, 11.68it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:08<00:14, 12.33it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:08<00:14, 12.72it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:08<00:13, 13.13it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:09<00:13, 13.37it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:09<00:12, 13.53it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:09<00:12, 13.59it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:09<00:12, 13.69it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:09<00:12, 13.84it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:09<00:11, 13.87it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:09<00:11, 13.96it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:10<00:11, 13.87it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:10<00:11, 13.82it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:10<00:11, 13.86it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:10<00:11, 13.85it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:10<00:11, 13.88it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:10<00:10, 13.90it/s]\u001b[AI1014 18:44:26.246084 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1150/config.json\n",
      "I1014 18:44:27.946319 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1150/pytorch_model.bin\n",
      "I1014 18:44:27.951018 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1150\n",
      "\n",
      "Iteration:  42%|████▏     | 110/260 [00:12<00:49,  3.04it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:12<00:37,  3.97it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:12<00:28,  5.05it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:13<00:23,  6.24it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:13<00:18,  7.50it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:13<00:16,  8.70it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:13<00:14,  9.83it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:13<00:12, 10.73it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:13<00:11, 11.51it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:13<00:10, 12.14it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:14<00:10, 12.61it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:14<00:09, 12.91it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:14<00:09, 13.18it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:14<00:09, 13.45it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:14<00:08, 13.64it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:14<00:08, 13.78it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:14<00:08, 13.74it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:15<00:08, 13.85it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:15<00:08, 13.86it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:15<00:08, 13.80it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:15<00:07, 13.82it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:15<00:07, 13.84it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:15<00:07, 13.92it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:15<00:07, 13.91it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:16<00:07, 13.83it/s]\u001b[AI1014 18:44:31.553248 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1200/config.json\n",
      "I1014 18:44:33.220823 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1200/pytorch_model.bin\n",
      "I1014 18:44:33.231659 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1200\n",
      "\n",
      "Iteration:  62%|██████▏   | 160/260 [00:17<00:32,  3.08it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:18<00:24,  4.01it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:18<00:18,  5.09it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:18<00:14,  6.29it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:18<00:12,  7.55it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:18<00:10,  8.72it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:18<00:08,  9.86it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:18<00:07, 10.85it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:19<00:07, 11.67it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:19<00:06, 12.33it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:19<00:06, 12.77it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:19<00:05, 13.08it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:19<00:05, 13.38it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:19<00:05, 13.48it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:19<00:05, 13.68it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:20<00:05, 13.70it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:20<00:04, 13.84it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:20<00:04, 13.87it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:20<00:04, 13.96it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:20<00:04, 13.88it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:20<00:04, 13.61it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:20<00:04, 13.61it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:21<00:04, 13.71it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:21<00:03, 13.84it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:21<00:03, 13.95it/s]\u001b[AI1014 18:44:36.829975 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1250/config.json\n",
      "I1014 18:44:38.454574 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1250/pytorch_model.bin\n",
      "I1014 18:44:38.458453 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1250\n",
      "\n",
      "Iteration:  81%|████████  | 210/260 [00:23<00:15,  3.16it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [00:23<00:11,  4.10it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [00:23<00:08,  5.20it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [00:23<00:06,  6.41it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [00:23<00:05,  7.62it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [00:23<00:04,  8.79it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [00:24<00:03,  9.87it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [00:24<00:03, 10.76it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [00:24<00:02, 11.59it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [00:24<00:02, 12.13it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [00:24<00:02, 12.60it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [00:24<00:02, 12.89it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [00:24<00:01, 13.17it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [00:25<00:01, 13.30it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [00:25<00:01, 13.53it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [00:25<00:01, 13.62it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [00:25<00:01, 13.76it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [00:25<00:01, 13.79it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [00:25<00:01, 13.89it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [00:25<00:00, 13.88it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [00:26<00:00, 13.75it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [00:26<00:00, 13.78it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [00:26<00:00, 13.87it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [00:26<00:00, 13.86it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [00:26<00:00, 13.86it/s]\u001b[AI1014 18:44:42.070093 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1300/config.json\n",
      "I1014 18:44:43.672015 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1300/pytorch_model.bin\n",
      "I1014 18:44:43.676395 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1300\n",
      "\n",
      "Epoch:  50%|█████     | 5/10 [02:10<02:12, 26.44s/it]20it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<00:18, 14.02it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:00<00:18, 14.03it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:00<00:18, 13.99it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:00<00:18, 13.88it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:00<00:18, 13.81it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:00<00:17, 13.90it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:01<00:17, 13.89it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:01<00:17, 13.88it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:01<00:17, 13.88it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:01<00:17, 13.80it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:01<00:17, 13.89it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:01<00:17, 13.81it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:01<00:16, 13.90it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:02<00:16, 13.89it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:02<00:16, 13.95it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:02<00:16, 13.85it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:02<00:16, 13.85it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:02<00:16, 13.85it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:02<00:16, 13.85it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:02<00:15, 13.80it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:03<00:15, 13.89it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:03<00:15, 13.88it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:03<00:15, 13.80it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:03<00:15, 13.74it/s]\u001b[AI1014 18:44:47.293019 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1350/config.json\n",
      "I1014 18:44:48.895736 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1350/pytorch_model.bin\n",
      "I1014 18:44:48.900252 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1350\n",
      "\n",
      "Iteration:  19%|█▉        | 50/260 [00:05<01:05,  3.19it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:05<00:50,  4.14it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:05<00:39,  5.24it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:05<00:31,  6.43it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:05<00:26,  7.66it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:05<00:22,  8.85it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:06<00:19,  9.93it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:06<00:18, 10.81it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:06<00:16, 11.63it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:06<00:15, 12.22it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:06<00:14, 12.67it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:06<00:14, 13.08it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:06<00:13, 13.31it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:07<00:13, 13.47it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:07<00:13, 13.66it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:07<00:13, 13.66it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:07<00:12, 13.73it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:07<00:12, 13.85it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:07<00:12, 13.85it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:07<00:12, 13.83it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:08<00:12, 13.81it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:08<00:12, 13.87it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:08<00:11, 13.93it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:08<00:11, 13.86it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:08<00:11, 13.77it/s]\u001b[AI1014 18:44:52.515419 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1400/config.json\n",
      "I1014 18:44:54.118974 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1400/pytorch_model.bin\n",
      "I1014 18:44:54.123415 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1400\n",
      "\n",
      "Iteration:  38%|███▊      | 100/260 [00:10<00:50,  3.18it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:10<00:38,  4.12it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:10<00:29,  5.22it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:10<00:23,  6.43it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:11<00:19,  7.66it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:11<00:16,  8.88it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:11<00:14,  9.96it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:11<00:13, 10.93it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:11<00:12, 11.73it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:11<00:11, 12.36it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:11<00:10, 12.78it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:12<00:10, 13.16it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:12<00:10, 13.44it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:12<00:09, 13.58it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:12<00:09, 13.74it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:12<00:09, 13.86it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:12<00:09, 13.88it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:12<00:09, 13.88it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:13<00:08, 13.81it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:13<00:08, 13.90it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:13<00:08, 13.89it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:13<00:08, 13.96it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:13<00:08, 14.00it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:13<00:08, 14.04it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:13<00:08, 13.92it/s]\u001b[AI1014 18:44:57.707121 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1450/config.json\n",
      "I1014 18:44:59.286562 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1450/pytorch_model.bin\n",
      "I1014 18:44:59.290935 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1450\n",
      "\n",
      "Iteration:  58%|█████▊    | 150/260 [00:15<00:34,  3.22it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:15<00:25,  4.18it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:15<00:19,  5.31it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:16<00:15,  6.53it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:16<00:13,  7.77it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:16<00:11,  8.92it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:16<00:09, 10.04it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:16<00:08, 11.00it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:16<00:08, 11.75it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:16<00:07, 12.38it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:17<00:07, 12.80it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:17<00:06, 13.06it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:17<00:06, 13.30it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:17<00:06, 13.49it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:17<00:06, 13.62it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:17<00:05, 13.71it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:17<00:05, 13.70it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:18<00:05, 13.84it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:18<00:05, 13.94it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:18<00:05, 13.85it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:18<00:05, 13.77it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:18<00:04, 13.89it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:18<00:04, 13.84it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:18<00:04, 13.87it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  76%|███████▌  | 198/260 [00:19<00:04, 13.89it/s]\u001b[AI1014 18:45:02.884966 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1500/config.json\n",
      "I1014 18:45:04.456979 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1500/pytorch_model.bin\n",
      "I1014 18:45:04.462090 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1500\n",
      "\n",
      "Iteration:  77%|███████▋  | 200/260 [00:20<00:18,  3.23it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:20<00:13,  4.20it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:21<00:10,  5.31it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:21<00:08,  6.51it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:21<00:06,  7.74it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [00:21<00:05,  8.94it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [00:21<00:04,  9.99it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [00:21<00:04, 10.96it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [00:21<00:03, 11.73it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [00:22<00:03, 12.32it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [00:22<00:03, 12.72it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [00:22<00:02, 13.13it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [00:22<00:02, 13.36it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [00:22<00:02, 13.52it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [00:22<00:02, 13.64it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [00:22<00:02, 13.79it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [00:23<00:02, 13.85it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [00:23<00:01, 13.95it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [00:23<00:01, 14.01it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [00:23<00:01, 13.90it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [00:23<00:01, 13.97it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [00:23<00:01, 13.96it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [00:23<00:01, 13.94it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [00:24<00:01, 13.93it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [00:24<00:00, 13.93it/s]\u001b[AI1014 18:45:08.052228 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1550/config.json\n",
      "I1014 18:45:09.622029 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1550/pytorch_model.bin\n",
      "I1014 18:45:09.626458 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1550\n",
      "\n",
      "Iteration:  96%|█████████▌| 250/260 [00:25<00:03,  3.24it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [00:26<00:01,  4.20it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [00:26<00:01,  5.30it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [00:26<00:00,  6.53it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [00:26<00:00,  7.79it/s]\u001b[A\n",
      "Epoch:  60%|██████    | 6/10 [02:37<01:46, 26.50s/it]09it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<00:18, 14.31it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:00<00:17, 14.26it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:00<00:17, 14.23it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:00<00:17, 14.21it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:00<00:17, 14.19it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:00<00:17, 14.19it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:00<00:17, 14.18it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:01<00:17, 14.17it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:01<00:17, 14.17it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:01<00:16, 14.16it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:01<00:16, 14.15it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:01<00:16, 14.08it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:01<00:16, 14.11it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:01<00:16, 14.13it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:02<00:16, 14.09it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:02<00:16, 14.04it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:02<00:16, 14.00it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:02<00:15, 14.05it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:02<00:15, 14.06it/s]\u001b[AI1014 18:45:13.182232 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1600/config.json\n",
      "I1014 18:45:14.739224 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1600/pytorch_model.bin\n",
      "I1014 18:45:14.743753 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1600\n",
      "\n",
      "Iteration:  15%|█▌        | 40/260 [00:04<01:07,  3.26it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:04<00:51,  4.24it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:04<00:40,  5.37it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:04<00:32,  6.59it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:04<00:27,  7.83it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:05<00:23,  9.04it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:05<00:20, 10.14it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:05<00:18, 11.09it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:05<00:17, 11.86it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:05<00:16, 12.42it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:05<00:15, 12.90it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:05<00:15, 13.13it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:06<00:14, 13.42it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:06<00:14, 13.64it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:06<00:13, 13.80it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:06<00:13, 13.91it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:06<00:13, 13.99it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:06<00:13, 13.98it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:06<00:13, 13.96it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:07<00:12, 14.02it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:07<00:12, 14.02it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:07<00:12, 14.06it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:07<00:12, 14.09it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:07<00:12, 14.04it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:07<00:12, 14.00it/s]\u001b[AI1014 18:45:18.303474 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1650/config.json\n",
      "I1014 18:45:19.856382 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1650/pytorch_model.bin\n",
      "I1014 18:45:19.860774 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1650\n",
      "\n",
      "Iteration:  35%|███▍      | 90/260 [00:09<00:51,  3.27it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:09<00:39,  4.25it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:09<00:30,  5.36it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:09<00:24,  6.58it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:10<00:20,  7.79it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:10<00:17,  9.00it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:10<00:15, 10.11it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:10<00:14, 11.06it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:10<00:13, 11.79it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:10<00:12, 12.36it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:10<00:11, 12.74it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:11<00:11, 13.06it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:11<00:10, 13.31it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:11<00:10, 13.55it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:11<00:10, 13.63it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:11<00:10, 13.79it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:11<00:09, 13.91it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:11<00:09, 13.97it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:12<00:09, 14.01it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:12<00:09, 14.04it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:12<00:09, 13.98it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:12<00:09, 13.98it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:12<00:09, 13.95it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:12<00:08, 13.90it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:12<00:08, 13.95it/s]\u001b[AI1014 18:45:23.439412 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1700/config.json\n",
      "I1014 18:45:25.001921 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1700/pytorch_model.bin\n",
      "I1014 18:45:25.007199 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1700\n",
      "\n",
      "Iteration:  54%|█████▍    | 140/260 [00:14<00:36,  3.25it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:14<00:27,  4.22it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:14<00:21,  5.34it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:15<00:17,  6.56it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:15<00:14,  7.82it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:15<00:12,  8.96it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:15<00:10, 10.02it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:15<00:09, 10.93it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:15<00:08, 11.71it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:15<00:08, 12.34it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:16<00:07, 12.76it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:16<00:07, 13.12it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:16<00:07, 13.33it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:16<00:06, 13.48it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:16<00:06, 13.59it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:16<00:06, 13.67it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:16<00:06, 13.80it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:17<00:06, 13.81it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:17<00:06, 13.82it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:17<00:05, 13.83it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:17<00:05, 13.78it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:17<00:05, 13.86it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:17<00:05, 13.87it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:17<00:05, 13.89it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:18<00:05, 13.97it/s]\u001b[AI1014 18:45:28.603195 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1750/config.json\n",
      "I1014 18:45:30.107164 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1750/pytorch_model.bin\n",
      "I1014 18:45:30.110779 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1750\n",
      "\n",
      "Iteration:  73%|███████▎  | 190/260 [00:19<00:20,  3.35it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:19<00:15,  4.34it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:20<00:12,  5.47it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:20<00:09,  6.69it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:20<00:07,  7.95it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:20<00:06,  9.10it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:20<00:05, 10.20it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:20<00:05, 11.09it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:20<00:04, 11.77it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:21<00:04, 12.34it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [00:21<00:03, 12.85it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [00:21<00:03, 13.16it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [00:21<00:03, 13.39it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [00:21<00:03, 13.62it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [00:21<00:03, 13.79it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [00:21<00:02, 13.83it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [00:22<00:02, 13.86it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [00:22<00:02, 13.96it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [00:22<00:02, 13.96it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [00:22<00:02, 14.03it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [00:22<00:02, 14.00it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [00:22<00:02, 13.98it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [00:22<00:01, 13.91it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [00:23<00:01, 13.92it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [00:23<00:01, 13.93it/s]\u001b[AI1014 18:45:33.690024 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1800/config.json\n",
      "I1014 18:45:35.047732 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1800/pytorch_model.bin\n",
      "I1014 18:45:35.052134 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1800\n",
      "\n",
      "Iteration:  92%|█████████▏| 240/260 [00:24<00:05,  3.61it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [00:24<00:03,  4.63it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [00:25<00:02,  5.79it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [00:25<00:01,  7.04it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [00:25<00:01,  8.29it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [00:25<00:01,  9.43it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [00:25<00:00, 10.48it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [00:25<00:00, 11.37it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [00:25<00:00, 12.03it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [00:25<00:00, 12.60it/s]\u001b[A\n",
      "Epoch:  70%|███████   | 7/10 [03:03<01:19, 26.39s/it]28it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<00:18, 14.05it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:00<00:18, 13.94it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:00<00:18, 14.01it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:00<00:17, 14.05it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:00<00:17, 14.08it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:00<00:17, 14.04it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:00<00:17, 14.07it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:01<00:17, 14.03it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:01<00:17, 13.99it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:01<00:17, 14.04it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:01<00:16, 14.07it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:01<00:16, 14.10it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:01<00:16, 14.11it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:01<00:16, 14.13it/s]\u001b[AI1014 18:45:38.613649 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1850/config.json\n",
      "I1014 18:45:39.991151 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1850/pytorch_model.bin\n",
      "I1014 18:45:39.995799 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1850\n",
      "\n",
      "Iteration:  12%|█▏        | 30/260 [00:03<01:04,  3.58it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:03<00:49,  4.62it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:03<00:39,  5.79it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:03<00:31,  7.04it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:04<00:26,  8.30it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:04<00:23,  9.49it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:04<00:20, 10.55it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:04<00:18, 11.45it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:04<00:17, 12.12it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:04<00:16, 12.65it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:04<00:16, 13.11it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:05<00:15, 13.38it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:05<00:15, 13.58it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:05<00:14, 13.72it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:05<00:14, 13.89it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:05<00:14, 14.00it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:05<00:14, 13.98it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:05<00:13, 14.05it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:06<00:13, 14.02it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:06<00:13, 14.08it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:06<00:13, 14.11it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:06<00:13, 14.07it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:06<00:13, 14.12it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:06<00:13, 14.15it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  30%|███       | 78/260 [00:06<00:12, 14.17it/s]\u001b[AI1014 18:45:43.532794 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1900/config.json\n",
      "I1014 18:45:44.918318 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1900/pytorch_model.bin\n",
      "I1014 18:45:44.923607 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1900\n",
      "\n",
      "Iteration:  31%|███       | 80/260 [00:08<00:50,  3.57it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:08<00:38,  4.58it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:08<00:30,  5.75it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:08<00:24,  7.00it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:09<00:20,  8.25it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:09<00:18,  9.40it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:09<00:16, 10.47it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:09<00:14, 11.38it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:09<00:13, 12.06it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:09<00:12, 12.58it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:09<00:12, 13.05it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:10<00:11, 13.34it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:10<00:11, 13.65it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:10<00:11, 13.88it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:10<00:10, 14.00it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:10<00:10, 14.08it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:10<00:10, 14.11it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:10<00:10, 14.07it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:10<00:10, 14.13it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:11<00:10, 14.18it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:11<00:09, 14.14it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:11<00:09, 14.18it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:11<00:09, 14.21it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:11<00:09, 14.24it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:11<00:09, 14.18it/s]\u001b[AI1014 18:45:48.457739 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-1950/config.json\n",
      "I1014 18:45:49.834500 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-1950/pytorch_model.bin\n",
      "I1014 18:45:49.840126 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-1950\n",
      "\n",
      "Iteration:  50%|█████     | 130/260 [00:13<00:36,  3.59it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:13<00:27,  4.62it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:13<00:21,  5.79it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:13<00:17,  7.01it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:13<00:14,  8.25it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:14<00:12,  9.45it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:14<00:11, 10.52it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:14<00:10, 11.43it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:14<00:09, 12.10it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:14<00:08, 12.66it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:14<00:08, 13.08it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:14<00:08, 13.36it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:15<00:07, 13.63it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:15<00:07, 13.76it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:15<00:07, 13.84it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:15<00:07, 13.97it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:15<00:06, 14.06it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:15<00:06, 14.13it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:15<00:06, 14.18it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:16<00:06, 14.21it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:16<00:06, 14.24it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:16<00:06, 14.19it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:16<00:06, 14.15it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:16<00:05, 14.12it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:16<00:05, 14.17it/s]\u001b[AI1014 18:45:53.377533 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2000/config.json\n",
      "I1014 18:45:54.751552 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2000/pytorch_model.bin\n",
      "I1014 18:45:54.756364 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2000\n",
      "\n",
      "Iteration:  69%|██████▉   | 180/260 [00:18<00:22,  3.59it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:18<00:16,  4.62it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:18<00:13,  5.77it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:18<00:10,  7.02it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:18<00:08,  8.26it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:18<00:07,  9.43it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:19<00:06, 10.47it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:19<00:05, 11.30it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:19<00:05, 12.02it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:19<00:04, 12.52it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:19<00:04, 12.92it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:19<00:04, 13.26it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:19<00:04, 13.51it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:20<00:03, 13.65it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:20<00:03, 13.78it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [00:20<00:03, 13.87it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [00:20<00:03, 13.87it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [00:20<00:03, 13.93it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [00:20<00:03, 13.98it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [00:20<00:03, 13.94it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [00:21<00:02, 13.99it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [00:21<00:02, 13.95it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [00:21<00:02, 14.00it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [00:21<00:02, 14.02it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [00:21<00:02, 14.06it/s]\u001b[AI1014 18:45:58.325400 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2050/config.json\n",
      "I1014 18:45:59.714867 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2050/pytorch_model.bin\n",
      "I1014 18:45:59.719080 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2050\n",
      "\n",
      "Iteration:  88%|████████▊ | 230/260 [00:23<00:08,  3.56it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [00:23<00:06,  4.59it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [00:23<00:04,  5.75it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [00:23<00:03,  7.01it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [00:23<00:02,  8.27it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [00:23<00:02,  9.46it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [00:24<00:01, 10.48it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [00:24<00:01, 11.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [00:24<00:01, 12.11it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [00:24<00:00, 12.61it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [00:24<00:00, 13.07it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [00:24<00:00, 13.30it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [00:24<00:00, 13.54it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [00:25<00:00, 13.71it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [00:25<00:00, 13.77it/s]\u001b[A\n",
      "Epoch:  80%|████████  | 8/10 [03:28<00:52, 26.08s/it]15it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<00:18, 14.23it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:00<00:18, 14.20it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:00<00:17, 14.20it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:00<00:17, 14.22it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 10/260 [00:00<00:17, 14.21it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:00<00:17, 14.23it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:00<00:17, 14.22it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:01<00:17, 14.22it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:01<00:17, 14.23it/s]\u001b[AI1014 18:46:03.250852 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2100/config.json\n",
      "I1014 18:46:04.635780 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2100/pytorch_model.bin\n",
      "I1014 18:46:04.640567 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2100\n",
      "\n",
      "Iteration:   8%|▊         | 20/260 [00:02<01:07,  3.58it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:02<00:51,  4.60it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:03<00:40,  5.77it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:03<00:33,  7.00it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:03<00:28,  8.26it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:03<00:24,  9.42it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:03<00:21, 10.48it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:03<00:19, 11.38it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:03<00:18, 12.12it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:04<00:17, 12.69it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:04<00:16, 13.02it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:04<00:16, 13.35it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:04<00:15, 13.57it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:04<00:15, 13.72it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:04<00:15, 13.76it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:04<00:15, 13.90it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:05<00:14, 13.93it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:05<00:14, 14.02it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:05<00:14, 14.08it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:05<00:14, 14.10it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 60/260 [00:05<00:14, 14.14it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:05<00:13, 14.16it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:05<00:13, 14.19it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:06<00:13, 14.20it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:06<00:13, 14.21it/s]\u001b[AI1014 18:46:08.183188 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2150/config.json\n",
      "I1014 18:46:09.563996 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2150/pytorch_model.bin\n",
      "I1014 18:46:09.569156 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2150\n",
      "\n",
      "Iteration:  27%|██▋       | 70/260 [00:07<00:53,  3.58it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:07<00:40,  4.61it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:08<00:32,  5.78it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:08<00:26,  7.03it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:08<00:21,  8.29it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:08<00:18,  9.48it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:08<00:16, 10.51it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:08<00:15, 11.36it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:08<00:14, 12.09it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:09<00:13, 12.66it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:09<00:12, 13.08it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:09<00:12, 13.42it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:09<00:12, 13.62it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:09<00:11, 13.77it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:09<00:11, 13.88it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:09<00:11, 13.89it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:09<00:11, 13.97it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:10<00:11, 14.02it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:10<00:10, 14.09it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:10<00:10, 14.14it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 110/260 [00:10<00:10, 14.16it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:10<00:10, 14.19it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:10<00:10, 14.14it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:10<00:10, 14.17it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:11<00:10, 14.17it/s]\u001b[AI1014 18:46:13.105017 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2200/config.json\n",
      "I1014 18:46:14.479650 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2200/pytorch_model.bin\n",
      "I1014 18:46:14.484717 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2200\n",
      "\n",
      "Iteration:  46%|████▌     | 120/260 [00:12<00:38,  3.59it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:12<00:29,  4.63it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:12<00:23,  5.79it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:13<00:19,  7.02it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:13<00:15,  8.25it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:13<00:13,  9.45it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:13<00:12, 10.52it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:13<00:11, 11.42it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:13<00:10, 12.15it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:13<00:09, 12.70it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:14<00:09, 13.11it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:14<00:08, 13.41it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:14<00:08, 13.48it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:14<00:08, 13.68it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:14<00:08, 13.84it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:14<00:07, 13.99it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:14<00:07, 14.00it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:15<00:07, 14.08it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:15<00:07, 14.13it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:15<00:07, 14.09it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 160/260 [00:15<00:07, 14.15it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:15<00:06, 14.11it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:15<00:06, 14.08it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:15<00:06, 14.13it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:16<00:06, 14.17it/s]\u001b[AI1014 18:46:18.025763 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2250/config.json\n",
      "I1014 18:46:19.412929 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2250/pytorch_model.bin\n",
      "I1014 18:46:19.417637 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2250\n",
      "\n",
      "Iteration:  65%|██████▌   | 170/260 [00:17<00:25,  3.57it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:17<00:19,  4.60it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:17<00:14,  5.75it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:18<00:12,  6.99it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:18<00:09,  8.22it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:18<00:08,  9.40it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:18<00:07, 10.45it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:18<00:06, 11.29it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:18<00:06, 12.01it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:18<00:05, 12.58it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:19<00:05, 12.98it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:19<00:05, 13.31it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:19<00:04, 13.55it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:19<00:04, 13.72it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:19<00:04, 13.84it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:19<00:04, 13.93it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:19<00:04, 13.99it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:19<00:03, 14.03it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:20<00:03, 14.06it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:20<00:03, 14.08it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 210/260 [00:20<00:03, 14.10it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [00:20<00:03, 14.11it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [00:20<00:03, 14.11it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [00:20<00:03, 14.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  84%|████████▍ | 218/260 [00:20<00:02, 14.13it/s]\u001b[AI1014 18:46:22.971063 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2300/config.json\n",
      "I1014 18:46:24.353339 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2300/pytorch_model.bin\n",
      "I1014 18:46:24.357234 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2300\n",
      "\n",
      "Iteration:  85%|████████▍ | 220/260 [00:22<00:11,  3.58it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [00:22<00:08,  4.61it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [00:22<00:06,  5.77it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [00:22<00:04,  7.02it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [00:23<00:03,  8.27it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [00:23<00:03,  9.44it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [00:23<00:02, 10.49it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [00:23<00:02, 11.37it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [00:23<00:01, 12.08it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [00:23<00:01, 12.63it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [00:23<00:01, 12.98it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [00:24<00:01, 13.24it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [00:24<00:01, 13.44it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [00:24<00:01, 13.64it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [00:24<00:00, 13.79it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [00:24<00:00, 13.88it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [00:24<00:00, 13.96it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [00:24<00:00, 13.93it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [00:25<00:00, 13.99it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [00:25<00:00, 13.96it/s]\u001b[A\n",
      "Epoch:  90%|█████████ | 9/10 [03:54<00:25, 25.87s/it]29it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/260 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1%|          | 2/260 [00:00<00:18, 14.24it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 4/260 [00:00<00:18, 14.20it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 6/260 [00:00<00:17, 14.19it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 8/260 [00:00<00:17, 14.11it/s]\u001b[AI1014 18:46:27.910062 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2350/config.json\n",
      "I1014 18:46:29.293092 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2350/pytorch_model.bin\n",
      "I1014 18:46:29.297619 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2350\n",
      "\n",
      "Iteration:   4%|▍         | 10/260 [00:02<01:09,  3.58it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 12/260 [00:02<00:53,  4.60it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 14/260 [00:02<00:42,  5.77it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 16/260 [00:02<00:34,  7.02it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 18/260 [00:02<00:29,  8.28it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 20/260 [00:02<00:25,  9.45it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 22/260 [00:02<00:22, 10.45it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 24/260 [00:03<00:20, 11.34it/s]\u001b[A\n",
      "Iteration:  10%|█         | 26/260 [00:03<00:19, 12.06it/s]\u001b[A\n",
      "Iteration:  11%|█         | 28/260 [00:03<00:18, 12.64it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 30/260 [00:03<00:17, 13.09it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 32/260 [00:03<00:17, 13.41it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 34/260 [00:03<00:16, 13.65it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 36/260 [00:03<00:16, 13.80it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 38/260 [00:04<00:16, 13.79it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 40/260 [00:04<00:15, 13.92it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 42/260 [00:04<00:15, 13.95it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 44/260 [00:04<00:15, 14.03it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 46/260 [00:04<00:15, 14.10it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 48/260 [00:04<00:15, 14.11it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 50/260 [00:04<00:14, 14.24it/s]\u001b[A\n",
      "Iteration:  20%|██        | 52/260 [00:05<00:14, 14.34it/s]\u001b[A\n",
      "Iteration:  21%|██        | 54/260 [00:05<00:14, 14.41it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 56/260 [00:05<00:14, 14.44it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 58/260 [00:05<00:13, 14.47it/s]\u001b[AI1014 18:46:32.817659 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2400/config.json\n",
      "I1014 18:46:34.183488 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2400/pytorch_model.bin\n",
      "I1014 18:46:34.187876 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2400\n",
      "\n",
      "Iteration:  23%|██▎       | 60/260 [00:06<00:55,  3.63it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 62/260 [00:07<00:42,  4.67it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 64/260 [00:07<00:33,  5.85it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 66/260 [00:07<00:27,  7.11it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 68/260 [00:07<00:22,  8.39it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 70/260 [00:07<00:19,  9.61it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 72/260 [00:07<00:17, 10.70it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 74/260 [00:07<00:15, 11.63it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 76/260 [00:08<00:14, 12.37it/s]\u001b[A\n",
      "Iteration:  30%|███       | 78/260 [00:08<00:14, 12.95it/s]\u001b[A\n",
      "Iteration:  31%|███       | 80/260 [00:08<00:13, 13.39it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 82/260 [00:08<00:12, 13.71it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 84/260 [00:08<00:12, 13.94it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 86/260 [00:08<00:12, 14.13it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 88/260 [00:08<00:12, 14.26it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 90/260 [00:09<00:11, 14.36it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 92/260 [00:09<00:11, 14.43it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 94/260 [00:09<00:11, 14.48it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 96/260 [00:09<00:11, 14.45it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 98/260 [00:09<00:11, 14.47it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 100/260 [00:09<00:11, 14.52it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 102/260 [00:09<00:10, 14.47it/s]\u001b[A\n",
      "Iteration:  40%|████      | 104/260 [00:10<00:10, 14.51it/s]\u001b[A\n",
      "Iteration:  41%|████      | 106/260 [00:10<00:10, 14.54it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 108/260 [00:10<00:10, 14.42it/s]\u001b[AI1014 18:46:37.644525 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2450/config.json\n",
      "I1014 18:46:39.012987 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2450/pytorch_model.bin\n",
      "I1014 18:46:39.017945 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2450\n",
      "\n",
      "Iteration:  42%|████▏     | 110/260 [00:11<00:41,  3.62it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 112/260 [00:11<00:31,  4.67it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 114/260 [00:12<00:24,  5.87it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 116/260 [00:12<00:20,  7.14it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 118/260 [00:12<00:16,  8.41it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 120/260 [00:12<00:14,  9.64it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 122/260 [00:12<00:12, 10.73it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 124/260 [00:12<00:11, 11.66it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 126/260 [00:12<00:10, 12.35it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 128/260 [00:13<00:10, 12.95it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 130/260 [00:13<00:09, 13.41it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 132/260 [00:13<00:09, 13.74it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 134/260 [00:13<00:09, 13.98it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 136/260 [00:13<00:08, 14.15it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 138/260 [00:13<00:08, 14.28it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 140/260 [00:13<00:08, 14.36it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 142/260 [00:14<00:08, 14.42it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 144/260 [00:14<00:08, 14.47it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 146/260 [00:14<00:07, 14.50it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 148/260 [00:14<00:07, 14.53it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 150/260 [00:14<00:07, 14.46it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 152/260 [00:14<00:07, 14.28it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 154/260 [00:14<00:07, 14.28it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 156/260 [00:14<00:07, 14.37it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 158/260 [00:15<00:07, 14.42it/s]\u001b[AI1014 18:46:42.477607 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2500/config.json\n",
      "I1014 18:46:43.833708 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2500/pytorch_model.bin\n",
      "I1014 18:46:43.838598 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2500\n",
      "\n",
      "Iteration:  62%|██████▏   | 160/260 [00:16<00:27,  3.64it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 162/260 [00:16<00:20,  4.67it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 164/260 [00:16<00:16,  5.87it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 166/260 [00:17<00:13,  7.14it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 168/260 [00:17<00:10,  8.43it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 170/260 [00:17<00:09,  9.65it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 172/260 [00:17<00:08, 10.74it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 174/260 [00:17<00:07, 11.66it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 176/260 [00:17<00:06, 12.41it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 178/260 [00:17<00:06, 12.98it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 180/260 [00:18<00:05, 13.42it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 182/260 [00:18<00:05, 13.74it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 184/260 [00:18<00:05, 13.98it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 186/260 [00:18<00:05, 14.08it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 188/260 [00:18<00:05, 14.22it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 190/260 [00:18<00:04, 14.30it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 192/260 [00:18<00:04, 14.38it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 194/260 [00:18<00:04, 14.45it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 196/260 [00:19<00:04, 14.50it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 198/260 [00:19<00:04, 14.53it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 200/260 [00:19<00:04, 14.54it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 202/260 [00:19<00:03, 14.56it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 204/260 [00:19<00:03, 14.58it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 206/260 [00:19<00:03, 14.58it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 208/260 [00:19<00:03, 14.50it/s]\u001b[AI1014 18:46:47.289795 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2550/config.json\n",
      "I1014 18:46:48.661992 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2550/pytorch_model.bin\n",
      "I1014 18:46:48.667471 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2550\n",
      "\n",
      "Iteration:  81%|████████  | 210/260 [00:21<00:13,  3.61it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 212/260 [00:21<00:10,  4.66it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 214/260 [00:21<00:07,  5.85it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 216/260 [00:21<00:06,  7.13it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 218/260 [00:22<00:05,  8.37it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 220/260 [00:22<00:04,  9.60it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 222/260 [00:22<00:03, 10.69it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 224/260 [00:22<00:03, 11.61it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 226/260 [00:22<00:02, 12.32it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 228/260 [00:22<00:02, 12.88it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 230/260 [00:22<00:02, 13.35it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 232/260 [00:22<00:02, 13.71it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 234/260 [00:23<00:01, 13.93it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 236/260 [00:23<00:01, 14.11it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 238/260 [00:23<00:01, 14.25it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 240/260 [00:23<00:01, 14.33it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 242/260 [00:23<00:01, 14.39it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 244/260 [00:23<00:01, 14.44it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 246/260 [00:23<00:00, 14.49it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 248/260 [00:24<00:00, 14.51it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 250/260 [00:24<00:00, 14.51it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 252/260 [00:24<00:00, 14.51it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 254/260 [00:24<00:00, 14.51it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 256/260 [00:24<00:00, 14.51it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 258/260 [00:24<00:00, 14.39it/s]\u001b[AI1014 18:46:52.117783 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/checkpoint-2600/config.json\n",
      "I1014 18:46:53.498138 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/checkpoint-2600/pytorch_model.bin\n",
      "I1014 18:46:53.506762 47346561829312 <ipython-input-13-ce0a3a7e9c33>:107] Saving model checkpoint to bert_output_mutlilingual_cased/checkpoint-2600\n",
      "\n",
      "Epoch: 100%|██████████| 10/10 [04:20<00:00, 26.00s/it]0it/s]\u001b[A\n",
      "I1014 18:46:53.512391 47346561829312 <ipython-input-18-fb4439387059>:148]  global_step = 2600, average loss = 0.10242143964860588\n",
      "I1014 18:46:53.513125 47346561829312 <ipython-input-18-fb4439387059>:157] Saving model checkpoint to bert_output_mutlilingual_cased\n",
      "I1014 18:46:53.517918 47346561829312 configuration_utils.py:70] Configuration saved in bert_output_mutlilingual_cased/config.json\n",
      "I1014 18:46:54.891410 47346561829312 modeling_utils.py:205] Model weights saved in bert_output_mutlilingual_cased/pytorch_model.bin\n",
      "I1014 18:46:55.041242 47346561829312 configuration_utils.py:148] loading configuration file bert_output_mutlilingual_cased/config.json\n",
      "I1014 18:46:55.042875 47346561829312 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "I1014 18:46:55.044242 47346561829312 modeling_utils.py:334] loading weights file bert_output_mutlilingual_cased/pytorch_model.bin\n",
      "I1014 18:46:59.513608 47346561829312 tokenization_utils.py:306] Model name 'bert_output_mutlilingual_cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_output_mutlilingual_cased' is a path or url to a directory containing tokenizer files.\n",
      "I1014 18:46:59.515400 47346561829312 tokenization_utils.py:370] loading file bert_output_mutlilingual_cased/vocab.txt\n",
      "I1014 18:46:59.516129 47346561829312 tokenization_utils.py:370] loading file bert_output_mutlilingual_cased/added_tokens.json\n",
      "I1014 18:46:59.516815 47346561829312 tokenization_utils.py:370] loading file bert_output_mutlilingual_cased/special_tokens_map.json\n",
      "I1014 18:46:59.517468 47346561829312 tokenization_utils.py:370] loading file bert_output_mutlilingual_cased/tokenizer_config.json\n",
      "I1014 18:46:59.936461 47346561829312 tokenization_utils.py:306] Model name 'bert_output_mutlilingual_cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_output_mutlilingual_cased' is a path or url to a directory containing tokenizer files.\n",
      "I1014 18:46:59.938013 47346561829312 tokenization_utils.py:370] loading file bert_output_mutlilingual_cased/vocab.txt\n",
      "I1014 18:46:59.938705 47346561829312 tokenization_utils.py:370] loading file bert_output_mutlilingual_cased/added_tokens.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1014 18:46:59.939364 47346561829312 tokenization_utils.py:370] loading file bert_output_mutlilingual_cased/special_tokens_map.json\n",
      "I1014 18:46:59.940014 47346561829312 tokenization_utils.py:370] loading file bert_output_mutlilingual_cased/tokenizer_config.json\n",
      "I1014 18:47:00.181553 47346561829312 <ipython-input-18-fb4439387059>:181] Evaluate the following checkpoints: ['bert_output_mutlilingual_cased']\n",
      "I1014 18:47:00.183044 47346561829312 configuration_utils.py:148] loading configuration file bert_output_mutlilingual_cased/config.json\n",
      "I1014 18:47:00.184162 47346561829312 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "I1014 18:47:00.185470 47346561829312 modeling_utils.py:334] loading weights file bert_output_mutlilingual_cased/pytorch_model.bin\n",
      "I1014 18:47:04.684628 47346561829312 <ipython-input-16-5385282ede45>:15] Loading features from cached file dataset/0/cached_dev_bert-base-multilingual-uncased_128_frame\n",
      "I1014 18:47:04.693774 47346561829312 <ipython-input-15-b336438098bc>:19] ***** Running evaluation  *****\n",
      "I1014 18:47:04.694604 47346561829312 <ipython-input-15-b336438098bc>:20]   Num examples = 263\n",
      "I1014 18:47:04.695324 47346561829312 <ipython-input-15-b336438098bc>:21]   Batch size = 8\n",
      "Evaluating: 100%|██████████| 33/33 [00:00<00:00, 42.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape:  (263, 9)\n",
      "out label ids:  (263, 9)\n",
      "[[0.01423015 0.02182806 0.06950232 0.7868451  0.14007674 0.01471578\n",
      "  0.00524659 0.02217446 0.00773888]\n",
      " [0.01215458 0.01103574 0.00603635 0.05186746 0.048393   0.97418106\n",
      "  0.04332058 0.04945757 0.01418138]\n",
      " [0.01507436 0.0082345  0.01210421 0.78430957 0.08987287 0.01107814\n",
      "  0.0261486  0.03306131 0.01354449]\n",
      " [0.02113908 0.0259786  0.01688389 0.92976    0.04313533 0.02356634\n",
      "  0.01978928 0.04160449 0.0179706 ]\n",
      " [0.00838097 0.00616693 0.02063526 0.00827147 0.0604271  0.9323913\n",
      "  0.06060061 0.01141125 0.01471036]]\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]]\n",
      "length:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1014 18:47:05.810430 47346561829312 <ipython-input-15-b336438098bc>:82] ***** Eval results  *****\n",
      "I1014 18:47:05.811176 47346561829312 <ipython-input-15-b336438098bc>:84]   auc = 0.9512310977305601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.9512310977305601}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc_': 0.9512310977305601}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multi lingual uncased\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1014 14:05:49.849627 47925521336768 <ipython-input-15-fb4439387059>:110] Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "I1014 14:05:49.949977 47925521336768 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /usr4/cs591/akyurek/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I1014 14:05:49.951650 47925521336768 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I1014 14:05:50.084694 47925521336768 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /usr4/cs591/akyurek/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "I1014 14:05:50.213910 47925521336768 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /usr4/cs591/akyurek/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "I1014 14:05:53.135619 47925521336768 modeling_utils.py:405] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1014 14:05:53.137409 47925521336768 modeling_utils.py:408] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1014 14:05:53.213803 47925521336768 <ipython-input-15-fb4439387059>:141] Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='dataset/0', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-cased', model_type='bertmultilabel', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='bert_output', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, save_steps=50, seed=42, server_ip='', server_port='', task_name='frame', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "I1014 14:05:53.215255 47925521336768 tokenization_utils.py:306] Model name 'bert_output' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'bert_output' is a path or url to a directory containing tokenizer files.\n",
      "I1014 14:05:53.217195 47925521336768 tokenization_utils.py:370] loading file bert_output/vocab.txt\n",
      "I1014 14:05:53.217900 47925521336768 tokenization_utils.py:370] loading file bert_output/added_tokens.json\n",
      "I1014 14:05:53.218630 47925521336768 tokenization_utils.py:370] loading file bert_output/special_tokens_map.json\n",
      "I1014 14:05:53.219337 47925521336768 tokenization_utils.py:370] loading file bert_output/tokenizer_config.json\n",
      "I1014 14:05:53.283475 47925521336768 <ipython-input-15-fb4439387059>:181] Evaluate the following checkpoints: ['bert_output']\n",
      "I1014 14:05:53.284802 47925521336768 configuration_utils.py:148] loading configuration file bert_output/config.json\n",
      "I1014 14:05:53.285980 47925521336768 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"frame\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I1014 14:05:53.287317 47925521336768 modeling_utils.py:334] loading weights file bert_output/pytorch_model.bin\n",
      "I1014 14:05:56.023650 47925521336768 <ipython-input-13-5385282ede45>:15] Loading features from cached file dataset/0/cached_dev_bert-base-cased_128_frame\n",
      "I1014 14:05:56.035111 47925521336768 <ipython-input-24-b336438098bc>:19] ***** Running evaluation  *****\n",
      "I1014 14:05:56.036190 47925521336768 <ipython-input-24-b336438098bc>:20]   Num examples = 263\n",
      "I1014 14:05:56.037070 47925521336768 <ipython-input-24-b336438098bc>:21]   Batch size = 8\n",
      "Evaluating: 100%|██████████| 33/33 [00:00<00:00, 42.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape:  (263, 9)\n",
      "out label ids:  (263, 9)\n",
      "[[0.00920546 0.0050703  0.8210223  0.49708992 0.08384976 0.01146775\n",
      "  0.00370745 0.043563   0.00552611]\n",
      " [0.01327827 0.01413584 0.02024557 0.02304885 0.03063032 0.9699369\n",
      "  0.02601531 0.03138949 0.01738443]\n",
      " [0.03360216 0.01113563 0.01220965 0.0251116  0.1388215  0.01353287\n",
      "  0.00809702 0.49573562 0.01237645]\n",
      " [0.00908147 0.0164304  0.01402232 0.60032433 0.60190356 0.02522935\n",
      "  0.00398023 0.03535081 0.00764521]\n",
      " [0.019145   0.01561153 0.02028489 0.01663143 0.03528612 0.9601685\n",
      "  0.02668507 0.01709183 0.01178133]]\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]]\n",
      "length:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1014 14:05:57.137552 47925521336768 <ipython-input-24-b336438098bc>:82] ***** Eval results  *****\n",
      "I1014 14:05:57.138645 47925521336768 <ipython-input-24-b336438098bc>:84]   auc = 0.948673714653332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.948673714653332}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc_': 0.948673714653332}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--do_lower_case=True\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frames(file, name):\n",
    "    df = pd.read_csv(file, sep='\\t', header=None)\n",
    "    df.columns = [\"guid\", \"text_a\", \"text_b\"] + [str(x+1) for x in range(9)]\n",
    "    return(df.iloc[:,3:].sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions_test = dict()\n",
    "distributions_train = dict()\n",
    "for i in range(5):\n",
    "    distributions_test[i] = count_frames(\"dataset/\"+str(i)+\"/dev.tsv\", \"test\")\n",
    "    distributions_train[i] = count_frames(\"dataset/\"+str(i)+\"/train.tsv\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test0</th>\n",
       "      <th>test1</th>\n",
       "      <th>test2</th>\n",
       "      <th>test3</th>\n",
       "      <th>test4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test0  test1  test2  test3  test4\n",
       "1   13.0   11.0   16.0   14.0   12.0\n",
       "2   65.0   62.0   61.0   67.0   67.0\n",
       "3   78.0   88.0   94.0   81.0   86.0\n",
       "4   16.0   18.0   16.0   15.0   15.0\n",
       "5   41.0   36.0   33.0   38.0   34.0\n",
       "6   27.0   28.0   29.0   26.0   24.0\n",
       "7   53.0   54.0   53.0   52.0   51.0\n",
       "8   11.0    9.0   11.0   10.0    9.0\n",
       "9   18.0   20.0   17.0   21.0   19.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dist_df = pd.DataFrame(distributions_test)\n",
    "test_dist_df.columns = [\"test\" + str(t) for t in test_dist_df.columns]\n",
    "test_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train0</th>\n",
       "      <th>train1</th>\n",
       "      <th>train2</th>\n",
       "      <th>train3</th>\n",
       "      <th>train4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>257.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>349.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>141.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>210.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train0  train1  train2  train3  train4\n",
       "1    53.0    55.0    50.0    52.0    54.0\n",
       "2   257.0   260.0   261.0   255.0   255.0\n",
       "3   349.0   339.0   333.0   346.0   341.0\n",
       "4    64.0    62.0    64.0    65.0    65.0\n",
       "5   141.0   146.0   149.0   144.0   148.0\n",
       "6   107.0   106.0   105.0   108.0   110.0\n",
       "7   210.0   209.0   210.0   211.0   212.0\n",
       "8    39.0    41.0    39.0    40.0    41.0\n",
       "9    77.0    75.0    78.0    74.0    76.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dist_df = pd.DataFrame(distributions_train)\n",
    "train_dist_df.columns = [\"train\" + str(t) for t in train_dist_df.columns]\n",
    "train_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train0</th>\n",
       "      <th>train1</th>\n",
       "      <th>train2</th>\n",
       "      <th>train3</th>\n",
       "      <th>train4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>257.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>349.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>141.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>210.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train0  train1  train2  train3  train4\n",
       "1    53.0    55.0    50.0    52.0    54.0\n",
       "2   257.0   260.0   261.0   255.0   255.0\n",
       "3   349.0   339.0   333.0   346.0   341.0\n",
       "4    64.0    62.0    64.0    65.0    65.0\n",
       "5   141.0   146.0   149.0   144.0   148.0\n",
       "6   107.0   106.0   105.0   108.0   110.0\n",
       "7   210.0   209.0   210.0   211.0   212.0\n",
       "8    39.0    41.0    39.0    40.0    41.0\n",
       "9    77.0    75.0    78.0    74.0    76.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test0  test1  test2  test3  test4  train0  train1  train2  train3  train4\n",
      "1   13.0   11.0   16.0   14.0   12.0    53.0    55.0    50.0    52.0    54.0\n",
      "2   65.0   62.0   61.0   67.0   67.0   257.0   260.0   261.0   255.0   255.0\n",
      "3   78.0   88.0   94.0   81.0   86.0   349.0   339.0   333.0   346.0   341.0\n",
      "4   16.0   18.0   16.0   15.0   15.0    64.0    62.0    64.0    65.0    65.0\n",
      "5   41.0   36.0   33.0   38.0   34.0   141.0   146.0   149.0   144.0   148.0\n",
      "6   27.0   28.0   29.0   26.0   24.0   107.0   106.0   105.0   108.0   110.0\n",
      "7   53.0   54.0   53.0   52.0   51.0   210.0   209.0   210.0   211.0   212.0\n",
      "8   11.0    9.0   11.0   10.0    9.0    39.0    41.0    39.0    40.0    41.0\n",
      "9   18.0   20.0   17.0   21.0   19.0    77.0    75.0    78.0    74.0    76.0\n"
     ]
    }
   ],
   "source": [
    "dists = pd.concat([test_dist_df, train_dist_df], axis=1)\n",
    "col_order = \n",
    "print(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Gun/2nd Amendment rights\n",
    "# 2 Gun control/regulation  \n",
    "# 3 Politics \n",
    "# 4 Mental health \n",
    "# 5 School or public space safety \n",
    "# 6 Race/ethnicity \n",
    "# 7 Public opinion\n",
    "# 8 Society/culture\n",
    "# 9 Economic consequences \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
