{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSTEPS:\\n1. Read english_omitted_words/dev.tsv\\n2. Split it into augmented (headlines whose words omitted) and original (intact headlines)\\n3. For a given frame X, find headlines s.t. gold frameX == True within augmented (indices)\\n4. Read scores \\n5. Get scores for which Step 3 holds among the augmented.\\n6. Get scores for the intact headlines.\\n7. Concat the scores that you get in Step 6 to the english.csv to match them to IDs.\\n8. Read the omitted data and left join the prediction scores to original data on ID.\\n9. Concat the scores obtained in Step 5 to Step 8. Calculate differences in scores.\\n10. Strip whitespaces in words. \\n11. Group by word and aggregate by mean.\\n12. Sort by mean.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "STEPS:\n",
    "1. Read english_omitted_words/dev.tsv\n",
    "2. Split it into augmented (headlines whose words omitted) and original (intact headlines)\n",
    "3. For a given frame X, find headlines s.t. gold frameX == True within augmented (indices)\n",
    "4. Read scores \n",
    "5. Get scores for which Step 3 holds among the augmented.\n",
    "6. Get scores for the intact headlines.\n",
    "7. Concat the scores that you get in Step 6 to the english.csv to match them to IDs.\n",
    "8. Read the omitted data and left join the prediction scores to original data on ID.\n",
    "9. Concat the scores obtained in Step 5 to Step 8. Calculate differences in scores.\n",
    "10. Strip whitespaces in words. \n",
    "11. Group by word and aggregate by mean.\n",
    "12. Sort by mean.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = pd.read_csv('english.csv')\n",
    "\n",
    "def omit_words(row):\n",
    "    orig_headline = row.news_title\n",
    "    orig_theme1 = row['Q3 Theme1']\n",
    "    orig_theme2 = row['Q3 Theme2']\n",
    "    orig_id = row.ID\n",
    "    \n",
    "    words = orig_headline.split(' ')\n",
    "    \n",
    "    new_data_points = []\n",
    "    for i, w in enumerate(words):\n",
    "        new_words = words[:i] + words[i+1:]\n",
    "        new_data_points.append((orig_id, w, orig_headline, ' '.join(new_words), \n",
    "                                orig_theme1, orig_theme2))\n",
    "    return new_data_points\n",
    "\n",
    "new_data = []\n",
    "for index, row in english.iterrows():\n",
    "    #returns list of tuples (ID, omitted_word, original_headline, \n",
    "    #omitted_headline, original_frame1, original_frame2)\n",
    "    new_data.extend(omit_words(row)) \n",
    "    \n",
    "augmented_english = pd.DataFrame(new_data)\n",
    "augmented_english.columns = ['ID', 'omitted_word', 'original_headline', \n",
    "                             'omitted_headline', 'theme1', 'theme2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"../multilabel_multibert_cased_focal3_omitted_words_zero_shot.pkl\"\n",
    "\n",
    "with open(exp_name, 'rb') as f:\n",
    "    results = pickle.load(f)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the predictions to the english dataset\n",
    "preds_for_english = pd.DataFrame(results[-1300:,], \n",
    "            index=english.index, \n",
    "            columns=['old_frame1', 'old_frame2', 'old_frame3', 'old_frame4', \n",
    "                     'old_frame5', 'old_frame6', 'old_frame7', 'old_frame8', 'old_frame9']\n",
    "        )\n",
    "english_with_preds = pd.concat([english, preds_for_english], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in range(9):\n",
    "    # create a df which only contains headlines that have frame from english_with_preds\n",
    "    cols = ['ID', \"old_frame\"+str(frame+1)]\n",
    "    condition = (english_with_preds['Q3 Theme1']==frame+1) | (english_with_preds['Q3 Theme2']==frame+1)\n",
    "    df = english_with_preds.loc[condition,cols]\n",
    "    # left join df to augmented english orig_pred_frame \n",
    "    augmented_english = augmented_english.merge(df, on='ID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15711"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(augmented_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results[:-1300,], \n",
    "            index=augmented_english.index, \n",
    "            columns=['new_frame1', 'new_frame2', 'new_frame3', 'new_frame4', \n",
    "                     'new_frame5', 'new_frame6', 'new_frame7', 'new_frame8', 'new_frame9']\n",
    "        )\n",
    "augmented_english = pd.concat([augmented_english, results_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in range(9):\n",
    "    old_col_name = \"old_frame\"+str(frame+1)\n",
    "    new_col_name = \"new_frame\"+str(frame+1)\n",
    "    diff_col_name = \"diff_frame\"+str(frame+1)\n",
    "    \n",
    "    augmented_english[diff_col_name] = augmented_english[old_col_name] - augmented_english[new_col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_english['omitted_word_clean'] = augmented_english['omitted_word'].str.strip().str.strip(\"’‘“”\"+string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words_by_frame(n, frame):\n",
    "    col_name = \"diff_frame\"+str(frame)\n",
    "    \n",
    "    return augmented_english[['omitted_word_clean', col_name]].dropna() \\\n",
    "    .groupby(['omitted_word_clean']) \\\n",
    "    .agg({col_name:'mean'}) \\\n",
    "    .sort_values(by=[col_name], ascending=False) \\\n",
    "    .head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in range(1,10):\n",
    "    get_top_n_words_by_frame(45, frame).to_csv('english_code_switch_words_omitting/frame'+str(frame)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([])\n",
    "for frame in range(1,10):\n",
    "    df = get_top_n_words_by_frame(45, frame)\n",
    "    df.reset_index(inplace=True)\n",
    "    s = pd.concat([s, df['omitted_word_clean']])\n",
    "#     words.extend(df['omitted_word_clean'].tolist())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_unique = sorted(s.unique(), key=str.casefold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('english_code_switch_words_omitting/combined_unique.csv', \n",
    "           words_unique, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COUNT THE CODE SWITCH WORDS IN THE TRAIN SET FOR ENGLISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words_prev_cs = []\n",
    "with open(\"turkish/CodeSwitched/english_words.txt\") as fp:\n",
    "    for line in fp:\n",
    "        english_words_prev_cs.append(line.strip())\n",
    "        \n",
    "english_words_new_cs = []\n",
    "with open(\"turkish/OmittedCodeSwitch/english_words.txt\") as fp:\n",
    "    for line in fp:\n",
    "        english_words_new_cs.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_words_prev_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_words_new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect = list(set(english_words_prev_cs) & set(english_words_new_cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "union = list(set(english_words_prev_cs) | set(english_words_new_cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(union) == len(english_words_prev_cs) + len(english_words_new_cs) - len(intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('union_english_words.txt', 'w') as f:\n",
    "    for item in sorted(union, key=str.casefold):\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>Cremated remains of Las Vegas mass shooter to ...</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>Florida shooter a troubled loner with white su...</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>Vernon Hills teen accused of wearing white sup...</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>Griffith student charged with accidentally bri...</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98</td>\n",
       "      <td>Exclusive: Group chat messages show school sho...</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1  2    3    4    5   \\\n",
       "0  36  Cremated remains of Las Vegas mass shooter to ...  a  0.0  0.0  0.0   \n",
       "1  47  Florida shooter a troubled loner with white su...  a  0.0  0.0  0.0   \n",
       "2  68  Vernon Hills teen accused of wearing white sup...  a  0.0  0.0  0.0   \n",
       "3  70  Griffith student charged with accidentally bri...  a  0.0  0.0  0.0   \n",
       "4  98  Exclusive: Group chat messages show school sho...  a  0.0  0.0  0.0   \n",
       "\n",
       "    6    7    8    9    10   11  \n",
       "0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "1  1.0  0.0  1.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "3  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "4  1.0  0.0  1.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"turkish/OmittedCodeSwitch/train-Copy1.tsv\", sep='\\t', header=None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in train[1]:\n",
    "    words = s.split(' ')\n",
    "    if \"'re\" in words or \"'s\" in words:\n",
    "        print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cremated remains of Las Vegas mass shooter to be kept in safe deposit box, brother says'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15711\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for sentence in train[1]:\n",
    "    for word in sentence.split(' '):\n",
    "        total += 1\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7522\n",
      "0.47877283431990325\n"
     ]
    }
   ],
   "source": [
    "word_count = 0\n",
    "for word in english_words_prev_cs:\n",
    "    for sentence in train[1]:\n",
    "        if word in sentence.split(' '):\n",
    "            word_count += 1\n",
    "\n",
    "print(word_count)\n",
    "print(word_count/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2121\n",
      "0.13500095474508306\n"
     ]
    }
   ],
   "source": [
    "word_count = 0\n",
    "for word in english_words_new_cs:\n",
    "    for sentence in train[1]:\n",
    "        if word in sentence.split(' '):\n",
    "            word_count += 1\n",
    "\n",
    "print(word_count)\n",
    "print(word_count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8139\n",
      "0.5180446820698873\n"
     ]
    }
   ],
   "source": [
    "word_count = 0\n",
    "for word in union:\n",
    "    for sentence in train[1]:\n",
    "        if word in sentence.split(' '):\n",
    "            word_count += 1\n",
    "\n",
    "print(word_count)\n",
    "print(word_count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "for sentence in train[1]:\n",
    "    for word in sentence.split(' '):\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] += 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_words = Counter({k: v for k, v in sorted(word_dict.items(), key=lambda item: item[1], reverse=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values = [v for k,v in sorted_words.most_common(358)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8349"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(top_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 429),\n",
       " ('gun', 331),\n",
       " ('of', 244),\n",
       " ('shooting', 239),\n",
       " ('in', 228),\n",
       " ('for', 210),\n",
       " ('the', 174),\n",
       " ('a', 164),\n",
       " ('on', 163),\n",
       " ('Gun', 134),\n",
       " ('Trump', 132),\n",
       " ('and', 129),\n",
       " ('NRA', 114),\n",
       " ('after', 97),\n",
       " ('Shooting', 95),\n",
       " ('school', 91),\n",
       " ('with', 90),\n",
       " ('at', 90),\n",
       " ('Florida', 89),\n",
       " ('Pittsburgh', 85),\n",
       " ('guns', 82),\n",
       " ('control', 80),\n",
       " ('Parkland', 76),\n",
       " ('synagogue', 63),\n",
       " ('says', 56),\n",
       " ('The', 56),\n",
       " ('as', 56),\n",
       " ('violence', 55),\n",
       " ('by', 55),\n",
       " ('School', 53),\n",
       " ('mass', 48),\n",
       " ('is', 48),\n",
       " ('After', 47),\n",
       " ('shootings', 41),\n",
       " ('students', 38),\n",
       " ('from', 36),\n",
       " ('over', 35),\n",
       " ('victims', 35),\n",
       " ('Vegas', 33),\n",
       " ('California', 33),\n",
       " ('police', 32),\n",
       " ('are', 32),\n",
       " ('that', 31),\n",
       " ('House', 31),\n",
       " ('man', 30),\n",
       " ('New', 30),\n",
       " ('shooter', 29),\n",
       " ('have', 29),\n",
       " ('shooting:', 29),\n",
       " ('Is', 29),\n",
       " ('A', 29),\n",
       " ('Guns', 29),\n",
       " ('not', 28),\n",
       " ('Jacksonville', 28),\n",
       " ('about', 28),\n",
       " ('To', 27),\n",
       " ('Synagogue', 27),\n",
       " ('laws', 27),\n",
       " ('new', 27),\n",
       " ('more', 27),\n",
       " ('be', 26),\n",
       " ('who', 26),\n",
       " ('Control', 26),\n",
       " ('black', 25),\n",
       " (\"Trump's\", 25),\n",
       " ('suspect', 24),\n",
       " ('In', 24),\n",
       " ('out', 24),\n",
       " ('With', 24),\n",
       " ('bill', 24),\n",
       " ('US', 23),\n",
       " ('people', 23),\n",
       " ('I', 22),\n",
       " ('Las', 21),\n",
       " ('White', 21),\n",
       " ('will', 21),\n",
       " ('3D', 21),\n",
       " ('How', 21),\n",
       " ('Amendment', 21),\n",
       " ('survivors', 21),\n",
       " ('gunman', 20),\n",
       " ('Students', 20),\n",
       " ('Texas', 20),\n",
       " ('schools', 20),\n",
       " ('Democrats', 20),\n",
       " ('Chicago', 20),\n",
       " ('but', 20),\n",
       " ('say', 19),\n",
       " ('Second', 19),\n",
       " ('it', 19),\n",
       " ('Kavanaugh', 19),\n",
       " ('ban', 19),\n",
       " ('weapons', 18),\n",
       " ('Police', 18),\n",
       " ('Video', 18),\n",
       " ('Of', 18),\n",
       " ('|', 18),\n",
       " ('Are', 18),\n",
       " ('governor', 18),\n",
       " ('their', 18),\n",
       " ('year', 18),\n",
       " ('safety', 18),\n",
       " ('has', 18),\n",
       " ('Donald', 18),\n",
       " ('What', 17),\n",
       " ('video', 17),\n",
       " ('Black', 17),\n",
       " ('shooting,', 17),\n",
       " ('—', 17),\n",
       " ('against', 17),\n",
       " ('calls', 17),\n",
       " ('call', 16),\n",
       " ('Says', 16),\n",
       " ('do', 16),\n",
       " ('For', 16),\n",
       " ('up', 16),\n",
       " ('3D-printed', 16),\n",
       " ('assault', 16),\n",
       " ('GOP', 16),\n",
       " ('he', 15),\n",
       " ('Shooter', 15),\n",
       " ('printed', 15),\n",
       " ('could', 15),\n",
       " ('blueprints', 15),\n",
       " ('teachers', 15),\n",
       " ('than', 15),\n",
       " ('during', 15),\n",
       " ('debate', 15),\n",
       " ('was', 14),\n",
       " ('Violence', 14),\n",
       " ('had', 14),\n",
       " ('This', 14),\n",
       " ('Santa', 14),\n",
       " ('America', 14),\n",
       " ('rights', 14),\n",
       " ('deadly', 14),\n",
       " ('student', 13),\n",
       " ('high', 13),\n",
       " ('About', 13),\n",
       " ('him', 13),\n",
       " ('mental', 13),\n",
       " ('online', 13),\n",
       " ('attack', 13),\n",
       " ('Why', 13),\n",
       " ('Judge', 13),\n",
       " ('take', 13),\n",
       " ('Fe', 13),\n",
       " ('rally', 13),\n",
       " ('Congress', 13),\n",
       " ('this', 13),\n",
       " ('stop', 13),\n",
       " ('Thousand', 13),\n",
       " ('Oaks', 13),\n",
       " ('Doctors', 13),\n",
       " ('groups', 13),\n",
       " ('lawmakers', 13),\n",
       " ('into', 13),\n",
       " ('group', 13),\n",
       " ('Mass', 13),\n",
       " ('teen', 12),\n",
       " ('Suspect', 12),\n",
       " ('an', 12),\n",
       " ('your', 12),\n",
       " ('Who', 12),\n",
       " ('Gunman', 12),\n",
       " ('court', 12),\n",
       " ('York', 12),\n",
       " ('U.S.', 12),\n",
       " ('Victims', 12),\n",
       " ('action', 12),\n",
       " ('On', 12),\n",
       " ('Shooting,', 12),\n",
       " ('honor', 12),\n",
       " ('Brett', 12),\n",
       " ('We', 12),\n",
       " ('show', 11),\n",
       " ('state', 11),\n",
       " ('law', 11),\n",
       " ('victim', 11),\n",
       " ('report', 11),\n",
       " ('He', 11),\n",
       " ('hate', 11),\n",
       " ('At', 11),\n",
       " ('states', 11),\n",
       " ('go', 11),\n",
       " (\"won't\", 11),\n",
       " ('sales', 11),\n",
       " ('Will', 11),\n",
       " ('support', 11),\n",
       " ('massacre', 11),\n",
       " ('Court', 11),\n",
       " ('should', 11),\n",
       " ('High', 11),\n",
       " ('protest', 11),\n",
       " ('killed', 11),\n",
       " ('white', 10),\n",
       " ('before', 10),\n",
       " ('kill', 10),\n",
       " ('Kentucky', 10),\n",
       " ('may', 10),\n",
       " ('11', 10),\n",
       " ('By', 10),\n",
       " ('-', 10),\n",
       " ('despite', 10),\n",
       " ('you', 10),\n",
       " ('Republican', 10),\n",
       " ('firearms', 10),\n",
       " ('community', 10),\n",
       " ('her', 10),\n",
       " ('want', 10),\n",
       " ('DeVos', 10),\n",
       " ('kids', 10),\n",
       " ('plan', 10),\n",
       " ('would', 10),\n",
       " ('control,', 10),\n",
       " ('wake', 10),\n",
       " ('charged', 9),\n",
       " ('Cruz', 9),\n",
       " ('his', 9),\n",
       " ('they', 9),\n",
       " ('It', 9),\n",
       " ('Kroger', 9),\n",
       " ('media', 9),\n",
       " ('As', 9),\n",
       " ('TheHill', 9),\n",
       " ('federal', 9),\n",
       " ('3-D', 9),\n",
       " ('Laws', 9),\n",
       " ('3D-Printed', 9),\n",
       " ('carry', 9),\n",
       " ('guns,', 9),\n",
       " ('Support', 9),\n",
       " ('why', 9),\n",
       " ('ad', 9),\n",
       " ('More', 9),\n",
       " ('&', 9),\n",
       " ('1', 9),\n",
       " ('back', 9),\n",
       " ('game', 9),\n",
       " ('Shootings', 9),\n",
       " ('News', 9),\n",
       " ('Dems', 9),\n",
       " ('measures', 9),\n",
       " ('Gov.', 9),\n",
       " ('gun-control', 9),\n",
       " ('reform', 9),\n",
       " ('Dem', 9),\n",
       " ('can', 9),\n",
       " ('Supreme', 9),\n",
       " ('Our', 9),\n",
       " ('loaded', 8),\n",
       " ('Man', 8),\n",
       " ('no', 8),\n",
       " ('FBI', 8),\n",
       " ('security', 8),\n",
       " ('Madden', 8),\n",
       " ('stand', 8),\n",
       " ('shoot', 8),\n",
       " ('found', 8),\n",
       " ('anti-Semitic', 8),\n",
       " ('Robert', 8),\n",
       " ('crime', 8),\n",
       " ('health', 8),\n",
       " ('if', 8),\n",
       " ('Have', 8),\n",
       " ('social', 8),\n",
       " ('Was', 8),\n",
       " ('help', 8),\n",
       " ('bar', 8),\n",
       " ('release', 8),\n",
       " ('selling', 8),\n",
       " ('judge', 8),\n",
       " ('Stop', 8),\n",
       " ('buy', 8),\n",
       " ('President', 8),\n",
       " ('Twitter', 8),\n",
       " ('Security', 8),\n",
       " ('Trump’s', 8),\n",
       " ('age', 8),\n",
       " ('lawmaker', 8),\n",
       " ('armed', 8),\n",
       " ('activists', 8),\n",
       " ('Governor', 8),\n",
       " (\"'We\", 8),\n",
       " ('signs', 8),\n",
       " ('meeting', 8),\n",
       " ('money', 8),\n",
       " (\"NRA's\", 8),\n",
       " ('we', 8),\n",
       " ('candidate', 8),\n",
       " ('Illinois', 8),\n",
       " ('They', 8),\n",
       " ('guilty', 7),\n",
       " ('charges', 7),\n",
       " ('keep', 7),\n",
       " ('Family', 7),\n",
       " ('Accused', 7),\n",
       " ('–', 7),\n",
       " ('threatened', 7),\n",
       " ('amid', 7),\n",
       " ('Jewish', 7),\n",
       " (\"don't\", 7),\n",
       " ('lost', 7),\n",
       " ('People', 7),\n",
       " ('Want', 7),\n",
       " ('said', 7),\n",
       " ('vote', 7),\n",
       " ('illness', 7),\n",
       " ('pressure', 7),\n",
       " ('Federal', 7),\n",
       " ('blocks', 7),\n",
       " ('And', 7),\n",
       " ('campaign', 7),\n",
       " ('lawsuit', 7),\n",
       " ('Americans', 7),\n",
       " ('background', 7),\n",
       " ('Do', 7),\n",
       " ('anniversary', 7),\n",
       " ('all', 7),\n",
       " ('day', 7),\n",
       " ('Trump,', 7),\n",
       " ('must', 7),\n",
       " ('speech', 7),\n",
       " ('since', 7),\n",
       " ('Justice', 7),\n",
       " ('raise', 7),\n",
       " ('urges', 7),\n",
       " ('across', 7),\n",
       " ('From', 7),\n",
       " ('protect', 7),\n",
       " ('made', 7),\n",
       " ('National', 7),\n",
       " ('Democratic', 7),\n",
       " ('Former', 7),\n",
       " ('Safety', 7),\n",
       " ('down', 7),\n",
       " ('Senate', 7),\n",
       " ('Calls', 7),\n",
       " ('one', 7),\n",
       " ('active', 7),\n",
       " ('Big', 7),\n",
       " ('safe', 6),\n",
       " ('ties', 6),\n",
       " ('accused', 6),\n",
       " ('Group', 6),\n",
       " ('Nikolas', 6),\n",
       " ('Mental', 6),\n",
       " ('shooters', 6),\n",
       " (\"It's\", 6),\n",
       " ('When', 6),\n",
       " ('case', 6),\n",
       " ('teacher', 6),\n",
       " ('arrested', 6),\n",
       " ('tournament', 6),\n",
       " ('shoots', 6),\n",
       " ('Waffle', 6),\n",
       " ('That', 6),\n",
       " ('going', 6)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_words.most_common(358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_lower = [s.lower() for s in english_words_prev_cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(prev_lower))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
